[
    {
        "title": "sampathlonka/a2c-AntBulletEnv-v0",
        "author": "sampathlonka",
        "model_name": "a2c-AntBulletEnv-v0",
        "url": "https://huggingface.co/sampathlonka/a2c-AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nsampathlonka\n/\na2c-AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n1925.78 +/- 212.69\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "giggling-squid/ppo-PyramidsRND",
        "author": "giggling-squid",
        "model_name": "ppo-PyramidsRND",
        "url": "https://huggingface.co/giggling-squid/ppo-PyramidsRND",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ngiggling-squid\n/\nppo-PyramidsRND\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: giggling-squid/ppo-PyramidsRND\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "TahsinZaman/q-Taxi-v3",
        "author": "TahsinZaman",
        "model_name": "q-Taxi-v3",
        "url": "https://huggingface.co/TahsinZaman/q-Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nTahsinZaman\n/\nq-Taxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"TahsinZaman/q-Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "bestemoon/q-FrozenLake-v1-4x4-noSlippery",
        "author": "bestemoon",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/bestemoon/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nbestemoon\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\n# **Q-Learning** Agent playing1 **FrozenLake-v1**\nThis is a trained model of a **Q-Learning** agent playing **FrozenLake-v1** .\n\n## Usage\n\n```python\n\nmodel = load_from_hub(repo_id=\"bestemoon/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n```\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Behnam/Pixelcopter-PLE-v0",
        "author": "Behnam",
        "model_name": "Pixelcopter-PLE-v0",
        "url": "https://huggingface.co/Behnam/Pixelcopter-PLE-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nBehnam\n/\nPixelcopter-PLE-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n38.30 +/- 26.88\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ManishW/Reinforce-cartpole-v1",
        "author": "ManishW",
        "model_name": "Reinforce-cartpole-v1",
        "url": "https://huggingface.co/ManishW/Reinforce-cartpole-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nManishW\n/\nReinforce-cartpole-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "sampathlonka/a2c-PandaReachDense-v2",
        "author": "sampathlonka",
        "model_name": "a2c-PandaReachDense-v2",
        "url": "https://huggingface.co/sampathlonka/a2c-PandaReachDense-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nsampathlonka\n/\na2c-PandaReachDense-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nPandaReachDense-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing PandaReachDense-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing PandaReachDense-v2\n\n\nThis is a trained model of a A2C agent playing PandaReachDense-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton PandaReachDense-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-2.97 +/- 0.56\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "yingzhi/ppo-LunarLander-v2",
        "author": "yingzhi",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/yingzhi/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nyingzhi\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n250.62 +/- 34.24\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ManishW/Reinforce-PixelCopter-v1",
        "author": "ManishW",
        "model_name": "Reinforce-PixelCopter-v1",
        "url": "https://huggingface.co/ManishW/Reinforce-PixelCopter-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nManishW\n/\nReinforce-PixelCopter-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n14.20 +/- 9.06\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "sonny-dev/dqn-atari",
        "author": "sonny-dev",
        "model_name": "dqn-atari",
        "url": "https://huggingface.co/sonny-dev/dqn-atari",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nsonny-dev\n/\ndqn-atari\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga sonny-dev -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga sonny-dev -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga sonny-dev\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 1000000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n263.50 +/- 153.62\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "sartajbhuvaji/Reinforce-Unit4",
        "author": "sartajbhuvaji",
        "model_name": "Reinforce-Unit4",
        "url": "https://huggingface.co/sartajbhuvaji/Reinforce-Unit4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nsartajbhuvaji\n/\nReinforce-Unit4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "FranEnguix/poca-SoccerTwos-test",
        "author": "FranEnguix",
        "model_name": "poca-SoccerTwos-test",
        "url": "https://huggingface.co/FranEnguix/poca-SoccerTwos-test",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nFranEnguix\n/\npoca-SoccerTwos-test\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSoccerTwos\n\ndeep-reinforcement-learning\n\nML-Agents-SoccerTwos\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\npoca Agent playing SoccerTwos\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\npoca Agent playing SoccerTwos\n\n\n  This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos\nStep 1: Find your model_id: FranEnguix/poca-SoccerTwos-test\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "arkadyark/dqn-SpaceInvadersNoFrameskip-v4-default-params",
        "author": "arkadyark",
        "model_name": "dqn-SpaceInvadersNoFrameskip-v4-default-params",
        "url": "https://huggingface.co/arkadyark/dqn-SpaceInvadersNoFrameskip-v4-default-params",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\narkadyark\n/\ndqn-SpaceInvadersNoFrameskip-v4-default-params\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga arkadyark -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga arkadyark -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga arkadyark\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 10000000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n373.50 +/- 194.15\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "cleth/a2c-AntBulletEnv-v0",
        "author": "cleth",
        "model_name": "a2c-AntBulletEnv-v0",
        "url": "https://huggingface.co/cleth/a2c-AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ncleth\n/\na2c-AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n2078.47 +/- 41.45\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "kraken2404/poca-SoccerTwos_v3",
        "author": "kraken2404",
        "model_name": "poca-SoccerTwos_v3",
        "url": "https://huggingface.co/kraken2404/poca-SoccerTwos_v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nkraken2404\n/\npoca-SoccerTwos_v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nunity-ml-agents\n\ndeep-reinforcement-learning\n\nML-Agents-SoccerTwos\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\npoca Agent playing SoccerTwos\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\npoca Agent playing SoccerTwos\n\n\n  This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos\nStep 1: Write your model_id: kraken2404/poca-SoccerTwos_v3\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "moavia/ppo-LunarLander-v2",
        "author": "moavia",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/moavia/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nmoavia\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n230.23 +/- 20.83\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "sartajbhuvaji/Reinforce-Unit4PixelCopter",
        "author": "sartajbhuvaji",
        "model_name": "Reinforce-Unit4PixelCopter",
        "url": "https://huggingface.co/sartajbhuvaji/Reinforce-Unit4PixelCopter",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nsartajbhuvaji\n/\nReinforce-Unit4PixelCopter\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n22.60 +/- 18.21\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "anna-t/rl_course_vizdoom_health_gathering_supreme",
        "author": "anna-t",
        "model_name": "rl_course_vizdoom_health_gathering_supreme",
        "url": "https://huggingface.co/anna-t/rl_course_vizdoom_health_gathering_supreme",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nanna-t\n/\nrl_course_vizdoom_health_gathering_supreme\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nSample Factory\n\nTensorBoard\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in sample-factory\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\nA(n) APPO model trained on the doom_health_gathering_supreme environment.\nThis model was trained using Sample-Factory 2.0: https://github.com/alex-petrenko/sample-factory.\nDocumentation for how to use Sample-Factory can be found at https://www.samplefactory.dev/\n\n\n\n\n\n\t\tDownloading the model\n\t\n\nAfter installing Sample-Factory, download the model with:\npython -m sample_factory.huggingface.load_from_hub -r Jupiterian9/rl_course_vizdoom_health_gathering_supreme\n\n\n\n\n\n\n\t\tUsing the model\n\t\n\nTo run the model after download, use the enjoy script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme\n\nYou can also upload models to the Hugging Face Hub using the same script with the --push_to_hub flag.\nSee https://www.samplefactory.dev/10-huggingface/huggingface/ for more details\n\n\n\n\n\n\t\tTraining with this model\n\t\n\nTo continue training with this model, use the train script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme --restart_behavior=resume --train_for_env_steps=10000000000\n\nNote, you may have to adjust --train_for_env_steps to a suitably high number as the experiment will resume at the number of steps it concluded at.\n        \n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton doom_health_gathering_supreme\nself-reported\n\t\t\t\t\t\t\t\n\n9.38 +/- 2.91\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ecemisildar/doom_health_gathering_supreme_2222",
        "author": "ecemisildar",
        "model_name": "doom_health_gathering_supreme_2222",
        "url": "https://huggingface.co/ecemisildar/doom_health_gathering_supreme_2222",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\necemisildar\n/\ndoom_health_gathering_supreme_2222\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nSample Factory\n\nTensorBoard\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in sample-factory\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\nA(n) APPO model trained on the doom_health_gathering_supreme environment.\nThis model was trained using Sample-Factory 2.0: https://github.com/alex-petrenko/sample-factory.\nDocumentation for how to use Sample-Factory can be found at https://www.samplefactory.dev/\n\n\n\n\n\n\t\tDownloading the model\n\t\n\nAfter installing Sample-Factory, download the model with:\npython -m sample_factory.huggingface.load_from_hub -r ecemisildar/doom_health_gathering_supreme_2222\n\n\n\n\n\n\n\t\tUsing the model\n\t\n\nTo run the model after download, use the enjoy script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=doom_health_gathering_supreme_2222\n\nYou can also upload models to the Hugging Face Hub using the same script with the --push_to_hub flag.\nSee https://www.samplefactory.dev/10-huggingface/huggingface/ for more details\n\n\n\n\n\n\t\tTraining with this model\n\t\n\nTo continue training with this model, use the train script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=doom_health_gathering_supreme_2222 --restart_behavior=resume --train_for_env_steps=10000000000\n\nNote, you may have to adjust --train_for_env_steps to a suitably high number as the experiment will resume at the number of steps it concluded at.\n        \n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton doom_health_gathering_supreme\nself-reported\n\t\t\t\t\t\t\t\n\n3.97 +/- 0.29\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "cleth/a2c-PandaReachDense-v2",
        "author": "cleth",
        "model_name": "a2c-PandaReachDense-v2",
        "url": "https://huggingface.co/cleth/a2c-PandaReachDense-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ncleth\n/\na2c-PandaReachDense-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nPandaReachDense-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing PandaReachDense-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing PandaReachDense-v2\n\n\nThis is a trained model of a A2C agent playing PandaReachDense-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton PandaReachDense-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-0.95 +/- 0.34\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Mag-al/PPO_LunarLander_v2",
        "author": "Mag-al",
        "model_name": "PPO_LunarLander_v2",
        "url": "https://huggingface.co/Mag-al/PPO_LunarLander_v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nMag-al\n/\nPPO_LunarLander_v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n249.31 +/- 23.40\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "bestemoon/q-Taxi-v3",
        "author": "bestemoon",
        "model_name": "q-Taxi-v3",
        "url": "https://huggingface.co/bestemoon/q-Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nbestemoon\n/\nq-Taxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\n# **Q-Learning** Agent playing1 **Taxi-v3**\nThis is a trained model of a **Q-Learning** agent playing **Taxi-v3** .\n\n## Usage\n\n```python\n\nmodel = load_from_hub(repo_id=\"bestemoon/q-Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n```\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "theptrk/first_lunar_lander",
        "author": "theptrk",
        "model_name": "first_lunar_lander",
        "url": "https://huggingface.co/theptrk/first_lunar_lander",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ntheptrk\n/\nfirst_lunar_lander\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n233.59 +/- 36.15\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "spolisar/q-FrozenLake-v1-4x4-noSlippery",
        "author": "spolisar",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/spolisar/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nspolisar\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"spolisar/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "culteejen/DQN-default-RoombaAToB",
        "author": "culteejen",
        "model_name": "DQN-default-RoombaAToB",
        "url": "https://huggingface.co/culteejen/DQN-default-RoombaAToB",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nculteejen\n/\nDQN-default-RoombaAToB\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nRoombaAToB\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing RoombaAToB\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing RoombaAToB\n\n\nThis is a trained model of a DQN agent playing RoombaAToB\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton RoombaAToB\nself-reported\n\t\t\t\t\t\t\t\n\n-134.98 +/- 25.09\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "spolisar/q-Taxi-v3",
        "author": "spolisar",
        "model_name": "q-Taxi-v3",
        "url": "https://huggingface.co/spolisar/q-Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nspolisar\n/\nq-Taxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"spolisar/q-Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ecemisildar/SpaceInvadersNoFrameskip-v4",
        "author": "ecemisildar",
        "model_name": "SpaceInvadersNoFrameskip-v4",
        "url": "https://huggingface.co/ecemisildar/SpaceInvadersNoFrameskip-v4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\necemisildar\n/\nSpaceInvadersNoFrameskip-v4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga ecemisildar -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga ecemisildar -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga ecemisildar\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 1000000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n593.00 +/- 222.27\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "smatzanas/RL",
        "author": "smatzanas",
        "model_name": "RL",
        "url": "https://huggingface.co/smatzanas/RL",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nsmatzanas\n/\nRL\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nHuggy\n\ndeep-reinforcement-learning\n\nML-Agents-Huggy\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Huggy\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Huggy\n\n\n  This is a trained model of a ppo agent playing Huggy using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Huggy\nStep 1: Find your model_id: smatzanas/RL\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "dean-r/Reinforece-cartpole_policyV1",
        "author": "dean-r",
        "model_name": "Reinforece-cartpole_policyV1",
        "url": "https://huggingface.co/dean-r/Reinforece-cartpole_policyV1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ndean-r\n/\nReinforece-cartpole_policyV1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Yolaw/RLcourse",
        "author": "Yolaw",
        "model_name": "RLcourse",
        "url": "https://huggingface.co/Yolaw/RLcourse",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nYolaw\n/\nRLcourse\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\tYou need to agree to share your contact information to access this model\nThis repository is publicly accessible, but\n\t\t\tyou have to accept the conditions to access its files and content.\n\t\t\nLog in \n\t\t\tor\n\t\t\tSign Up \n\t\t\tto review the conditions and access this model content.\n\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n264.44 +/- 16.77\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Ytia1010/ppo-LunarLander-v2",
        "author": "Ytia1010",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/Ytia1010/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nYtia1010\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n257.01 +/- 17.76\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "arkadyark/dqn-SpaceInvadersNoFrameskip-v4-ppo",
        "author": "arkadyark",
        "model_name": "dqn-SpaceInvadersNoFrameskip-v4-ppo",
        "url": "https://huggingface.co/arkadyark/dqn-SpaceInvadersNoFrameskip-v4-ppo",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\narkadyark\n/\ndqn-SpaceInvadersNoFrameskip-v4-ppo\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga arkadyark -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga arkadyark -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga arkadyark\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 10000000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n862.50 +/- 470.60\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "natkite/ppo-Huggy",
        "author": "natkite",
        "model_name": "ppo-Huggy",
        "url": "https://huggingface.co/natkite/ppo-Huggy",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nnatkite\n/\nppo-Huggy\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nHuggy\n\ndeep-reinforcement-learning\n\nML-Agents-Huggy\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Huggy\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Huggy\n\n\n  This is a trained model of a ppo agent playing Huggy using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Huggy\nStep 1: Find your model_id: natkite/ppo-Huggy\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month9\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Romerik/q-FrozenLake-v1-4x4-noSlippery",
        "author": "Romerik",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/Romerik/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nRomerik\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Romerik/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Romerik/q-Taxi-v3",
        "author": "Romerik",
        "model_name": "q-Taxi-v3",
        "url": "https://huggingface.co/Romerik/q-Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nRomerik\n/\nq-Taxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Romerik/q-Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.52 +/- 2.73\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "stevbach/dqn-SpaceInvadersNoFrameskip-v4",
        "author": "stevbach",
        "model_name": "dqn-SpaceInvadersNoFrameskip-v4",
        "url": "https://huggingface.co/stevbach/dqn-SpaceInvadersNoFrameskip-v4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nstevbach\n/\ndqn-SpaceInvadersNoFrameskip-v4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga stevbach -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga stevbach -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga stevbach\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 1000000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n526.00 +/- 72.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "jimfordlafleur/polev1-basic",
        "author": "jimfordlafleur",
        "model_name": "polev1-basic",
        "url": "https://huggingface.co/jimfordlafleur/polev1-basic",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njimfordlafleur\n/\npolev1-basic\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "alanland/ppo-LunarLander-v2",
        "author": "alanland",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/alanland/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nalanland\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n258.36 +/- 13.96\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "globophobe/ppo-SnowballTarget",
        "author": "globophobe",
        "model_name": "ppo-SnowballTarget",
        "url": "https://huggingface.co/globophobe/ppo-SnowballTarget",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nglobophobe\n/\nppo-SnowballTarget\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: globophobe/ppo-SnowballTargetTESTCOLAB\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "globophobe/ppo-PyramidsRND",
        "author": "globophobe",
        "model_name": "ppo-PyramidsRND",
        "url": "https://huggingface.co/globophobe/ppo-PyramidsRND",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nglobophobe\n/\nppo-PyramidsRND\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: globophobe/ppo-PyramidsRND\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "stevbach/Reinforce-Cartpolev1",
        "author": "stevbach",
        "model_name": "Reinforce-Cartpolev1",
        "url": "https://huggingface.co/stevbach/Reinforce-Cartpolev1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nstevbach\n/\nReinforce-Cartpolev1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "globophobe/a2c-AntBulletEnv-v0",
        "author": "globophobe",
        "model_name": "a2c-AntBulletEnv-v0",
        "url": "https://huggingface.co/globophobe/a2c-AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nglobophobe\n/\na2c-AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n1087.72 +/- 88.11\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "erosendo/dqn-SpaceInvaders",
        "author": "erosendo",
        "model_name": "dqn-SpaceInvaders",
        "url": "https://huggingface.co/erosendo/dqn-SpaceInvaders",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nerosendo\n/\ndqn-SpaceInvaders\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga erosendo -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga erosendo -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga erosendo\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 1000000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n493.50 +/- 106.33\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "globophobe/a2c-PandaReachDense-v2",
        "author": "globophobe",
        "model_name": "a2c-PandaReachDense-v2",
        "url": "https://huggingface.co/globophobe/a2c-PandaReachDense-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nglobophobe\n/\na2c-PandaReachDense-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nPandaReachDense-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing PandaReachDense-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing PandaReachDense-v2\n\n\nThis is a trained model of a A2C agent playing PandaReachDense-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton PandaReachDense-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-2.26 +/- 0.57\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "chenoi/deepRL1",
        "author": "chenoi",
        "model_name": "deepRL1",
        "url": "https://huggingface.co/chenoi/deepRL1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nchenoi\n/\ndeepRL1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n280.03 +/- 20.25\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "globophobe/rl_course_vizdoom_health_gathering_supreme",
        "author": "globophobe",
        "model_name": "rl_course_vizdoom_health_gathering_supreme",
        "url": "https://huggingface.co/globophobe/rl_course_vizdoom_health_gathering_supreme",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nglobophobe\n/\nrl_course_vizdoom_health_gathering_supreme\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nSample Factory\n\nTensorBoard\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in sample-factory\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\nA(n) APPO model trained on the doom_health_gathering_supreme environment.\nThis model was trained using Sample-Factory 2.0: https://github.com/alex-petrenko/sample-factory.\nDocumentation for how to use Sample-Factory can be found at https://www.samplefactory.dev/\n\n\n\n\n\n\t\tDownloading the model\n\t\n\nAfter installing Sample-Factory, download the model with:\npython -m sample_factory.huggingface.load_from_hub -r globophobe/rl_course_vizdoom_health_gathering_supreme\n\n\n\n\n\n\n\t\tUsing the model\n\t\n\nTo run the model after download, use the enjoy script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme\n\nYou can also upload models to the Hugging Face Hub using the same script with the --push_to_hub flag.\nSee https://www.samplefactory.dev/10-huggingface/huggingface/ for more details\n\n\n\n\n\n\t\tTraining with this model\n\t\n\nTo continue training with this model, use the train script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme --restart_behavior=resume --train_for_env_steps=10000000000\n\nNote, you may have to adjust --train_for_env_steps to a suitably high number as the experiment will resume at the number of steps it concluded at.\n        \n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton doom_health_gathering_supreme\nself-reported\n\t\t\t\t\t\t\t\n\n11.21 +/- 5.05\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "stevbach/Reinforce-Pixelcopter-PLE-v0",
        "author": "stevbach",
        "model_name": "Reinforce-Pixelcopter-PLE-v0",
        "url": "https://huggingface.co/stevbach/Reinforce-Pixelcopter-PLE-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nstevbach\n/\nReinforce-Pixelcopter-PLE-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n12.40 +/- 10.50\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Bailey24/LunarLander-v2",
        "author": "Bailey24",
        "model_name": "LunarLander-v2",
        "url": "https://huggingface.co/Bailey24/LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nBailey24\n/\nLunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nppo Agent playing LunarLander-v2\n\n\nThis is a trained model of a ppo agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n260.52 +/- 35.41\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Ehsan-Tavan/q-FrozenLake-v1-4x4-noSlippery",
        "author": "Ehsan-Tavan",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/Ehsan-Tavan/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nEhsan-Tavan\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Ehsan-Tavan/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ManishW/ppo-SnowballTarget",
        "author": "ManishW",
        "model_name": "ppo-SnowballTarget",
        "url": "https://huggingface.co/ManishW/ppo-SnowballTarget",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nManishW\n/\nppo-SnowballTarget\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: ManishW/ppo-SnowballTarget\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Vaibhavoutat/q-FrozenLake-v1-4x4-noSlippery",
        "author": "Vaibhavoutat",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/Vaibhavoutat/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nVaibhavoutat\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Vaibhavoutat/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Ehsan-Tavan/Taxi-v3",
        "author": "Ehsan-Tavan",
        "model_name": "Taxi-v3",
        "url": "https://huggingface.co/Ehsan-Tavan/Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nEhsan-Tavan\n/\nTaxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Ehsan-Tavan/Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "lheinbokel/ppo-LunarLander-v2",
        "author": "lheinbokel",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/lheinbokel/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nlheinbokel\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n256.41 +/- 17.22\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ManishW/ppo-Pyramids-v1",
        "author": "ManishW",
        "model_name": "ppo-Pyramids-v1",
        "url": "https://huggingface.co/ManishW/ppo-Pyramids-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nManishW\n/\nppo-Pyramids-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: ManishW/ppo-Pyramids-v1\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Bailey24/ppo-Huggy",
        "author": "Bailey24",
        "model_name": "ppo-Huggy",
        "url": "https://huggingface.co/Bailey24/ppo-Huggy",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nBailey24\n/\nppo-Huggy\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nHuggy\n\ndeep-reinforcement-learning\n\nML-Agents-Huggy\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Huggy\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Huggy\n\n\n  This is a trained model of a ppo agent playing Huggy using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Huggy\nStep 1: Find your model_id: Bailey24/ppo-Huggy\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "NikosKokkini/ppo-CartPole-v1",
        "author": "NikosKokkini",
        "model_name": "ppo-CartPole-v1",
        "url": "https://huggingface.co/NikosKokkini/ppo-CartPole-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nNikosKokkini\n/\nppo-CartPole-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTensorBoard\n\nCartPole-v1\n\nppo\n\ndeep-reinforcement-learning\n\ncustom-implementation\n\ndeep-rl-course\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent Playing CartPole-v1\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\t\tPPO Agent Playing CartPole-v1\n\t\n\n  This is a trained model of a PPO agent playing CartPole-v1.\n\n\n\n\n\n\t\tHyperparameters\n\t\n\n{'exp_name': 'ppo'\n'seed': 1\n'repo_id': 'NikosKokkini/ppo-CartPole-v1'\n'torch_deterministic': True\n'cuda': True\n'track': False\n'wandb_project_name': 'cleanRL'\n'wandb_entity': None\n'capture_video': False\n'env_id': 'CartPole-v1'\n'total_timesteps': 50000\n'learning_rate': 0.00025\n'num_envs': 4\n'num_steps': 128\n'anneal_lr': True\n'gae': True\n'gamma': 0.99\n'gae_lambda': 0.95\n'num_minibatches': 4\n'update_epochs': 4\n'norm_adv': True\n'clip_coef': 0.2\n'clip_vloss': True\n'ent_coef': 0.01\n'vf_coef': 0.5\n'max_grad_norm': 0.5\n'target_kl': None\n'batch_size': 512\n'minibatch_size': 128}\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n182.80 +/- 97.40\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Raiden-1001/poca-Soccerv7",
        "author": "Raiden-1001",
        "model_name": "poca-Soccerv7",
        "url": "https://huggingface.co/Raiden-1001/poca-Soccerv7",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nRaiden-1001\n/\npoca-Soccerv7\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nunity-ml-agents\n\ndeep-reinforcement-learning\n\nML-Agents-SoccerTwos\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\npoca Agent playing SoccerTwos\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\npoca Agent playing SoccerTwos\n\n\n  This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos\nStep 1: Write your model_id: Raiden-1001/poca-Soccerv7\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month37\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "xerl/q-FrozenLake-v1-4x4-noSlippery",
        "author": "xerl",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/xerl/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nxerl\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\n# **Q-Learning** Agent playing1 **FrozenLake-v1**\nThis is a trained model of a **Q-Learning** agent playing **FrozenLake-v1** .\n\n## Usage\n\n```python\n\nmodel = load_from_hub(repo_id=\"xerl/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n```\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "NikosKokkini/LunaLander-v2",
        "author": "NikosKokkini",
        "model_name": "LunaLander-v2",
        "url": "https://huggingface.co/NikosKokkini/LunaLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nNikosKokkini\n/\nLunaLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTensorBoard\n\nLunarLander-v2\n\nppo\n\ndeep-reinforcement-learning\n\ncustom-implementation\n\ndeep-rl-course\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent Playing LunarLander-v2\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\t\tPPO Agent Playing LunarLander-v2\n\t\n\n  This is a trained model of a PPO agent playing LunarLander-v2.\n\n\n\n\n\n\t\tHyperparameters\n\t\n\n{'exp_name': 'ppo'\n'seed': 1\n'torch_deterministic': True\n'cuda': True\n'track': False\n'wandb_project_name': 'cleanRL'\n'wandb_entity': None\n'capture_video': False\n'env_id': 'LunarLander-v2'\n'total_timesteps': 50000\n'learning_rate': 0.00025\n'num_envs': 4\n'num_steps': 128\n'anneal_lr': True\n'gae': True\n'gamma': 0.99\n'gae_lambda': 0.95\n'num_minibatches': 4\n'update_epochs': 4\n'norm_adv': True\n'clip_coef': 0.2\n'clip_vloss': True\n'ent_coef': 0.01\n'vf_coef': 0.5\n'max_grad_norm': 0.5\n'target_kl': None\n'repo_id': 'NikosKokkini/LunaLander-v2'\n'batch_size': 512\n'minibatch_size': 128}\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-140.28 +/- 82.33\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "mmg10/deep_rl_unit1",
        "author": "mmg10",
        "model_name": "deep_rl_unit1",
        "url": "https://huggingface.co/mmg10/deep_rl_unit1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nmmg10\n/\ndeep_rl_unit1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n236.12 +/- 47.65\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "messham/a2c-AntBulletEnv-v0",
        "author": "messham",
        "model_name": "a2c-AntBulletEnv-v0",
        "url": "https://huggingface.co/messham/a2c-AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nmessham\n/\na2c-AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n1556.32 +/- 93.77\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "mmg10/deep_rl_unit1_1",
        "author": "mmg10",
        "model_name": "deep_rl_unit1_1",
        "url": "https://huggingface.co/mmg10/deep_rl_unit1_1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nmmg10\n/\ndeep_rl_unit1_1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n254.38 +/- 18.03\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "vovikdrg/q-FrozenLake-v1-4x4-noSlippery",
        "author": "vovikdrg",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/vovikdrg/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nvovikdrg\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"vovikdrg/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4\nself-reported\n\t\t\t\t\t\t\t\n\n0.82 +/- 0.38\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Allrandom/Reinforce-CartPole-v1-default",
        "author": "Allrandom",
        "model_name": "Reinforce-CartPole-v1-default",
        "url": "https://huggingface.co/Allrandom/Reinforce-CartPole-v1-default",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nAllrandom\n/\nReinforce-CartPole-v1-default\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "vovikdrg/taxi-rl",
        "author": "vovikdrg",
        "model_name": "taxi-rl",
        "url": "https://huggingface.co/vovikdrg/taxi-rl",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nvovikdrg\n/\ntaxi-rl\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"vovikdrg/taxi-rl\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "messham/a2c-PandaReachDense-v2",
        "author": "messham",
        "model_name": "a2c-PandaReachDense-v2",
        "url": "https://huggingface.co/messham/a2c-PandaReachDense-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nmessham\n/\na2c-PandaReachDense-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nPandaReachDense-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing PandaReachDense-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing PandaReachDense-v2\n\n\nThis is a trained model of a A2C agent playing PandaReachDense-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton PandaReachDense-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-2.35 +/- 0.96\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Mihara-bot/ppo-SnowballTargetTESTCOLAB",
        "author": "Mihara-bot",
        "model_name": "ppo-SnowballTargetTESTCOLAB",
        "url": "https://huggingface.co/Mihara-bot/ppo-SnowballTargetTESTCOLAB",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nMihara-bot\n/\nppo-SnowballTargetTESTCOLAB\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: Mihara-bot/ppo-SnowballTargetTESTCOLAB\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month13\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Bailey24/q-FrozenLake-v1-4x4-noSlippery",
        "author": "Bailey24",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/Bailey24/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nBailey24\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Bailey24/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "jimfordlafleur/pixelcopterV1",
        "author": "jimfordlafleur",
        "model_name": "pixelcopterV1",
        "url": "https://huggingface.co/jimfordlafleur/pixelcopterV1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njimfordlafleur\n/\npixelcopterV1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n18.60 +/- 15.79\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Mihara-bot/ppo-PyramidsTESTCOLAB",
        "author": "Mihara-bot",
        "model_name": "ppo-PyramidsTESTCOLAB",
        "url": "https://huggingface.co/Mihara-bot/ppo-PyramidsTESTCOLAB",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nMihara-bot\n/\nppo-PyramidsTESTCOLAB\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: Mihara-bot/ppo-PyramidsTESTCOLAB\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "tvnguyen/dqn-SpaceInvadersNoFrameskip-v4",
        "author": "tvnguyen",
        "model_name": "dqn-SpaceInvadersNoFrameskip-v4",
        "url": "https://huggingface.co/tvnguyen/dqn-SpaceInvadersNoFrameskip-v4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ntvnguyen\n/\ndqn-SpaceInvadersNoFrameskip-v4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga tvnguyen -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga tvnguyen -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga tvnguyen\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 2000000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n588.00 +/- 72.74\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "mmg10/ppo-Huggy",
        "author": "mmg10",
        "model_name": "ppo-Huggy",
        "url": "https://huggingface.co/mmg10/ppo-Huggy",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nmmg10\n/\nppo-Huggy\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nHuggy\n\ndeep-reinforcement-learning\n\nML-Agents-Huggy\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Huggy\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Huggy\n\n\n  This is a trained model of a ppo agent playing Huggy using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Huggy\nStep 1: Find your model_id: mmg10/ppo-Huggy\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Kimonode/ppo-LunarLander-v2",
        "author": "Kimonode",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/Kimonode/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nKimonode\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n260.80 +/- 17.52\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Musha-the-Yusha/rl_course_vizdoom_health_gathering_supreme",
        "author": "Musha-the-Yusha",
        "model_name": "rl_course_vizdoom_health_gathering_supreme",
        "url": "https://huggingface.co/Musha-the-Yusha/rl_course_vizdoom_health_gathering_supreme",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nMusha-the-Yusha\n/\nrl_course_vizdoom_health_gathering_supreme\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nSample Factory\n\nTensorBoard\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in sample-factory\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\nA(n) APPO model trained on the doom_health_gathering_supreme environment.\nThis model was trained using Sample-Factory 2.0: https://github.com/alex-petrenko/sample-factory.\nDocumentation for how to use Sample-Factory can be found at https://www.samplefactory.dev/\n\n\n\n\n\n\t\tDownloading the model\n\t\n\nAfter installing Sample-Factory, download the model with:\npython -m sample_factory.huggingface.load_from_hub -r Musha-the-Yusha/rl_course_vizdoom_health_gathering_supreme\n\n\n\n\n\n\n\t\tUsing the model\n\t\n\nTo run the model after download, use the enjoy script corresponding to this environment:\npython -m .home.deus.anaconda3.envs.ppo_implementation.lib.python3.9.site-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme\n\nYou can also upload models to the Hugging Face Hub using the same script with the --push_to_hub flag.\nSee https://www.samplefactory.dev/10-huggingface/huggingface/ for more details\n\n\n\n\n\n\t\tTraining with this model\n\t\n\nTo continue training with this model, use the train script corresponding to this environment:\npython -m .home.deus.anaconda3.envs.ppo_implementation.lib.python3.9.site-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme --restart_behavior=resume --train_for_env_steps=10000000000\n\nNote, you may have to adjust --train_for_env_steps to a suitably high number as the experiment will resume at the number of steps it concluded at.\n        \n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton doom_health_gathering_supreme\nself-reported\n\t\t\t\t\t\t\t\n\n9.94 +/- 4.58\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "PabloTa/rl_course_vizdoom_health_gathering_supreme",
        "author": "PabloTa",
        "model_name": "rl_course_vizdoom_health_gathering_supreme",
        "url": "https://huggingface.co/PabloTa/rl_course_vizdoom_health_gathering_supreme",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nPabloTa\n/\nrl_course_vizdoom_health_gathering_supreme\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nSample Factory\n\nTensorBoard\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in sample-factory\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\nA(n) APPO model trained on the doom_health_gathering_supreme environment.\nThis model was trained using Sample-Factory 2.0: https://github.com/alex-petrenko/sample-factory.\nDocumentation for how to use Sample-Factory can be found at https://www.samplefactory.dev/\n\n\n\n\n\n\t\tDownloading the model\n\t\n\nAfter installing Sample-Factory, download the model with:\npython -m sample_factory.huggingface.load_from_hub -r PabloTa/rl_course_vizdoom_health_gathering_supreme\n\n\n\n\n\n\n\t\tUsing the model\n\t\n\nTo run the model after download, use the enjoy script corresponding to this environment:\npython -m .home.melon.PycharmProjects.huggingface.unit8.2.main --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme\n\nYou can also upload models to the Hugging Face Hub using the same script with the --push_to_hub flag.\nSee https://www.samplefactory.dev/10-huggingface/huggingface/ for more details\n\n\n\n\n\n\t\tTraining with this model\n\t\n\nTo continue training with this model, use the train script corresponding to this environment:\npython -m .home.melon.PycharmProjects.huggingface.unit8.2.main --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme --restart_behavior=resume --train_for_env_steps=10000000000\n\nNote, you may have to adjust --train_for_env_steps to a suitably high number as the experiment will resume at the number of steps it concluded at.\n        \n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton doom_health_gathering_supreme\nself-reported\n\t\t\t\t\t\t\t\n\n19.01 +/- 2.72\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "utyug1/ppo-sb3-LunarLander-v2",
        "author": "utyug1",
        "model_name": "ppo-sb3-LunarLander-v2",
        "url": "https://huggingface.co/utyug1/ppo-sb3-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nutyug1\n/\nppo-sb3-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n269.49 +/- 26.70\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "giggling-squid/a2c-AntBulletEnv-v0",
        "author": "giggling-squid",
        "model_name": "a2c-AntBulletEnv-v0",
        "url": "https://huggingface.co/giggling-squid/a2c-AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ngiggling-squid\n/\na2c-AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n1648.15 +/- 395.99\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "torreygooch/PPO-Lunar_Lander",
        "author": "torreygooch",
        "model_name": "PPO-Lunar_Lander",
        "url": "https://huggingface.co/torreygooch/PPO-Lunar_Lander",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ntorreygooch\n/\nPPO-Lunar_Lander\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n266.77 +/- 22.64\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "stucksam/Reinforce-v1",
        "author": "stucksam",
        "model_name": "Reinforce-v1",
        "url": "https://huggingface.co/stucksam/Reinforce-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nstucksam\n/\nReinforce-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "erosendo/Reinforce-cartpole",
        "author": "erosendo",
        "model_name": "Reinforce-cartpole",
        "url": "https://huggingface.co/erosendo/Reinforce-cartpole",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nerosendo\n/\nReinforce-cartpole\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n129.80 +/- 4.28\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ibadrehman/Reinforce-copter02",
        "author": "ibadrehman",
        "model_name": "Reinforce-copter02",
        "url": "https://huggingface.co/ibadrehman/Reinforce-copter02",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nibadrehman\n/\nReinforce-copter02\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n35.60 +/- 16.76\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "giggling-squid/a2c-PandaReachDense-v2",
        "author": "giggling-squid",
        "model_name": "a2c-PandaReachDense-v2",
        "url": "https://huggingface.co/giggling-squid/a2c-PandaReachDense-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ngiggling-squid\n/\na2c-PandaReachDense-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nPandaReachDense-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing PandaReachDense-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing PandaReachDense-v2\n\n\nThis is a trained model of a A2C agent playing PandaReachDense-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton PandaReachDense-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-1.04 +/- 0.39\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "stucksam/Reinforce-PixelCopter-v1",
        "author": "stucksam",
        "model_name": "Reinforce-PixelCopter-v1",
        "url": "https://huggingface.co/stucksam/Reinforce-PixelCopter-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nstucksam\n/\nReinforce-PixelCopter-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n32.00 +/- 24.31\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "enakilci/ppo-lunar-agent-v2",
        "author": "enakilci",
        "model_name": "ppo-lunar-agent-v2",
        "url": "https://huggingface.co/enakilci/ppo-lunar-agent-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nenakilci\n/\nppo-lunar-agent-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n233.41 +/- 45.16\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Vaibhavoutat/q-Taxi-v3",
        "author": "Vaibhavoutat",
        "model_name": "q-Taxi-v3",
        "url": "https://huggingface.co/Vaibhavoutat/q-Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nVaibhavoutat\n/\nq-Taxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Vaibhavoutat/q-Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.52 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Maulik-P/ppo-SnowballTargetTESTCOLAB",
        "author": "Maulik-P",
        "model_name": "ppo-SnowballTargetTESTCOLAB",
        "url": "https://huggingface.co/Maulik-P/ppo-SnowballTargetTESTCOLAB",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nMaulik-P\n/\nppo-SnowballTargetTESTCOLAB\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: Maulik-P/ppo-SnowballTargetTESTCOLAB\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "FranEnguix/LunarLander-v2-ppo",
        "author": "FranEnguix",
        "model_name": "LunarLander-v2-ppo",
        "url": "https://huggingface.co/FranEnguix/LunarLander-v2-ppo",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nFranEnguix\n/\nLunarLander-v2-ppo\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTensorBoard\n\nLunarLander-v2\n\nppo\n\ndeep-reinforcement-learning\n\ncustom-implementation\n\ndeep-rl-course\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent Playing LunarLander-v2\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\t\tPPO Agent Playing LunarLander-v2\n\t\n\n  This is a trained model of a PPO agent playing LunarLander-v2.\n\n\n\n\n\n\t\tHyperparameters\n\t\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-175.67 +/- 73.55\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ItchyB/dqn-SpaceInvadersNoFrameskip-v4",
        "author": "ItchyB",
        "model_name": "dqn-SpaceInvadersNoFrameskip-v4",
        "url": "https://huggingface.co/ItchyB/dqn-SpaceInvadersNoFrameskip-v4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nItchyB\n/\ndqn-SpaceInvadersNoFrameskip-v4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga ItchyB -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga ItchyB -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga ItchyB\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 1000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n274.50 +/- 31.50\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Maulik-P/ppo-PyramidTargetTESTCOLAB",
        "author": "Maulik-P",
        "model_name": "ppo-PyramidTargetTESTCOLAB",
        "url": "https://huggingface.co/Maulik-P/ppo-PyramidTargetTESTCOLAB",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nMaulik-P\n/\nppo-PyramidTargetTESTCOLAB\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: Maulik-P/ppo-PyramidTargetTESTCOLAB\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Allrandom/Reinforce-Pixelcopter-PLE-v0-short",
        "author": "Allrandom",
        "model_name": "Reinforce-Pixelcopter-PLE-v0-short",
        "url": "https://huggingface.co/Allrandom/Reinforce-Pixelcopter-PLE-v0-short",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nAllrandom\n/\nReinforce-Pixelcopter-PLE-v0-short\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n75.20 +/- 76.07\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "xerl/Taxi-v3",
        "author": "xerl",
        "model_name": "Taxi-v3",
        "url": "https://huggingface.co/xerl/Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nxerl\n/\nTaxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\n# **Q-Learning** Agent playing1 **Taxi-v3**\nThis is a trained model of a **Q-Learning** agent playing **Taxi-v3** .\n\n## Usage\n\n```python\n\nmodel = load_from_hub(repo_id=\"xerl/Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n```\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.52 +/- 2.62\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "gelas/a2c-AntBulletEnv-v0",
        "author": "gelas",
        "model_name": "a2c-AntBulletEnv-v0",
        "url": "https://huggingface.co/gelas/a2c-AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ngelas\n/\na2c-AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n1495.73 +/- 181.82\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "FranEnguix/rl_course_vizdoom_health_gathering_supreme",
        "author": "FranEnguix",
        "model_name": "rl_course_vizdoom_health_gathering_supreme",
        "url": "https://huggingface.co/FranEnguix/rl_course_vizdoom_health_gathering_supreme",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nFranEnguix\n/\nrl_course_vizdoom_health_gathering_supreme\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nSample Factory\n\nTensorBoard\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in sample-factory\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\nA(n) APPO model trained on the doom_health_gathering_supreme environment.\nThis model was trained using Sample-Factory 2.0: https://github.com/alex-petrenko/sample-factory.\nDocumentation for how to use Sample-Factory can be found at https://www.samplefactory.dev/\n\n\n\n\n\n\t\tDownloading the model\n\t\n\nAfter installing Sample-Factory, download the model with:\npython -m sample_factory.huggingface.load_from_hub -r FranEnguix/rl_course_vizdoom_health_gathering_supreme\n\n\n\n\n\n\n\t\tUsing the model\n\t\n\nTo run the model after download, use the enjoy script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme\n\nYou can also upload models to the Hugging Face Hub using the same script with the --push_to_hub flag.\nSee https://www.samplefactory.dev/10-huggingface/huggingface/ for more details\n\n\n\n\n\n\t\tTraining with this model\n\t\n\nTo continue training with this model, use the train script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme --restart_behavior=resume --train_for_env_steps=10000000000\n\nNote, you may have to adjust --train_for_env_steps to a suitably high number as the experiment will resume at the number of steps it concluded at.\n        \n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton doom_health_gathering_supreme\nself-reported\n\t\t\t\t\t\t\t\n\n12.79 +/- 5.30\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "utyug1/rl_course_vizdoom_health_gathering_supreme",
        "author": "utyug1",
        "model_name": "rl_course_vizdoom_health_gathering_supreme",
        "url": "https://huggingface.co/utyug1/rl_course_vizdoom_health_gathering_supreme",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nutyug1\n/\nrl_course_vizdoom_health_gathering_supreme\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nSample Factory\n\nTensorBoard\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in sample-factory\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\nA(n) APPO model trained on the doom_health_gathering_supreme environment.\nThis model was trained using Sample-Factory 2.0: https://github.com/alex-petrenko/sample-factory.\nDocumentation for how to use Sample-Factory can be found at https://www.samplefactory.dev/\n\n\n\n\n\n\t\tDownloading the model\n\t\n\nAfter installing Sample-Factory, download the model with:\npython -m sample_factory.huggingface.load_from_hub -r utyug1/rl_course_vizdoom_health_gathering_supreme\n\n\n\n\n\n\n\t\tUsing the model\n\t\n\nTo run the model after download, use the enjoy script corresponding to this environment:\npython -m .home.boris.ustyugov.miniconda3.envs.deep_rl.lib.python3.10.site-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme\n\nYou can also upload models to the Hugging Face Hub using the same script with the --push_to_hub flag.\nSee https://www.samplefactory.dev/10-huggingface/huggingface/ for more details\n\n\n\n\n\n\t\tTraining with this model\n\t\n\nTo continue training with this model, use the train script corresponding to this environment:\npython -m .home.boris.ustyugov.miniconda3.envs.deep_rl.lib.python3.10.site-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme --restart_behavior=resume --train_for_env_steps=10000000000\n\nNote, you may have to adjust --train_for_env_steps to a suitably high number as the experiment will resume at the number of steps it concluded at.\n        \n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton doom_health_gathering_supreme\nself-reported\n\t\t\t\t\t\t\t\n\n15.67 +/- 5.23\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Agneev/a2c-AntBulletEnv-v0",
        "author": "Agneev",
        "model_name": "a2c-AntBulletEnv-v0",
        "url": "https://huggingface.co/Agneev/a2c-AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nAgneev\n/\na2c-AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n2090.94 +/- 510.35\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "gelas/a2c-PandaReachDense-v2",
        "author": "gelas",
        "model_name": "a2c-PandaReachDense-v2",
        "url": "https://huggingface.co/gelas/a2c-PandaReachDense-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ngelas\n/\na2c-PandaReachDense-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nPandaReachDense-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing PandaReachDense-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing PandaReachDense-v2\n\n\nThis is a trained model of a A2C agent playing PandaReachDense-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton PandaReachDense-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-2.04 +/- 0.93\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ibadrehman/new-a2c-PandaReachDense-v2",
        "author": "ibadrehman",
        "model_name": "new-a2c-PandaReachDense-v2",
        "url": "https://huggingface.co/ibadrehman/new-a2c-PandaReachDense-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nibadrehman\n/\nnew-a2c-PandaReachDense-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nPandaReachDense-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing PandaReachDense-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing PandaReachDense-v2\n\n\nThis is a trained model of a A2C agent playing PandaReachDense-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton PandaReachDense-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-1.20 +/- 0.48\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "JaviBJ/ppo-SnowballTarget",
        "author": "JaviBJ",
        "model_name": "ppo-SnowballTarget",
        "url": "https://huggingface.co/JaviBJ/ppo-SnowballTarget",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nJaviBJ\n/\nppo-SnowballTarget\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: JaviBJ/ppo-SnowballTarget\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month11\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "JustinReboullot/q-Taxi-v3",
        "author": "JustinReboullot",
        "model_name": "q-Taxi-v3",
        "url": "https://huggingface.co/JustinReboullot/q-Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nJustinReboullot\n/\nq-Taxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\n# **Q-Learning** Agent playing1 **Taxi-v3**\nThis is a trained model of a **Q-Learning** agent playing **Taxi-v3** .\n\n## Usage\n\n```python\n\nmodel = load_from_hub(repo_id=\"JustinReboullot/q-Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n```\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Agneev/a2c-PandaReachDense-v2",
        "author": "Agneev",
        "model_name": "a2c-PandaReachDense-v2",
        "url": "https://huggingface.co/Agneev/a2c-PandaReachDense-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nAgneev\n/\na2c-PandaReachDense-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nPandaReachDense-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing PandaReachDense-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing PandaReachDense-v2\n\n\nThis is a trained model of a A2C agent playing PandaReachDense-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton PandaReachDense-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-3.51 +/- 1.02\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Eselroth/LunaTryout",
        "author": "Eselroth",
        "model_name": "LunaTryout",
        "url": "https://huggingface.co/Eselroth/LunaTryout",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nEselroth\n/\nLunaTryout\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n262.66 +/- 41.92\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "JaviBJ/ppo-Pyramids",
        "author": "JaviBJ",
        "model_name": "ppo-Pyramids",
        "url": "https://huggingface.co/JaviBJ/ppo-Pyramids",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nJaviBJ\n/\nppo-Pyramids\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: JaviBJ/ppo-Pyramids\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Jensonah/RL_tutorial1",
        "author": "Jensonah",
        "model_name": "RL_tutorial1",
        "url": "https://huggingface.co/Jensonah/RL_tutorial1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nJensonah\n/\nRL_tutorial1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n266.04 +/- 17.78\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "tooucci/lander_agent",
        "author": "tooucci",
        "model_name": "lander_agent",
        "url": "https://huggingface.co/tooucci/lander_agent",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ntooucci\n/\nlander_agent\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nimport gym\n\nfrom huggingface_sb3 import load_from_hub, package_to_hub, push_to_hub\nfrom huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub.\n\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.evaluation import evaluate_policy\nfrom stable_baselines3.common.env_util import make_vec_env\n\n# Create the environment\nenv = make_vec_env('LunarLander-v2', n_envs=16)\n\nmodel = PPO(\n    policy = 'MlpPolicy',\n    env = env,\n    n_steps = 1024,\n    batch_size = 64,\n    n_epochs = 4,\n    gamma = 0.999,\n    gae_lambda = 0.98,\n    ent_coef = 0.01,\n    verbose=1)\n\n# Train it for 1,000,000 timesteps\nmodel.learn(total_timesteps=1000000)\n\n# Save the model\nmodel_name = \"unit1-ppo-LunarLander-v2\"\nmodel.save(model_name)\n\n#evaluate model\neval_env = gym.make(\"LunarLander-v2\")\nmean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\nprint(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")\n\n...\n\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n264.64 +/- 12.68\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Allrandom/Reinforce-Pixelcopter-PLE-v0",
        "author": "Allrandom",
        "model_name": "Reinforce-Pixelcopter-PLE-v0",
        "url": "https://huggingface.co/Allrandom/Reinforce-Pixelcopter-PLE-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nAllrandom\n/\nReinforce-Pixelcopter-PLE-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n35.40 +/- 18.02\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "tvnguyen/Reinforce-CartPole-v1",
        "author": "tvnguyen",
        "model_name": "Reinforce-CartPole-v1",
        "url": "https://huggingface.co/tvnguyen/Reinforce-CartPole-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ntvnguyen\n/\nReinforce-CartPole-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "messham/poca-SoccerTwos0_1",
        "author": "messham",
        "model_name": "poca-SoccerTwos0_1",
        "url": "https://huggingface.co/messham/poca-SoccerTwos0_1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nmessham\n/\npoca-SoccerTwos0_1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nunity-ml-agents\n\ndeep-reinforcement-learning\n\nML-Agents-SoccerTwos\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\npoca Agent playing SoccerTwos\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\npoca Agent playing SoccerTwos\n\n\n  This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos\nStep 1: Write your model_id: messham/poca-SoccerTwos0_1\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "zoltantensorfow/ppo-LunarLander-v2-e",
        "author": "zoltantensorfow",
        "model_name": "ppo-LunarLander-v2-e",
        "url": "https://huggingface.co/zoltantensorfow/ppo-LunarLander-v2-e",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nzoltantensorfow\n/\nppo-LunarLander-v2-e\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n297.09 +/- 14.29\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "jkorstad/Jk-LunarLander-v2",
        "author": "jkorstad",
        "model_name": "Jk-LunarLander-v2",
        "url": "https://huggingface.co/jkorstad/Jk-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njkorstad\n/\nJk-LunarLander-v2\n\n\n\nlike\n1\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n282 +/- 22.48\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ZyXin/PPO-LunarLander-v2",
        "author": "ZyXin",
        "model_name": "PPO-LunarLander-v2",
        "url": "https://huggingface.co/ZyXin/PPO-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nZyXin\n/\nPPO-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n244.51 +/- 20.63\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "globophobe/poca-SoccerTwos",
        "author": "globophobe",
        "model_name": "poca-SoccerTwos",
        "url": "https://huggingface.co/globophobe/poca-SoccerTwos",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nglobophobe\n/\npoca-SoccerTwos\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nunity-ml-agents\n\ndeep-reinforcement-learning\n\nML-Agents-SoccerTwos\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\npoca Agent playing SoccerTwos\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\npoca Agent playing SoccerTwos\n\n\n  This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos\nStep 1: Write your model_id: globophobe/poca-SoccerTwos\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "culteejen/DQN-default-RoombaAToB-Hardcoded",
        "author": "culteejen",
        "model_name": "DQN-default-RoombaAToB-Hardcoded",
        "url": "https://huggingface.co/culteejen/DQN-default-RoombaAToB-Hardcoded",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nculteejen\n/\nDQN-default-RoombaAToB-Hardcoded\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nRoombaAToB-Hardcoded\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing RoombaAToB-Hardcoded\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing RoombaAToB-Hardcoded\n\n\nThis is a trained model of a DQN agent playing RoombaAToB-Hardcoded\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton RoombaAToB-Hardcoded\nself-reported\n\t\t\t\t\t\t\t\n\n-10.01 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "jimfordlafleur/SnowballTarget",
        "author": "jimfordlafleur",
        "model_name": "SnowballTarget",
        "url": "https://huggingface.co/jimfordlafleur/SnowballTarget",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njimfordlafleur\n/\nSnowballTarget\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: jimfordlafleur/SnowballTarget\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "hussamalafandi/ppo-SnowballTarget",
        "author": "hussamalafandi",
        "model_name": "ppo-SnowballTarget",
        "url": "https://huggingface.co/hussamalafandi/ppo-SnowballTarget",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nhussamalafandi\n/\nppo-SnowballTarget\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: hussamalafandi/ppo-SnowballTarget\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "gr22dy/LunarLander_RLstudy",
        "author": "gr22dy",
        "model_name": "LunarLander_RLstudy",
        "url": "https://huggingface.co/gr22dy/LunarLander_RLstudy",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ngr22dy\n/\nLunarLander_RLstudy\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n252.37 +/- 13.74\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "hussamalafandi/ppo-PyramidsRND",
        "author": "hussamalafandi",
        "model_name": "ppo-PyramidsRND",
        "url": "https://huggingface.co/hussamalafandi/ppo-PyramidsRND",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nhussamalafandi\n/\nppo-PyramidsRND\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: hussamalafandi/ppo-PyramidsRND\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "justinsiow/Reinforce-Cartpole-v1",
        "author": "justinsiow",
        "model_name": "Reinforce-Cartpole-v1",
        "url": "https://huggingface.co/justinsiow/Reinforce-Cartpole-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njustinsiow\n/\nReinforce-Cartpole-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n453.20 +/- 46.48\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ntrant7/Reincorece-CartPole-v1",
        "author": "ntrant7",
        "model_name": "Reincorece-CartPole-v1",
        "url": "https://huggingface.co/ntrant7/Reincorece-CartPole-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nntrant7\n/\nReincorece-CartPole-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "jkorstad/ppo-Huggy",
        "author": "jkorstad",
        "model_name": "ppo-Huggy",
        "url": "https://huggingface.co/jkorstad/ppo-Huggy",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njkorstad\n/\nppo-Huggy\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nHuggy\n\ndeep-reinforcement-learning\n\nML-Agents-Huggy\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Huggy\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Huggy\n\n\n  This is a trained model of a ppo agent playing Huggy using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Huggy\nStep 1: Find your model_id: jkorstad/ppo-Huggy\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month8\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "PabloTa/rl_course_vizdoom_doom_basic",
        "author": "PabloTa",
        "model_name": "rl_course_vizdoom_doom_basic",
        "url": "https://huggingface.co/PabloTa/rl_course_vizdoom_doom_basic",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nPabloTa\n/\nrl_course_vizdoom_doom_basic\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nSample Factory\n\nTensorBoard\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in sample-factory\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\nA(n) APPO model trained on the doom_basic environment.\nThis model was trained using Sample-Factory 2.0: https://github.com/alex-petrenko/sample-factory.\nDocumentation for how to use Sample-Factory can be found at https://www.samplefactory.dev/\n\n\n\n\n\n\t\tDownloading the model\n\t\n\nAfter installing Sample-Factory, download the model with:\npython -m sample_factory.huggingface.load_from_hub -r PabloTa/rl_course_vizdoom_doom_basic\n\n\n\n\n\n\n\t\tUsing the model\n\t\n\nTo run the model after download, use the enjoy script corresponding to this environment:\npython -m .home.melon.PycharmProjects.huggingface.unit8.2.main --algo=APPO --env=doom_basic --train_dir=./train_dir --experiment=rl_course_vizdoom_doom_basic\n\nYou can also upload models to the Hugging Face Hub using the same script with the --push_to_hub flag.\nSee https://www.samplefactory.dev/10-huggingface/huggingface/ for more details\n\n\n\n\n\n\t\tTraining with this model\n\t\n\nTo continue training with this model, use the train script corresponding to this environment:\npython -m .home.melon.PycharmProjects.huggingface.unit8.2.main --algo=APPO --env=doom_basic --train_dir=./train_dir --experiment=rl_course_vizdoom_doom_basic --restart_behavior=resume --train_for_env_steps=10000000000\n\nNote, you may have to adjust --train_for_env_steps to a suitably high number as the experiment will resume at the number of steps it concluded at.\n        \n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton doom_basic\nself-reported\n\t\t\t\t\t\t\t\n\n0.74 +/- 0.10\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "holer/Reinforce-041001",
        "author": "holer",
        "model_name": "Reinforce-041001",
        "url": "https://huggingface.co/holer/Reinforce-041001",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nholer\n/\nReinforce-041001\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "aaaorg/ppo-LunarLander-v2",
        "author": "aaaorg",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/aaaorg/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\naaaorg\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n260.46 +/- 19.19\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "culteejen/PPO-default-RoombaAToB-Hardcoded",
        "author": "culteejen",
        "model_name": "PPO-default-RoombaAToB-Hardcoded",
        "url": "https://huggingface.co/culteejen/PPO-default-RoombaAToB-Hardcoded",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nculteejen\n/\nPPO-default-RoombaAToB-Hardcoded\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nRoombaAToB-Hardcoded\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing RoombaAToB-Hardcoded\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing RoombaAToB-Hardcoded\n\n\nThis is a trained model of a PPO agent playing RoombaAToB-Hardcoded\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton RoombaAToB-Hardcoded\nself-reported\n\t\t\t\t\t\t\t\n\n-101.34 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "dyc-v222/ppo-LunarLander-v2",
        "author": "dyc-v222",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/dyc-v222/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ndyc-v222\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n273.45 +/- 18.14\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "culteejen/PPO-hardcoded-RoombaAToB-Hardcoded",
        "author": "culteejen",
        "model_name": "PPO-hardcoded-RoombaAToB-Hardcoded",
        "url": "https://huggingface.co/culteejen/PPO-hardcoded-RoombaAToB-Hardcoded",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nculteejen\n/\nPPO-hardcoded-RoombaAToB-Hardcoded\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nRoombaAToB-Hardcoded\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing RoombaAToB-Hardcoded\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing RoombaAToB-Hardcoded\n\n\nThis is a trained model of a PPO agent playing RoombaAToB-Hardcoded\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton RoombaAToB-Hardcoded\nself-reported\n\t\t\t\t\t\t\t\n\n-151.11 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "holer/Reinforce-041002",
        "author": "holer",
        "model_name": "Reinforce-041002",
        "url": "https://huggingface.co/holer/Reinforce-041002",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nholer\n/\nReinforce-041002\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n7.30 +/- 6.03\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "sarahpuspdew/DeepRLCourse_Unit1-ppo-LunarLander-v2",
        "author": "sarahpuspdew",
        "model_name": "DeepRLCourse_Unit1-ppo-LunarLander-v2",
        "url": "https://huggingface.co/sarahpuspdew/DeepRLCourse_Unit1-ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nsarahpuspdew\n/\nDeepRLCourse_Unit1-ppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n251.81 +/- 19.19\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "climbingsilver/ppo-LunarLander-v2",
        "author": "climbingsilver",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/climbingsilver/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nclimbingsilver\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n250.41 +/- 32.03\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "chenoi/deepRL2",
        "author": "chenoi",
        "model_name": "deepRL2",
        "url": "https://huggingface.co/chenoi/deepRL2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nchenoi\n/\ndeepRL2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"chenoi/deepRL2\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Ye27/q-FrozenLake-v1-4x4-noSlippery",
        "author": "Ye27",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/Ye27/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nYe27\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\nmodel = load_from_hub(repo_id=\"Ye27/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\nevaluate_agent(env, model[\"max_steps\"], model[\"n_eval_episodes\"], model[\"qtable\"], model[\"eval_seed\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "asubiabre/Reinforce-unit4-pixel-copter",
        "author": "asubiabre",
        "model_name": "Reinforce-unit4-pixel-copter",
        "url": "https://huggingface.co/asubiabre/Reinforce-unit4-pixel-copter",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nasubiabre\n/\nReinforce-unit4-pixel-copter\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n52.30 +/- 31.95\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Ye27/q-Taxi-v3",
        "author": "Ye27",
        "model_name": "q-Taxi-v3",
        "url": "https://huggingface.co/Ye27/q-Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nYe27\n/\nq-Taxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\nmodel = load_from_hub(repo_id=\"Ye27/q-Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\nevaluate_agent(env, model[\"max_steps\"], model[\"n_eval_episodes\"], model[\"qtable\"], model[\"eval_seed\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.52 +/- 2.73\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "sarahpuspdew/DeepRLCourse_BonusUnit1-ppo-Huggy",
        "author": "sarahpuspdew",
        "model_name": "DeepRLCourse_BonusUnit1-ppo-Huggy",
        "url": "https://huggingface.co/sarahpuspdew/DeepRLCourse_BonusUnit1-ppo-Huggy",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nsarahpuspdew\n/\nDeepRLCourse_BonusUnit1-ppo-Huggy\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nHuggy\n\ndeep-reinforcement-learning\n\nML-Agents-Huggy\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Huggy\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Huggy\n\n\n  This is a trained model of a ppo agent playing Huggy using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Huggy\nStep 1: Find your model_id: sarahpuspdew/DeepRLCourse_BonusUnit1-ppo-Huggy\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "cleth/poca-SoccerTwos",
        "author": "cleth",
        "model_name": "poca-SoccerTwos",
        "url": "https://huggingface.co/cleth/poca-SoccerTwos",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ncleth\n/\npoca-SoccerTwos\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nONNX\n\nunity-ml-agents\n\ndeep-reinforcement-learning\n\nML-Agents-SoccerTwos\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\npoca Agent playing SoccerTwos\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\npoca Agent playing SoccerTwos\n\n\n  This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos\nStep 1: Write your model_id: cleth/poca-SoccerTwos\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "frank1991/a2c-AntBulletEnv",
        "author": "frank1991",
        "model_name": "a2c-AntBulletEnv",
        "url": "https://huggingface.co/frank1991/a2c-AntBulletEnv",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nfrank1991\n/\na2c-AntBulletEnv\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n1983.16 +/- 45.58\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "marimurta/rl_course_vizdoom_health_gathering_supreme",
        "author": "marimurta",
        "model_name": "rl_course_vizdoom_health_gathering_supreme",
        "url": "https://huggingface.co/marimurta/rl_course_vizdoom_health_gathering_supreme",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nmarimurta\n/\nrl_course_vizdoom_health_gathering_supreme\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nSample Factory\n\nTensorBoard\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in sample-factory\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\nA(n) APPO model trained on the doom_health_gathering_supreme environment.\nThis model was trained using Sample-Factory 2.0: https://github.com/alex-petrenko/sample-factory.\nDocumentation for how to use Sample-Factory can be found at https://www.samplefactory.dev/\n\n\n\n\n\n\t\tDownloading the model\n\t\n\nAfter installing Sample-Factory, download the model with:\npython -m sample_factory.huggingface.load_from_hub -r marimurta/rl_course_vizdoom_health_gathering_supreme\n\n\n\n\n\n\n\t\tUsing the model\n\t\n\nTo run the model after download, use the enjoy script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme\n\nYou can also upload models to the Hugging Face Hub using the same script with the --push_to_hub flag.\nSee https://www.samplefactory.dev/10-huggingface/huggingface/ for more details\n\n\n\n\n\n\t\tTraining with this model\n\t\n\nTo continue training with this model, use the train script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme --restart_behavior=resume --train_for_env_steps=10000000000\n\nNote, you may have to adjust --train_for_env_steps to a suitably high number as the experiment will resume at the number of steps it concluded at.\n        \n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton doom_health_gathering_supreme\nself-reported\n\t\t\t\t\t\t\t\n\n11.21 +/- 5.12\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ntrant7/Reinforce-Pixelcopter-PLE-v0",
        "author": "ntrant7",
        "model_name": "Reinforce-Pixelcopter-PLE-v0",
        "url": "https://huggingface.co/ntrant7/Reinforce-Pixelcopter-PLE-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nntrant7\n/\nReinforce-Pixelcopter-PLE-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n110.90 +/- 77.25\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "justinsiow/Reinforce-Pixelcopter-PLE-v0",
        "author": "justinsiow",
        "model_name": "Reinforce-Pixelcopter-PLE-v0",
        "url": "https://huggingface.co/justinsiow/Reinforce-Pixelcopter-PLE-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njustinsiow\n/\nReinforce-Pixelcopter-PLE-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n21.40 +/- 19.42\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "climbingsilver/q-FrozenLake-v1-4x4-noSlippery",
        "author": "climbingsilver",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/climbingsilver/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nclimbingsilver\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"climbingsilver/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "xgas/ppo-LunarLander-v2",
        "author": "xgas",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/xgas/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nxgas\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n268.20 +/- 14.01\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "tvnguyen/Reinforce-Pixelcopter-PLE-v0",
        "author": "tvnguyen",
        "model_name": "Reinforce-Pixelcopter-PLE-v0",
        "url": "https://huggingface.co/tvnguyen/Reinforce-Pixelcopter-PLE-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ntvnguyen\n/\nReinforce-Pixelcopter-PLE-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n16.80 +/- 9.55\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "climbingsilver/Taxi-v3",
        "author": "climbingsilver",
        "model_name": "Taxi-v3",
        "url": "https://huggingface.co/climbingsilver/Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nclimbingsilver\n/\nTaxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"climbingsilver/Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.52 +/- 2.72\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ManishW/a2c-AntBulletEnv-v0",
        "author": "ManishW",
        "model_name": "a2c-AntBulletEnv-v0",
        "url": "https://huggingface.co/ManishW/a2c-AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nManishW\n/\na2c-AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n1010.09 +/- 189.32\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Eselroth/q-FrozenLake-v1-4x4-noSlippery",
        "author": "Eselroth",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/Eselroth/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nEselroth\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Eselroth/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Eselroth/CrazyTaxi",
        "author": "Eselroth",
        "model_name": "CrazyTaxi",
        "url": "https://huggingface.co/Eselroth/CrazyTaxi",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nEselroth\n/\nCrazyTaxi\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Eselroth/CrazyTaxi\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ManishW/a2c-PandaReachDense-v2",
        "author": "ManishW",
        "model_name": "a2c-PandaReachDense-v2",
        "url": "https://huggingface.co/ManishW/a2c-PandaReachDense-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nManishW\n/\na2c-PandaReachDense-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nPandaReachDense-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing PandaReachDense-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing PandaReachDense-v2\n\n\nThis is a trained model of a A2C agent playing PandaReachDense-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton PandaReachDense-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-0.48 +/- 0.23\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "keremnayman/lunarlander-deneme",
        "author": "keremnayman",
        "model_name": "lunarlander-deneme",
        "url": "https://huggingface.co/keremnayman/lunarlander-deneme",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nkeremnayman\n/\nlunarlander-deneme\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n241.81 +/- 21.46\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "vincentmin/opt-125m-eli5-rl-finetune-128-8-8-1.4e-5_ada",
        "author": "vincentmin",
        "model_name": "opt-125m-eli5-rl-finetune-128-8-8-1.4e-5_ada",
        "url": "https://huggingface.co/vincentmin/opt-125m-eli5-rl-finetune-128-8-8-1.4e-5_ada",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nvincentmin\n/\nopt-125m-eli5-rl-finetune-128-8-8-1.4e-5_ada\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTransformers\n\nPyTorch\n\ntrl\n\nInference Endpoints\n\n\n\nLicense: \napache-2.0\n\n\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\t\t\tTrain\n\t\t\n\n\n\n\n\n\t\t\tDeploy\n\t\t\n\n\n\n\t\tUse in Transformers\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nTRL Model\nUsage\n\n\n\n\n\n\n\n\n\n\n\t\tTRL Model\n\t\n\nThis is a TRL language model that has been fine-tuned with reinforcement learning to\n guide the model outputs according to a value, function, or human feedback. The model can be used for text generation.\n\n\n\n\n\n\t\tUsage\n\t\n\nTo use this model for inference, first install the TRL library:\npython -m pip install trl\n\nYou can then generate text as follows:\nfrom transformers import pipeline\n\ngenerator = pipeline(\"text-generation\", model=\"vincentmin//tmp/tmp_mpm7q96/vincentmin/opt-125m-eli5-rl-finetune-128-8-8-1.4e-5_ada\")\noutputs = generator(\"Hello, my llama is cute\")\n\nIf you want to use the model for training or to obtain the outputs from the value head, load the model as follows:\nfrom transformers import AutoTokenizer\nfrom trl import AutoModelForCausalLMWithValueHead\n\ntokenizer = AutoTokenizer.from_pretrained(\"vincentmin//tmp/tmp_mpm7q96/vincentmin/opt-125m-eli5-rl-finetune-128-8-8-1.4e-5_ada\")\nmodel = AutoModelForCausalLMWithValueHead.from_pretrained(\"vincentmin//tmp/tmp_mpm7q96/vincentmin/opt-125m-eli5-rl-finetune-128-8-8-1.4e-5_ada\")\n\ninputs = tokenizer(\"Hello, my llama is cute\", return_tensors=\"pt\")\noutputs = model(**inputs, labels=inputs[\"input_ids\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "irgallard/q-FrozenLake-v1-4x4-noSlippery",
        "author": "irgallard",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/irgallard/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nirgallard\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"irgallard/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "irgallard/taxi-v3",
        "author": "irgallard",
        "model_name": "taxi-v3",
        "url": "https://huggingface.co/irgallard/taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nirgallard\n/\ntaxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"irgallard/taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.50 +/- 2.75\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "chenoi/deepRL3",
        "author": "chenoi",
        "model_name": "deepRL3",
        "url": "https://huggingface.co/chenoi/deepRL3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nchenoi\n/\ndeepRL3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga chenoi -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga chenoi -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga chenoi\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 1000000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n681.50 +/- 314.29\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "carolinainmymind/ppo-SnowballTarget",
        "author": "carolinainmymind",
        "model_name": "ppo-SnowballTarget",
        "url": "https://huggingface.co/carolinainmymind/ppo-SnowballTarget",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ncarolinainmymind\n/\nppo-SnowballTarget\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: carolinainmymind/ppo-SnowballTarget\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Nasree/poca-SoccerTwos",
        "author": "Nasree",
        "model_name": "poca-SoccerTwos",
        "url": "https://huggingface.co/Nasree/poca-SoccerTwos",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nNasree\n/\npoca-SoccerTwos\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nunity-ml-agents\n\ndeep-reinforcement-learning\n\nML-Agents-SoccerTwos\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\npoca Agent playing SoccerTwos\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\npoca Agent playing SoccerTwos\n\n\n  This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos\nStep 1: Write your model_id: Nasree/poca-SoccerTwos\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "MarshallPF/ppo-SnowballTarget",
        "author": "MarshallPF",
        "model_name": "ppo-SnowballTarget",
        "url": "https://huggingface.co/MarshallPF/ppo-SnowballTarget",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nMarshallPF\n/\nppo-SnowballTarget\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: MarshallPF/ppo-SnowballTarget\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "justinsiow/Reinforce-Pixelcopter-PLE-v0-v2",
        "author": "justinsiow",
        "model_name": "Reinforce-Pixelcopter-PLE-v0-v2",
        "url": "https://huggingface.co/justinsiow/Reinforce-Pixelcopter-PLE-v0-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njustinsiow\n/\nReinforce-Pixelcopter-PLE-v0-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n64.00 +/- 53.86\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "vldnechai/q-FrozenLake-v1-4x4-noSlippery",
        "author": "vldnechai",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/vldnechai/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nvldnechai\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"vldnechai/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "vldnechai/q-taxi-v3",
        "author": "vldnechai",
        "model_name": "q-taxi-v3",
        "url": "https://huggingface.co/vldnechai/q-taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nvldnechai\n/\nq-taxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"vldnechai/q-taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "helpingstar/ppo-CartPole-v2",
        "author": "helpingstar",
        "model_name": "ppo-CartPole-v2",
        "url": "https://huggingface.co/helpingstar/ppo-CartPole-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nhelpingstar\n/\nppo-CartPole-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTensorBoard\n\nLunarLander-v2\n\nppo\n\ndeep-reinforcement-learning\n\ncustom-implementation\n\ndeep-rl-course\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent Playing LunarLander-v2\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\t\tPPO Agent Playing LunarLander-v2\n\t\n\n  This is a trained model of a PPO agent playing LunarLander-v2.\n\n\n\n\n\n\t\tHyperparameters\n\t\n\n{'exp_name': 'ppo'\n'seed': 1\n'torch_deterministic': True\n'cuda': True\n'track': False\n'wandb_project_name': 'cleanRL'\n'wandb_entity': None\n'capture_video': False\n'env_id': 'LunarLander-v2'\n'total_timesteps': 50000\n'learning_rate': 0.00025\n'num_envs': 4\n'num_steps': 128\n'anneal_lr': True\n'gae': True\n'gamma': 0.99\n'gae_lambda': 0.95\n'num_minibatches': 4\n'update_epochs': 4\n'norm_adv': True\n'clip_coef': 0.2\n'clip_vloss': True\n'ent_coef': 0.01\n'vf_coef': 0.5\n'max_grad_norm': 0.5\n'target_kl': None\n'repo_id': 'helpingstar/ppo-CartPole-v2'\n'batch_size': 512\n'minibatch_size': 128}\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-175.44 +/- 68.55\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "justinsiow/ppo-SnowballTarget",
        "author": "justinsiow",
        "model_name": "ppo-SnowballTarget",
        "url": "https://huggingface.co/justinsiow/ppo-SnowballTarget",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njustinsiow\n/\nppo-SnowballTarget\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: justinsiow/ppo-SnowballTarget\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "carolinainmymind/Pyramids",
        "author": "carolinainmymind",
        "model_name": "Pyramids",
        "url": "https://huggingface.co/carolinainmymind/Pyramids",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ncarolinainmymind\n/\nPyramids\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: carolinainmymind/Pyramids\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "jmurphy97/q-FrozenLake-v1-4x4-noSlippery",
        "author": "jmurphy97",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/jmurphy97/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njmurphy97\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\n# **Q-Learning** Agent playing1 **FrozenLake-v1**\nThis is a trained model of a **Q-Learning** agent playing **FrozenLake-v1** .\n\n## Usage\n\n```python\n\nmodel = load_from_hub(repo_id=\"jmurphy97/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n```\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "helpingstar/ppo-LunarLander-v1",
        "author": "helpingstar",
        "model_name": "ppo-LunarLander-v1",
        "url": "https://huggingface.co/helpingstar/ppo-LunarLander-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nhelpingstar\n/\nppo-LunarLander-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTensorBoard\n\nLunarLander-v2\n\nppo\n\ndeep-reinforcement-learning\n\ncustom-implementation\n\ndeep-rl-course\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent Playing LunarLander-v2\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\t\tPPO Agent Playing LunarLander-v2\n\t\n\n  This is a trained model of a PPO agent playing LunarLander-v2.\n\n\n\n\n\n\t\tHyperparameters\n\t\n\n{'exp_name': 'ppo'\n'seed': 1\n'torch_deterministic': True\n'cuda': True\n'track': False\n'wandb_project_name': 'cleanRL'\n'wandb_entity': None\n'capture_video': False\n'env_id': 'LunarLander-v2'\n'total_timesteps': 1000000\n'learning_rate': 0.00025\n'num_envs': 4\n'num_steps': 128\n'anneal_lr': True\n'gae': True\n'gamma': 0.99\n'gae_lambda': 0.95\n'num_minibatches': 4\n'update_epochs': 4\n'norm_adv': True\n'clip_coef': 0.2\n'clip_vloss': True\n'ent_coef': 0.01\n'vf_coef': 0.5\n'max_grad_norm': 0.5\n'target_kl': None\n'repo_id': 'helpingstar/ppo-LunarLander-v1'\n'batch_size': 512\n'minibatch_size': 128}\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-83.97 +/- 83.48\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "justinsiow/PyramdisRND",
        "author": "justinsiow",
        "model_name": "PyramdisRND",
        "url": "https://huggingface.co/justinsiow/PyramdisRND",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njustinsiow\n/\nPyramdisRND\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: justinsiow/PyramdisRND\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "jmurphy97/q-Taxi-v3",
        "author": "jmurphy97",
        "model_name": "q-Taxi-v3",
        "url": "https://huggingface.co/jmurphy97/q-Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njmurphy97\n/\nq-Taxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\n# **Q-Learning** Agent playing1 **Taxi-v3**\nThis is a trained model of a **Q-Learning** agent playing **Taxi-v3** .\n\n## Usage\n\n```python\n\nmodel = load_from_hub(repo_id=\"jmurphy97/q-Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n```\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.52 +/- 2.73\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Agog/BASE",
        "author": "Agog",
        "model_name": "BASE",
        "url": "https://huggingface.co/Agog/BASE",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nAgog\n/\nBASE\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nunity-ml-agents\n\ndeep-reinforcement-learning\n\nML-Agents-SoccerTwos\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\npoca Agent playing SoccerTwos\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\npoca Agent playing SoccerTwos\n\n\n  This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos\nStep 1: Write your model_id: Agog/BASE\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month24\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "giggling-squid/poca-SoccerTwos",
        "author": "giggling-squid",
        "model_name": "poca-SoccerTwos",
        "url": "https://huggingface.co/giggling-squid/poca-SoccerTwos",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ngiggling-squid\n/\npoca-SoccerTwos\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSoccerTwos\n\ndeep-reinforcement-learning\n\nML-Agents-SoccerTwos\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\npoca Agent playing SoccerTwos\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\npoca Agent playing SoccerTwos\n\n\n  This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos\nStep 1: Find your model_id: giggling-squid/poca-SoccerTwos\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "helpingstar/rl_course_vizdoom_health_gathering_supreme",
        "author": "helpingstar",
        "model_name": "rl_course_vizdoom_health_gathering_supreme",
        "url": "https://huggingface.co/helpingstar/rl_course_vizdoom_health_gathering_supreme",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nhelpingstar\n/\nrl_course_vizdoom_health_gathering_supreme\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nSample Factory\n\nTensorBoard\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in sample-factory\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\nA(n) APPO model trained on the doom_health_gathering_supreme environment.\nThis model was trained using Sample-Factory 2.0: https://github.com/alex-petrenko/sample-factory.\nDocumentation for how to use Sample-Factory can be found at https://www.samplefactory.dev/\n\n\n\n\n\n\t\tDownloading the model\n\t\n\nAfter installing Sample-Factory, download the model with:\npython -m sample_factory.huggingface.load_from_hub -r helpingstar/rl_course_vizdoom_health_gathering_supreme\n\n\n\n\n\n\n\t\tUsing the model\n\t\n\nTo run the model after download, use the enjoy script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme\n\nYou can also upload models to the Hugging Face Hub using the same script with the --push_to_hub flag.\nSee https://www.samplefactory.dev/10-huggingface/huggingface/ for more details\n\n\n\n\n\n\t\tTraining with this model\n\t\n\nTo continue training with this model, use the train script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme --restart_behavior=resume --train_for_env_steps=10000000000\n\nNote, you may have to adjust --train_for_env_steps to a suitably high number as the experiment will resume at the number of steps it concluded at.\n        \n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton doom_health_gathering_supreme\nself-reported\n\t\t\t\t\t\t\t\n\n6.92 +/- 1.54\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "MarshallPF/pyramid-find",
        "author": "MarshallPF",
        "model_name": "pyramid-find",
        "url": "https://huggingface.co/MarshallPF/pyramid-find",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nMarshallPF\n/\npyramid-find\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: MarshallPF/pyramid-find\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "chenoi/deepRL4-1",
        "author": "chenoi",
        "model_name": "deepRL4-1",
        "url": "https://huggingface.co/chenoi/deepRL4-1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nchenoi\n/\ndeepRL4-1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Smone55/ppo-LunarLander-v2",
        "author": "Smone55",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/Smone55/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nSmone55\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n266.62 +/- 19.91\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "osman93/poca-SoccerTwos",
        "author": "osman93",
        "model_name": "poca-SoccerTwos",
        "url": "https://huggingface.co/osman93/poca-SoccerTwos",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nosman93\n/\npoca-SoccerTwos\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nunity-ml-agents\n\ndeep-reinforcement-learning\n\nML-Agents-SoccerTwos\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\npoca Agent playing SoccerTwos\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\npoca Agent playing SoccerTwos\n\n\n  This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos\nStep 1: Write your model_id: osman93/poca-SoccerTwos\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "tommytran/Reinforce-v1",
        "author": "tommytran",
        "model_name": "Reinforce-v1",
        "url": "https://huggingface.co/tommytran/Reinforce-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ntommytran\n/\nReinforce-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "vldnechai/dqn-SpaceInvadersNoFrameskip-v4",
        "author": "vldnechai",
        "model_name": "dqn-SpaceInvadersNoFrameskip-v4",
        "url": "https://huggingface.co/vldnechai/dqn-SpaceInvadersNoFrameskip-v4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nvldnechai\n/\ndqn-SpaceInvadersNoFrameskip-v4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga vldnechai -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga vldnechai -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga vldnechai\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 64),\n             ('buffer_size', 50000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 1500000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n578.00 +/- 165.14\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "yenniejun/q-FrozenLake-v1-4x4-noSlippery",
        "author": "yenniejun",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/yenniejun/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nyenniejun\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"yenniejun/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4\nself-reported\n\t\t\t\t\t\t\t\n\n0.46 +/- 0.50\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "sgoodfriend/ppo-unet-MicrortsDefeatCoacAIShaped-v3-diverseBots",
        "author": "sgoodfriend",
        "model_name": "ppo-unet-MicrortsDefeatCoacAIShaped-v3-diverseBots",
        "url": "https://huggingface.co/sgoodfriend/ppo-unet-MicrortsDefeatCoacAIShaped-v3-diverseBots",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nsgoodfriend\n/\nppo-unet-MicrortsDefeatCoacAIShaped-v3-diverseBots\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nrl-algo-impls\n\nMicrortsDefeatCoacAIShaped-v3\n\nppo\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing MicrortsDefeatCoacAIShaped-v3\nTraining Results\nPrerequisites: Weights & Biases (WandB)\n\nUsage\n\nTraining\n\nBenchmarking (with Lambda Labs instance)\nAlternative: Google Colab Pro+\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing MicrortsDefeatCoacAIShaped-v3\n\n\nThis is a trained model of a PPO agent playing MicrortsDefeatCoacAIShaped-v3 using the /sgoodfriend/rl-algo-impls repo.\nAll models trained at this commit can be found at https://api.wandb.ai/links/sgoodfriend/j6e39wms.\n\n\n\n\n\n\t\tTraining Results\n\t\n\nThis model was trained from 3 trainings of PPO agents using different initial seeds. These agents were trained by checking out 1c95957. The best and last models were kept from each training. This submission has loaded the best models from each training, reevaluates them, and selects the best model from these latest evaluations (mean - std).\n\n\n\nalgo\nenv\nseed\nreward_mean\nreward_std\neval_episodes\nbest\nwandb_url\n\n\nppo\nMicrortsDefeatCoacAIShaped-v3\n1\n176.25\n29.7719\n24\n\nwandb\n\n\nppo\nMicrortsDefeatCoacAIShaped-v3\n2\n185.45\n30.5944\n24\n*\nwandb\n\n\nppo\nMicrortsDefeatCoacAIShaped-v3\n3\n174.367\n21.155\n24\n\nwandb\n\n\n\n\n\n\n\n\n\n\t\tPrerequisites: Weights & Biases (WandB)\n\t\n\nTraining and benchmarking assumes you have a Weights & Biases project to upload runs to.\nBy default training goes to a rl-algo-impls project while benchmarks go to\nrl-algo-impls-benchmarks. During training and benchmarking runs, videos of the best\nmodels and the model weights are uploaded to WandB.\nBefore doing anything below, you'll need to create a wandb account and run wandb login.\n\n\n\n\n\n\t\tUsage\n\t\n\n/sgoodfriend/rl-algo-impls: https://github.com/sgoodfriend/rl-algo-impls\nNote: While the model state dictionary and hyperaparameters are saved, the latest\nimplementation could be sufficiently different to not be able to reproduce similar\nresults. You might need to checkout the commit the agent was trained on:\n1c95957.\n# Downloads the model, sets hyperparameters, and runs agent for 3 episodes\npython enjoy.py --wandb-run-path=sgoodfriend/rl-algo-impls-benchmarks/hambvua5\n\nSetup hasn't been completely worked out yet, so you might be best served by using Google\nColab starting from the\ncolab_enjoy.ipynb\nnotebook.\n\n\n\n\n\n\t\tTraining\n\t\n\nIf you want the highest chance to reproduce these results, you'll want to checkout the\ncommit the agent was trained on: 1c95957. While\ntraining is deterministic, different hardware will give different results.\npython train.py --algo ppo --env MicrortsDefeatCoacAIShaped-v3 --seed 2\n\nSetup hasn't been completely worked out yet, so you might be best served by using Google\nColab starting from the\ncolab_train.ipynb\nnotebook.\n\n\n\n\n\n\t\tBenchmarking (with Lambda Labs instance)\n\t\n\nThis and other models from https://api.wandb.ai/links/sgoodfriend/j6e39wms were generated by running a script on a Lambda\nLabs instance. In a Lambda Labs instance terminal:\ngit clone git@github.com:sgoodfriend/rl-algo-impls.git\ncd rl-algo-impls\nbash ./lambda_labs/setup.sh\nwandb login\nbash ./lambda_labs/benchmark.sh [-a {\"ppo a2c dqn vpg\"}] [-e ENVS] [-j {6}] [-p {rl-algo-impls-benchmarks}] [-s {\"1 2 3\"}]\n\n\n\n\n\n\n\t\tAlternative: Google Colab Pro+\n\t\n\nAs an alternative,\ncolab_benchmark.ipynb,\ncan be used. However, this requires a Google Colab Pro+ subscription and running across\n4 separate instances because otherwise running all jobs will exceed the 24-hour limit.\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nThis isn't exactly the format of hyperparams in hyperparams/ppo.yml, but instead the Wandb Run Config. However, it's very\nclose and has some additional data:\nadditional_keys_to_log:\n- microrts_stats\nalgo: ppo\nalgo_hyperparams:\n  batch_size: 3072\n  clip_range: 0.1\n  clip_range_decay: none\n  clip_range_vf: 0.1\n  ent_coef: 0.01\n  learning_rate: 0.00025\n  learning_rate_decay: spike\n  max_grad_norm: 0.5\n  n_epochs: 4\n  n_steps: 512\n  ppo2_vf_coef_halving: true\n  vf_coef: 0.5\ndevice: auto\nenv: unet-MicrortsDefeatCoacAIShaped-v3-diverseBots\nenv_hyperparams:\n  bots:\n    coacAI: 18\n    lightRushAI: 2\n    randomBiasedAI: 2\n    workerRushAI: 2\n  env_type: microrts\n  make_kwargs:\n    map_path: maps/16x16/basesWorkers16x16.xml\n    max_steps: 2000\n    num_selfplay_envs: 0\n    render_theme: 2\n    reward_weight:\n    - 10\n    - 1\n    - 1\n    - 0.2\n    - 1\n    - 4\n  n_envs: 24\nenv_id: MicrortsDefeatCoacAIShaped-v3\neval_params:\n  deterministic: false\nn_timesteps: 300000000\npolicy_hyperparams:\n  activation_fn: relu\n  actor_head_style: unet\n  cnn_flatten_dim: 256\n  cnn_style: microrts\n  v_hidden_sizes:\n  - 256\n  - 128\nseed: 2\nuse_deterministic_algorithms: true\nwandb_entity: null\nwandb_group: null\nwandb_project_name: rl-algo-impls-benchmarks\nwandb_tags:\n- benchmark_1c95957\n- host_129-159-37-196\n- branch_unet\n- v0.0.8\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton MicrortsDefeatCoacAIShaped-v3\nself-reported\n\t\t\t\t\t\t\t\n\n185.45 +/- 30.59\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "tommytran/pixelcopter_v1",
        "author": "tommytran",
        "model_name": "pixelcopter_v1",
        "url": "https://huggingface.co/tommytran/pixelcopter_v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ntommytran\n/\npixelcopter_v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n23.00 +/- 16.37\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "yenniejun/q-Taxi-v3",
        "author": "yenniejun",
        "model_name": "q-Taxi-v3",
        "url": "https://huggingface.co/yenniejun/q-Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nyenniejun\n/\nq-Taxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"yenniejun/q-Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.48 +/- 2.77\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "tommytran/ppo-SnowballTarget",
        "author": "tommytran",
        "model_name": "ppo-SnowballTarget",
        "url": "https://huggingface.co/tommytran/ppo-SnowballTarget",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ntommytran\n/\nppo-SnowballTarget\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: tommytran/ppo-SnowballTarget\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Mihail-P/dqn-SpaceInvadersNoFrameskip-v4",
        "author": "Mihail-P",
        "model_name": "dqn-SpaceInvadersNoFrameskip-v4",
        "url": "https://huggingface.co/Mihail-P/dqn-SpaceInvadersNoFrameskip-v4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nMihail-P\n/\ndqn-SpaceInvadersNoFrameskip-v4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga Mihail-P -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga Mihail-P -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga Mihail-P\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 10000000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n441.50 +/- 89.78\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Mihail-P/dqn-SpaceInvadersNoFrameskip-v4_2",
        "author": "Mihail-P",
        "model_name": "dqn-SpaceInvadersNoFrameskip-v4_2",
        "url": "https://huggingface.co/Mihail-P/dqn-SpaceInvadersNoFrameskip-v4_2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nMihail-P\n/\ndqn-SpaceInvadersNoFrameskip-v4_2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga Mihail-P -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga Mihail-P -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga Mihail-P\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 10000000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n684.00 +/- 220.63\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Flooow/ppo-Huggy",
        "author": "Flooow",
        "model_name": "ppo-Huggy",
        "url": "https://huggingface.co/Flooow/ppo-Huggy",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nFlooow\n/\nppo-Huggy\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nHuggy\n\ndeep-reinforcement-learning\n\nML-Agents-Huggy\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Huggy\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Huggy\n\n\n  This is a trained model of a ppo agent playing Huggy using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/ThomasSimonini/Huggy\nStep 1: Find your model_id: Flooow/ppo-Huggy\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "MarshallPF/a2c-AntBulletEnv-v0",
        "author": "MarshallPF",
        "model_name": "a2c-AntBulletEnv-v0",
        "url": "https://huggingface.co/MarshallPF/a2c-AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nMarshallPF\n/\na2c-AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n1495.39 +/- 78.25\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Kimonode/q-FrozenLake-v1-4x4-noSlippery",
        "author": "Kimonode",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/Kimonode/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nKimonode\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Kimonode/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Kimonode/Taxi-v3",
        "author": "Kimonode",
        "model_name": "Taxi-v3",
        "url": "https://huggingface.co/Kimonode/Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nKimonode\n/\nTaxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Kimonode/Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Flooow/q-FrozenLake-v1-4x4-noSlippery",
        "author": "Flooow",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/Flooow/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nFlooow\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Flooow/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Flooow/q-Taxi-v3",
        "author": "Flooow",
        "model_name": "q-Taxi-v3",
        "url": "https://huggingface.co/Flooow/q-Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nFlooow\n/\nq-Taxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Flooow/q-Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "podolskipio/RL_1",
        "author": "podolskipio",
        "model_name": "RL_1",
        "url": "https://huggingface.co/podolskipio/RL_1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\npodolskipio\n/\nRL_1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n282.01 +/- 19.59\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "alkiskoudounas/ppo-LunarLander-v1",
        "author": "alkiskoudounas",
        "model_name": "ppo-LunarLander-v1",
        "url": "https://huggingface.co/alkiskoudounas/ppo-LunarLander-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nalkiskoudounas\n/\nppo-LunarLander-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTensorBoard\n\nLunarLander-v2\n\nppo\n\ndeep-reinforcement-learning\n\ncustom-implementation\n\ndeep-rl-course\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent Playing LunarLander-v2\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\t\tPPO Agent Playing LunarLander-v2\n\t\n\n  This is a trained model of a PPO agent playing LunarLander-v2.\n\n\n\n\n\n\t\tHyperparameters\n\t\n\n{'exp_name': 'ppo'\n'seed': 1\n'torch_deterministic': True\n'cuda': True\n'track': False\n'wandb_project_name': 'cleanRL'\n'wandb_entity': None\n'capture_video': False\n'env_id': 'LunarLander-v2'\n'total_timesteps': 500000\n'learning_rate': 0.00025\n'num_envs': 4\n'num_steps': 128\n'anneal_lr': True\n'gae': True\n'gamma': 0.99\n'gae_lambda': 0.95\n'num_minibatches': 4\n'update_epochs': 4\n'norm_adv': True\n'clip_coef': 0.2\n'clip_vloss': True\n'ent_coef': 0.01\n'vf_coef': 0.5\n'max_grad_norm': 0.5\n'target_kl': None\n'repo_id': 'alkiskoudounas/ppo-LunarLander-v1'\n'batch_size': 512\n'minibatch_size': 128}\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n43.80 +/- 74.90\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "AMI0x/q-FrozenLake-v1-4x4-noSlippery",
        "author": "AMI0x",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/AMI0x/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nAMI0x\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"AMI0x/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "tommytran/pyramids-v2",
        "author": "tommytran",
        "model_name": "pyramids-v2",
        "url": "https://huggingface.co/tommytran/pyramids-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ntommytran\n/\npyramids-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: tommytran/pyramids-v2\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ankandrew/rl_course_vizdoom_health_gathering_supreme",
        "author": "ankandrew",
        "model_name": "rl_course_vizdoom_health_gathering_supreme",
        "url": "https://huggingface.co/ankandrew/rl_course_vizdoom_health_gathering_supreme",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nankandrew\n/\nrl_course_vizdoom_health_gathering_supreme\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nSample Factory\n\nTensorBoard\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in sample-factory\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\nA(n) APPO model trained on the doom_health_gathering_supreme environment.\nThis model was trained using Sample-Factory 2.0: https://github.com/alex-petrenko/sample-factory.\nDocumentation for how to use Sample-Factory can be found at https://www.samplefactory.dev/\n\n\n\n\n\n\t\tDownloading the model\n\t\n\nAfter installing Sample-Factory, download the model with:\npython -m sample_factory.huggingface.load_from_hub -r ankandrew/rl_course_vizdoom_health_gathering_supreme\n\n\n\n\n\n\n\t\tUsing the model\n\t\n\nTo run the model after download, use the enjoy script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme\n\nYou can also upload models to the Hugging Face Hub using the same script with the --push_to_hub flag.\nSee https://www.samplefactory.dev/10-huggingface/huggingface/ for more details\n\n\n\n\n\n\t\tTraining with this model\n\t\n\nTo continue training with this model, use the train script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme --restart_behavior=resume --train_for_env_steps=10000000000\n\nNote, you may have to adjust --train_for_env_steps to a suitably high number as the experiment will resume at the number of steps it concluded at.\n        \n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton doom_health_gathering_supreme\nself-reported\n\t\t\t\t\t\t\t\n\n10.54 +/- 4.84\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "vahee/ppo-Huggy",
        "author": "vahee",
        "model_name": "ppo-Huggy",
        "url": "https://huggingface.co/vahee/ppo-Huggy",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nvahee\n/\nppo-Huggy\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nHuggy\n\ndeep-reinforcement-learning\n\nML-Agents-Huggy\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Huggy\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Huggy\n\n\n  This is a trained model of a ppo agent playing Huggy using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Huggy\nStep 1: Find your model_id: vahee/ppo-Huggy\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month16\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ormenesse/ppo-LunarLander-v2-tutorial",
        "author": "ormenesse",
        "model_name": "ppo-LunarLander-v2-tutorial",
        "url": "https://huggingface.co/ormenesse/ppo-LunarLander-v2-tutorial",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\normenesse\n/\nppo-LunarLander-v2-tutorial\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n250.89 +/- 35.23\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "jkorstad/q-FrozenLake-v1-4x4-noSlippery",
        "author": "jkorstad",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/jkorstad/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njkorstad\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"jkorstad/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "verderis/a2c-anagna-v1",
        "author": "verderis",
        "model_name": "a2c-anagna-v1",
        "url": "https://huggingface.co/verderis/a2c-anagna-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nverderis\n/\na2c-anagna-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n1873.06 +/- 108.61\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "jkorstad/Taxi-JPK-v3",
        "author": "jkorstad",
        "model_name": "Taxi-JPK-v3",
        "url": "https://huggingface.co/jkorstad/Taxi-JPK-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njkorstad\n/\nTaxi-JPK-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"jkorstad/Taxi-JPK-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "jmurphy97/dqn-SpaceInvadersNoFrameskip-v4",
        "author": "jmurphy97",
        "model_name": "dqn-SpaceInvadersNoFrameskip-v4",
        "url": "https://huggingface.co/jmurphy97/dqn-SpaceInvadersNoFrameskip-v4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njmurphy97\n/\ndqn-SpaceInvadersNoFrameskip-v4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga jmurphy97 -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga jmurphy97 -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga jmurphy97\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 1000000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n659.00 +/- 313.02\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "hawkeoni/lunar_laner_unit_1",
        "author": "hawkeoni",
        "model_name": "lunar_laner_unit_1",
        "url": "https://huggingface.co/hawkeoni/lunar_laner_unit_1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nhawkeoni\n/\nlunar_laner_unit_1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n242.80 +/- 39.81\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Yanrds/ppo-Huggy",
        "author": "Yanrds",
        "model_name": "ppo-Huggy",
        "url": "https://huggingface.co/Yanrds/ppo-Huggy",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nYanrds\n/\nppo-Huggy\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nHuggy\n\ndeep-reinforcement-learning\n\nML-Agents-Huggy\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Huggy\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Huggy\n\n\n  This is a trained model of a ppo agent playing Huggy using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Huggy\nStep 1: Find your model_id: Yanrds/ppo-Huggy\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "thackerhelik/ppo-LunarLander-v2",
        "author": "thackerhelik",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/thackerhelik/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nthackerhelik\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n265.88 +/- 22.12\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "torreygooch/PPO-LunarLander-V2",
        "author": "torreygooch",
        "model_name": "PPO-LunarLander-V2",
        "url": "https://huggingface.co/torreygooch/PPO-LunarLander-V2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ntorreygooch\n/\nPPO-LunarLander-V2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-114.11 +/- 77.19\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "amannlp/Reinforce-1",
        "author": "amannlp",
        "model_name": "Reinforce-1",
        "url": "https://huggingface.co/amannlp/Reinforce-1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\namannlp\n/\nReinforce-1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Ytia1010/q-FrozenLake-v1-4x4-noSlippery",
        "author": "Ytia1010",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/Ytia1010/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nYtia1010\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"ytia1010/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "alexdavey/a2c-AntBulletEnv-v0",
        "author": "alexdavey",
        "model_name": "a2c-AntBulletEnv-v0",
        "url": "https://huggingface.co/alexdavey/a2c-AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nalexdavey\n/\na2c-AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n1100.75 +/- 214.86\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "alexdavey/a2c-PandaReachDense-v2",
        "author": "alexdavey",
        "model_name": "a2c-PandaReachDense-v2",
        "url": "https://huggingface.co/alexdavey/a2c-PandaReachDense-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nalexdavey\n/\na2c-PandaReachDense-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nPandaReachDense-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\n\narxiv:\n2106.13687\n\n\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing PandaReachDense-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing PandaReachDense-v2\n\n\nThis is a trained model of a A2C agent playing PandaReachDense-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\nPanda Gym environments: arxiv.org/abs/2106.13687\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton PandaReachDense-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-2.01 +/- 0.43\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "globophobe/ppo-CleanRL-LunarLander-v2",
        "author": "globophobe",
        "model_name": "ppo-CleanRL-LunarLander-v2",
        "url": "https://huggingface.co/globophobe/ppo-CleanRL-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nglobophobe\n/\nppo-CleanRL-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTensorBoard\n\nLunarLander-v2\n\nppo\n\ndeep-reinforcement-learning\n\ncustom-implementation\n\ndeep-rl-course\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent Playing LunarLander-v2\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\t\tPPO Agent Playing LunarLander-v2\n\t\n\n  This is a trained model of a PPO agent playing LunarLander-v2.\n\n\n\n\n\n\t\tHyperparameters\n\t\n\n{'exp_name': 'ppo'\n'seed': 1\n'torch_deterministic': True\n'cuda': True\n'track': False\n'wandb_project_name': 'cleanRL'\n'wandb_entity': None\n'capture_video': False\n'env_id': 'LunarLander-v2'\n'total_timesteps': 1000000\n'learning_rate': 0.00025\n'num_envs': 4\n'num_steps': 128\n'anneal_lr': True\n'gae': True\n'gamma': 0.99\n'gae_lambda': 0.95\n'num_minibatches': 4\n'update_epochs': 4\n'norm_adv': True\n'clip_coef': 0.2\n'clip_vloss': True\n'ent_coef': 0.01\n'vf_coef': 0.5\n'max_grad_norm': 0.5\n'target_kl': None\n'repo_id': 'globophobe/ppo-CleanRL-LunarLander-v2'\n'batch_size': 512\n'minibatch_size': 128}\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n12.86 +/- 112.08\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "justinsiow/a2c-AntBulletEnv-v0",
        "author": "justinsiow",
        "model_name": "a2c-AntBulletEnv-v0",
        "url": "https://huggingface.co/justinsiow/a2c-AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njustinsiow\n/\na2c-AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n997.65 +/- 262.31\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "TahsinZaman/dqn-SpaceInvadersNoFrameskip-v4",
        "author": "TahsinZaman",
        "model_name": "dqn-SpaceInvadersNoFrameskip-v4",
        "url": "https://huggingface.co/TahsinZaman/dqn-SpaceInvadersNoFrameskip-v4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nTahsinZaman\n/\ndqn-SpaceInvadersNoFrameskip-v4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga TahsinZaman -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga TahsinZaman -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga TahsinZaman\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 10000000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n516.50 +/- 157.39\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "chenoi/deepRL4-2",
        "author": "chenoi",
        "model_name": "deepRL4-2",
        "url": "https://huggingface.co/chenoi/deepRL4-2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nchenoi\n/\ndeepRL4-2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n79.60 +/- 69.67\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "AMI0x/q-Taxi-v3",
        "author": "AMI0x",
        "model_name": "q-Taxi-v3",
        "url": "https://huggingface.co/AMI0x/q-Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nAMI0x\n/\nq-Taxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"AMI0x/q-Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "justinsiow/a2c-PandaReachDense-v2",
        "author": "justinsiow",
        "model_name": "a2c-PandaReachDense-v2",
        "url": "https://huggingface.co/justinsiow/a2c-PandaReachDense-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njustinsiow\n/\na2c-PandaReachDense-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nPandaReachDense-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing PandaReachDense-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing PandaReachDense-v2\n\n\nThis is a trained model of a A2C agent playing PandaReachDense-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton PandaReachDense-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-0.31 +/- 0.22\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "amannlp/Reinforce-02",
        "author": "amannlp",
        "model_name": "Reinforce-02",
        "url": "https://huggingface.co/amannlp/Reinforce-02",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\namannlp\n/\nReinforce-02\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n34.00 +/- 25.70\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "zoltantensorfow/q-Taxi-v3",
        "author": "zoltantensorfow",
        "model_name": "q-Taxi-v3",
        "url": "https://huggingface.co/zoltantensorfow/q-Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nzoltantensorfow\n/\nq-Taxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"zoltantensorfow/q-Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "gian-cr/LunarLander-v2",
        "author": "gian-cr",
        "model_name": "LunarLander-v2",
        "url": "https://huggingface.co/gian-cr/LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ngian-cr\n/\nLunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTensorBoard\n\nLunarLander-v2\n\nppo\n\ndeep-reinforcement-learning\n\ncustom-implementation\n\ndeep-rl-course\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent Playing LunarLander-v2\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\t\tPPO Agent Playing LunarLander-v2\n\t\n\n  This is a trained model of a PPO agent playing LunarLander-v2.\n\n\n\n\n\n\t\tHyperparameters\n\t\n\n{'exp_name': 'ppo'\n'seed': 1\n'torch_deterministic': True\n'cuda': True\n'track': False\n'wandb_project_name': 'cleanRL'\n'wandb_entity': None\n'capture_video': False\n'env_id': 'LunarLander-v2'\n'total_timesteps': 500000\n'learning_rate': 0.00025\n'num_envs': 4\n'num_steps': 128\n'anneal_lr': True\n'gae': True\n'gamma': 0.99\n'gae_lambda': 0.95\n'num_minibatches': 4\n'update_epochs': 4\n'norm_adv': True\n'clip_coef': 0.2\n'clip_vloss': True\n'ent_coef': 0.01\n'vf_coef': 0.5\n'max_grad_norm': 0.5\n'target_kl': None\n'repo_id': 'gian-cr/LunarLander-v2'\n'batch_size': 512\n'minibatch_size': 128}\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n35.44 +/- 80.93\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "alkiskoudounas/vizdoom_health_gathering_supreme",
        "author": "alkiskoudounas",
        "model_name": "vizdoom_health_gathering_supreme",
        "url": "https://huggingface.co/alkiskoudounas/vizdoom_health_gathering_supreme",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nalkiskoudounas\n/\nvizdoom_health_gathering_supreme\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nSample Factory\n\nTensorBoard\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in sample-factory\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\nA(n) APPO model trained on the doom_health_gathering_supreme environment.\nThis model was trained using Sample-Factory 2.0: https://github.com/alex-petrenko/sample-factory.\nDocumentation for how to use Sample-Factory can be found at https://www.samplefactory.dev/\n\n\n\n\n\n\t\tDownloading the model\n\t\n\nAfter installing Sample-Factory, download the model with:\npython -m sample_factory.huggingface.load_from_hub -r alkiskoudounas/vizdoom_health_gathering_supreme\n\n\n\n\n\n\n\t\tUsing the model\n\t\n\nTo run the model after download, use the enjoy script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=vizdoom_health_gathering_supreme\n\nYou can also upload models to the Hugging Face Hub using the same script with the --push_to_hub flag.\nSee https://www.samplefactory.dev/10-huggingface/huggingface/ for more details\n\n\n\n\n\n\t\tTraining with this model\n\t\n\nTo continue training with this model, use the train script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=vizdoom_health_gathering_supreme --restart_behavior=resume --train_for_env_steps=10000000000\n\nNote, you may have to adjust --train_for_env_steps to a suitably high number as the experiment will resume at the number of steps it concluded at.\n        \n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton doom_health_gathering_supreme\nself-reported\n\t\t\t\t\t\t\t\n\n10.15 +/- 4.91\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "hawkeoni/ppo-Huggy",
        "author": "hawkeoni",
        "model_name": "ppo-Huggy",
        "url": "https://huggingface.co/hawkeoni/ppo-Huggy",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nhawkeoni\n/\nppo-Huggy\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nHuggy\n\ndeep-reinforcement-learning\n\nML-Agents-Huggy\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Huggy\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Huggy\n\n\n  This is a trained model of a ppo agent playing Huggy using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Huggy\nStep 1: Find your model_id: hawkeoni/ppo-Huggy\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "chenoi/deepRL5",
        "author": "chenoi",
        "model_name": "deepRL5",
        "url": "https://huggingface.co/chenoi/deepRL5",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nchenoi\n/\ndeepRL5\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: chenoi/deepRL5\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "israel-avihail/poca-SoccerTwos",
        "author": "israel-avihail",
        "model_name": "poca-SoccerTwos",
        "url": "https://huggingface.co/israel-avihail/poca-SoccerTwos",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nisrael-avihail\n/\npoca-SoccerTwos\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nunity-ml-agents\n\ndeep-reinforcement-learning\n\nML-Agents-SoccerTwos\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\npoca Agent playing SoccerTwos\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\npoca Agent playing SoccerTwos\n\n\n  This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos\nStep 1: Write your model_id: israel-avihail/poca-SoccerTwos\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "lagarbure/ppo-LunarLander-v2",
        "author": "lagarbure",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/lagarbure/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nlagarbure\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n271.77 +/- 15.69\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "chenoi/deepRL5-2",
        "author": "chenoi",
        "model_name": "deepRL5-2",
        "url": "https://huggingface.co/chenoi/deepRL5-2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nchenoi\n/\ndeepRL5-2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: chenoi/deepRL5-2\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "hawkeoni/q-FrozenLake-v1-4x4-noSlippery",
        "author": "hawkeoni",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/hawkeoni/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nhawkeoni\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"hawkeoni/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "hawkeoni/Taxi-v3",
        "author": "hawkeoni",
        "model_name": "Taxi-v3",
        "url": "https://huggingface.co/hawkeoni/Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nhawkeoni\n/\nTaxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"hawkeoni/Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.54 +/- 2.74\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Hadar-97/ppo-LunarLander-v2",
        "author": "Hadar-97",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/Hadar-97/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nHadar-97\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n233.75 +/- 27.72\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "abarekatain/a2c-AntBulletEnv",
        "author": "abarekatain",
        "model_name": "a2c-AntBulletEnv",
        "url": "https://huggingface.co/abarekatain/a2c-AntBulletEnv",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nabarekatain\n/\na2c-AntBulletEnv\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n1121.85 +/- 111.24\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Augcos/ML-Agents-SnowballTarget",
        "author": "Augcos",
        "model_name": "ML-Agents-SnowballTarget",
        "url": "https://huggingface.co/Augcos/ML-Agents-SnowballTarget",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nAugcos\n/\nML-Agents-SnowballTarget\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: Augcos/ML-Agents-SnowballTarget\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "gian-cr/poca-SoccerTwos",
        "author": "gian-cr",
        "model_name": "poca-SoccerTwos",
        "url": "https://huggingface.co/gian-cr/poca-SoccerTwos",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ngian-cr\n/\npoca-SoccerTwos\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nunity-ml-agents\n\ndeep-reinforcement-learning\n\nML-Agents-SoccerTwos\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\npoca Agent playing SoccerTwos\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\npoca Agent playing SoccerTwos\n\n\n  This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos\nStep 1: Write your model_id: gian-cr/poca-SoccerTwos\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "abarekatain/a2c-PandaReachDense-v2",
        "author": "abarekatain",
        "model_name": "a2c-PandaReachDense-v2",
        "url": "https://huggingface.co/abarekatain/a2c-PandaReachDense-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nabarekatain\n/\na2c-PandaReachDense-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nPandaReachDense-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing PandaReachDense-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing PandaReachDense-v2\n\n\nThis is a trained model of a A2C agent playing PandaReachDense-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton PandaReachDense-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-2.76 +/- 0.79\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "chenoi/deepRL6-1AntBulletEnv-v0",
        "author": "chenoi",
        "model_name": "deepRL6-1AntBulletEnv-v0",
        "url": "https://huggingface.co/chenoi/deepRL6-1AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nchenoi\n/\ndeepRL6-1AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n1811.16 +/- 62.30\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Luksal/ppo-LunarLander-v2",
        "author": "Luksal",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/Luksal/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nLuksal\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n256.33 +/- 19.73\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "RohithKumar/Reinforce-cartpole-v1",
        "author": "RohithKumar",
        "model_name": "Reinforce-cartpole-v1",
        "url": "https://huggingface.co/RohithKumar/Reinforce-cartpole-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nRohithKumar\n/\nReinforce-cartpole-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "vovikdrg/space-invaders",
        "author": "vovikdrg",
        "model_name": "space-invaders",
        "url": "https://huggingface.co/vovikdrg/space-invaders",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nvovikdrg\n/\nspace-invaders\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga vovikdrg -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga vovikdrg -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga vovikdrg\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 700000),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n606.50 +/- 227.21\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "chenoi/deepRL6-2-PandaReachDense-v2",
        "author": "chenoi",
        "model_name": "deepRL6-2-PandaReachDense-v2",
        "url": "https://huggingface.co/chenoi/deepRL6-2-PandaReachDense-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nchenoi\n/\ndeepRL6-2-PandaReachDense-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nPandaReachDense-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing PandaReachDense-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing PandaReachDense-v2\n\n\nThis is a trained model of a A2C agent playing PandaReachDense-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton PandaReachDense-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-1.35 +/- 0.25\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Augcos/ML-Agents-Pyramids",
        "author": "Augcos",
        "model_name": "ML-Agents-Pyramids",
        "url": "https://huggingface.co/Augcos/ML-Agents-Pyramids",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nAugcos\n/\nML-Agents-Pyramids\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: Augcos/ML-Agents-Pyramids\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "TahsinZaman/Reinforce-model1",
        "author": "TahsinZaman",
        "model_name": "Reinforce-model1",
        "url": "https://huggingface.co/TahsinZaman/Reinforce-model1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nTahsinZaman\n/\nReinforce-model1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n486.10 +/- 27.82\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "RohithKumar/Reinforce-pixelcopter-v1",
        "author": "RohithKumar",
        "model_name": "Reinforce-pixelcopter-v1",
        "url": "https://huggingface.co/RohithKumar/Reinforce-pixelcopter-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nRohithKumar\n/\nReinforce-pixelcopter-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n14.30 +/- 10.27\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "jmurphy97/Reinforce-CartPole-v1",
        "author": "jmurphy97",
        "model_name": "Reinforce-CartPole-v1",
        "url": "https://huggingface.co/jmurphy97/Reinforce-CartPole-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njmurphy97\n/\nReinforce-CartPole-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n475.40 +/- 40.55\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "OpenDILabCommunity/LunarLander-v2-DDPG",
        "author": "OpenDILabCommunity",
        "model_name": "LunarLander-v2-DDPG",
        "url": "https://huggingface.co/OpenDILabCommunity/LunarLander-v2-DDPG",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nOpenDILabCommunity\n/\nLunarLander-v2-DDPG\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPyTorch\n\nEnglish\n\ndeep-reinforcement-learning\n\nDI-engine\n\nLunarLander-v2\n\n\n\nLicense: \napache-2.0\n\n\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\nYAML Metadata Error:\n\t\"model-index[0].results[0].dataset.type\" with value \"OpenAI/Gym/Box2d-LunarLander-v2\" fails to match the required pattern: /^(?:[\\w-]+\\/)?[\\w-.]+$/\n\t\n\n\n\n\nPlay LunarLander-v2 with DDPG Policy\nModel Description\n\nModel Usage\nInstall the Dependencies\nGit Clone from Huggingface and Run the Model\nRun Model by Using Huggingface_ding\n\nModel Training\nTrain the Model and Push to Huggingface_hub\n\nModel Information\n\nEnvironments\n\n\n\n\n\n\n\n\n\n\n\t\tPlay LunarLander-v2 with DDPG Policy\n\t\n\n\n\n\n\n\n\t\tModel Description\n\t\n\nThis is a simple DDPG implementation to OpenAI/Gym/Box2d LunarLander-v2 using the DI-engine library and the DI-zoo.\nDI-engine is a python library for solving general decision intelligence problems, which is based on implementations of reinforcement learning framework using PyTorch or JAX. This library aims to standardize the reinforcement learning framework across different algorithms, benchmarks, environments, and to support both academic researches and prototype applications. Besides, self-customized training pipelines and applications are supported  by reusing different abstraction levels of DI-engine reinforcement learning framework.\n\n\n\n\n\n\t\tModel Usage\n\t\n\n\n\n\n\n\n\t\tInstall the Dependencies\n\t\n\n\n(Click for Details)\n# install huggingface_ding\ngit clone https://github.com/opendilab/huggingface_ding.git\npip3 install -e ./huggingface_ding/\n# install environment dependencies if needed\npip3 install DI-engine[common_env]\n\n\n\n\n\n\n\n\t\tGit Clone from Huggingface and Run the Model\n\t\n\n\n(Click for Details)\n# running with trained model\npython3 -u run.py\n\nrun.py\nfrom ding.bonus import DDPGAgent\nfrom ding.config import Config\nfrom easydict import EasyDict\nimport torch\n\n# Pull model from files which are git cloned from huggingface\npolicy_state_dict = torch.load(\"pytorch_model.bin\", map_location=torch.device(\"cpu\"))\ncfg = EasyDict(Config.file_to_dict(\"policy_config.py\").cfg_dict)\n# Instantiate the agent\nagent = DDPGAgent(\n    env_id=\"LunarLanderContinuous-v2\",\n    exp_name=\"LunarLander-v2-DDPG\",\n    cfg=cfg.exp_config,\n    policy_state_dict=policy_state_dict\n)\n# Continue training\nagent.train(step=5000)\n# Render the new agent performance\nagent.deploy(enable_save_replay=True)\n\n\n\n\n\n\n\n\t\tRun Model by Using Huggingface_ding\n\t\n\n\n(Click for Details)\n# running with trained model\npython3 -u run.py\n\nrun.py\nfrom ding.bonus import DDPGAgent\nfrom huggingface_ding import pull_model_from_hub\n\n# Pull model from Hugggingface hub\npolicy_state_dict, cfg = pull_model_from_hub(repo_id=\"OpenDILabCommunity/LunarLander-v2-DDPG\")\n# Instantiate the agent\nagent = DDPGAgent(\n    env_id=\"LunarLanderContinuous-v2\",\n    exp_name=\"LunarLander-v2-DDPG\",\n    cfg=cfg.exp_config,\n    policy_state_dict=policy_state_dict\n)\n# Continue training\nagent.train(step=5000)\n# Render the new agent performance\nagent.deploy(enable_save_replay=True)\n\n\n\n\n\n\n\n\t\tModel Training\n\t\n\n\n\n\n\n\n\t\tTrain the Model and Push to Huggingface_hub\n\t\n\n\n(Click for Details)\n#Training Your Own Agent\npython3 -u train.py\n\ntrain.py\nfrom ding.bonus import DDPGAgent\nfrom huggingface_ding import push_model_to_hub\n\n# Instantiate the agent\nagent = DDPGAgent(env_id=\"LunarLanderContinuous-v2\", exp_name=\"LunarLander-v2-DDPG\")\n# Train the agent\nreturn_ = agent.train(step=int(4000000), collector_env_num=4, evaluator_env_num=4)\n# Push model to huggingface hub\npush_model_to_hub(\n    agent=agent.best,\n    env_name=\"OpenAI/Gym/Box2d\",\n    task_name=\"LunarLander-v2\",\n    algo_name=\"DDPG\",\n    wandb_url=return_.wandb_url,\n    github_repo_url=\"https://github.com/opendilab/DI-engine\",\n    github_doc_model_url=\"https://di-engine-docs.readthedocs.io/en/latest/12_policies/ddpg.html\",\n    github_doc_env_url=\"https://di-engine-docs.readthedocs.io/en/latest/13_envs/lunarlander.html\",\n    installation_guide=\"pip3 install DI-engine[common_env]\",\n    usage_file_by_git_clone=\"./ddpg/lunarlander_ddpg_deploy.py\",\n    usage_file_by_huggingface_ding=\"./ddpg/lunarlander_ddpg_download.py\",\n    train_file=\"./ddpg/lunarlander_ddpg.py\",\n    repo_id=\"OpenDILabCommunity/LunarLander-v2-DDPG\",\n    create_repo=False\n)\n\n\nConfiguration\n\n(Click for Details)\nexp_config = {\n    'env': {\n        'manager': {\n            'episode_num': float(\"inf\"),\n            'max_retry': 1,\n            'retry_type': 'reset',\n            'auto_reset': True,\n            'step_timeout': None,\n            'reset_timeout': None,\n            'retry_waiting_time': 0.1,\n            'cfg_type': 'BaseEnvManagerDict'\n        },\n        'stop_value': 260,\n        'n_evaluator_episode': 8,\n        'env_id': 'LunarLanderContinuous-v2',\n        'collector_env_num': 8,\n        'evaluator_env_num': 8,\n        'act_scale': True\n    },\n    'policy': {\n        'model': {\n            'obs_shape': 8,\n            'action_shape': 2,\n            'twin_critic': True,\n            'action_space': 'regression'\n        },\n        'learn': {\n            'learner': {\n                'train_iterations': 1000000000,\n                'dataloader': {\n                    'num_workers': 0\n                },\n                'log_policy': True,\n                'hook': {\n                    'load_ckpt_before_run': '',\n                    'log_show_after_iter': 100,\n                    'save_ckpt_after_iter': 10000,\n                    'save_ckpt_after_run': True\n                },\n                'cfg_type': 'BaseLearnerDict'\n            },\n            'update_per_collect': 2,\n            'batch_size': 128,\n            'learning_rate_actor': 0.001,\n            'learning_rate_critic': 0.001,\n            'ignore_done': False,\n            'target_theta': 0.005,\n            'discount_factor': 0.99,\n            'actor_update_freq': 1,\n            'noise': False,\n            'noise_sigma': 0.1,\n            'noise_range': {\n                'min': -0.5,\n                'max': 0.5\n            }\n        },\n        'collect': {\n            'collector': {\n                'collect_print_freq': 1000\n            },\n            'unroll_len': 1,\n            'noise_sigma': 0.1,\n            'n_sample': 48\n        },\n        'eval': {\n            'evaluator': {\n                'eval_freq': 100,\n                'render': {\n                    'render_freq': -1,\n                    'mode': 'train_iter'\n                },\n                'figure_path': None,\n                'cfg_type': 'InteractionSerialEvaluatorDict',\n                'stop_value': 260,\n                'n_episode': 8\n            }\n        },\n        'other': {\n            'replay_buffer': {\n                'replay_buffer_size': 20000\n            }\n        },\n        'on_policy': False,\n        'cuda': True,\n        'multi_gpu': False,\n        'bp_update_sync': True,\n        'traj_len_inf': False,\n        'type': 'ddpg',\n        'priority': False,\n        'priority_IS_weight': False,\n        'random_collect_size': 0,\n        'transition_with_policy_data': False,\n        'action_space': 'continuous',\n        'reward_batch_norm': False,\n        'multi_agent': False,\n        'cfg_type': 'DDPGPolicyDict'\n    },\n    'exp_name': 'LunarLander-v2-DDPG',\n    'seed': 0,\n    'wandb_logger': {\n        'gradient_logger': True,\n        'video_logger': True,\n        'plot_logger': True,\n        'action_logger': True,\n        'return_logger': False\n    }\n}\n\n\nTraining Procedure \n\nWeights & Biases (wandb): monitor link\n\n\n\n\n\n\n\t\tModel Information\n\t\n\n\nGithub Repository: repo link\nDoc: DI-engine-docs Algorithm link\nConfiguration: config link\nDemo: video\nParameters total size: 115.03 KB\nLast Update Date: 2023-09-22\n\n\n\n\n\n\n\t\tEnvironments\n\t\n\n\nBenchmark: OpenAI/Gym/Box2d\nTask: LunarLander-v2\nGym version: 0.25.1\nDI-engine version: v0.4.9\nPyTorch version: 2.0.1+cu117\nDoc: DI-engine-docs Environments link\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\nModel card error\nThis model's model-index metadata is invalid:\n\t\t\t\tSchema validation error. \"model-index[0].results[0].dataset.type\" with value \"OpenAI/Gym/Box2d-LunarLander-v2\" fails to match the required pattern: /^(?:[\\w-]+\\/)?[\\w-.]+$/\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "cha00/ppo-LunarLander-v2",
        "author": "cha00",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/cha00/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ncha00\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-681.89 +/- 267.44\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Apocalypse-19/FrozenLake-4x4-noSlippery",
        "author": "Apocalypse-19",
        "model_name": "FrozenLake-4x4-noSlippery",
        "url": "https://huggingface.co/Apocalypse-19/FrozenLake-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nApocalypse-19\n/\nFrozenLake-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 created by Apocalypse-19.\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Apocalypse-19/FrozenLake-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "JaviBJ/a2c-AntBulletEnv-v0",
        "author": "JaviBJ",
        "model_name": "a2c-AntBulletEnv-v0",
        "url": "https://huggingface.co/JaviBJ/a2c-AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nJaviBJ\n/\na2c-AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n1592.16 +/- 355.14\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "lagarbure/q-FrozenLake-v1-4x4-noSlippery",
        "author": "lagarbure",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/lagarbure/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nlagarbure\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"lagarbure/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "lagarbure/q-FrozenLake-v1-4x4-Slippery",
        "author": "lagarbure",
        "model_name": "q-FrozenLake-v1-4x4-Slippery",
        "url": "https://huggingface.co/lagarbure/q-FrozenLake-v1-4x4-Slippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nlagarbure\n/\nq-FrozenLake-v1-4x4-Slippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"lagarbure/q-FrozenLake-v1-4x4-Slippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4\nself-reported\n\t\t\t\t\t\t\t\n\n0.09 +/- 0.29\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "glitchyordis/Reinforce_cartpole_test",
        "author": "glitchyordis",
        "model_name": "Reinforce_cartpole_test",
        "url": "https://huggingface.co/glitchyordis/Reinforce_cartpole_test",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nglitchyordis\n/\nReinforce_cartpole_test\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Apocalypse-19/q-FrozenLake-8x8-Slippery",
        "author": "Apocalypse-19",
        "model_name": "q-FrozenLake-8x8-Slippery",
        "url": "https://huggingface.co/Apocalypse-19/q-FrozenLake-8x8-Slippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nApocalypse-19\n/\nq-FrozenLake-8x8-Slippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-8x8\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 created by Apocalypse-19.\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Apocalypse-19/q-FrozenLake-8x8-Slippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-8x8\nself-reported\n\t\t\t\t\t\t\t\n\n0.48 +/- 0.50\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Apocalypse-19/q-Taxi-v3",
        "author": "Apocalypse-19",
        "model_name": "q-Taxi-v3",
        "url": "https://huggingface.co/Apocalypse-19/q-Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nApocalypse-19\n/\nq-Taxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 created by Apocalypse-19.\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Apocalypse-19/q-Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Apocalypse-19/q-FrozenLake-8x8-Slippery-v2",
        "author": "Apocalypse-19",
        "model_name": "q-FrozenLake-8x8-Slippery-v2",
        "url": "https://huggingface.co/Apocalypse-19/q-FrozenLake-8x8-Slippery-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nApocalypse-19\n/\nq-FrozenLake-8x8-Slippery-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-8x8\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 created by Apocalypse-19.\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Apocalypse-19/q-FrozenLake-8x8-Slippery-v2\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-8x8\nself-reported\n\t\t\t\t\t\t\t\n\n0.57 +/- 0.50\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "kapilzadpe/ppo-LunarLander-v2",
        "author": "kapilzadpe",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/kapilzadpe/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nkapilzadpe\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n208.69 +/- 71.29\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "chenoi/deepRL7",
        "author": "chenoi",
        "model_name": "deepRL7",
        "url": "https://huggingface.co/chenoi/deepRL7",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nchenoi\n/\ndeepRL7\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nunity-ml-agents\n\ndeep-reinforcement-learning\n\nML-Agents-SoccerTwos\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\npoca Agent playing SoccerTwos\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\npoca Agent playing SoccerTwos\n\n\n  This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos\nStep 1: Write your model_id: chenoi/deepRL7\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Apocalypse-19/q-Taxi-v3-2",
        "author": "Apocalypse-19",
        "model_name": "q-Taxi-v3-2",
        "url": "https://huggingface.co/Apocalypse-19/q-Taxi-v3-2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nApocalypse-19\n/\nq-Taxi-v3-2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 created by Apocalypse-19.\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Apocalypse-19/q-Taxi-v3-2\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "sonny-dev/Reinforce-CartPole-v1",
        "author": "sonny-dev",
        "model_name": "Reinforce-CartPole-v1",
        "url": "https://huggingface.co/sonny-dev/Reinforce-CartPole-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nsonny-dev\n/\nReinforce-CartPole-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "chenoi/deepRL8-1",
        "author": "chenoi",
        "model_name": "deepRL8-1",
        "url": "https://huggingface.co/chenoi/deepRL8-1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nchenoi\n/\ndeepRL8-1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTensorBoard\n\nLunarLander-v2\n\nppo\n\ndeep-reinforcement-learning\n\ncustom-implementation\n\ndeep-rl-course\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent Playing LunarLander-v2\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\t\tPPO Agent Playing LunarLander-v2\n\t\n\n  This is a trained model of a PPO agent playing LunarLander-v2.\n\n\n\n\n\n\t\tHyperparameters\n\t\n\n{'exp_name': 'ppo'\n'seed': 1\n'torch_deterministic': True\n'cuda': True\n'track': False\n'wandb_project_name': 'cleanRL'\n'wandb_entity': None\n'capture_video': False\n'env_id': 'LunarLander-v2'\n'total_timesteps': 100000\n'learning_rate': 0.00025\n'num_envs': 4\n'num_steps': 128\n'anneal_lr': True\n'gae': True\n'gamma': 0.99\n'gae_lambda': 0.95\n'num_minibatches': 4\n'update_epochs': 4\n'norm_adv': True\n'clip_coef': 0.2\n'clip_vloss': True\n'ent_coef': 0.01\n'vf_coef': 0.5\n'max_grad_norm': 0.5\n'target_kl': None\n'repo_id': 'chenoi/deepRL8-1'\n'batch_size': 512\n'minibatch_size': 128}\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-135.57 +/- 57.14\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "infatum/ppo-SnowballTarget",
        "author": "infatum",
        "model_name": "ppo-SnowballTarget",
        "url": "https://huggingface.co/infatum/ppo-SnowballTarget",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ninfatum\n/\nppo-SnowballTarget\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: infatum/ppo-SnowballTarget\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Dabe/dqn-LunarLander-v2-4",
        "author": "Dabe",
        "model_name": "dqn-LunarLander-v2-4",
        "url": "https://huggingface.co/Dabe/dqn-LunarLander-v2-4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nDabe\n/\ndqn-LunarLander-v2-4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing LunarLander-v2\n\n\nThis is a trained model of a DQN agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n106.68 +/- 89.76\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "asantiago/ppo-LunarLander-v2",
        "author": "asantiago",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/asantiago/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nasantiago\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n276.03 +/- 19.66\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "justinsiow/poca-SoccerTwos",
        "author": "justinsiow",
        "model_name": "poca-SoccerTwos",
        "url": "https://huggingface.co/justinsiow/poca-SoccerTwos",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njustinsiow\n/\npoca-SoccerTwos\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nunity-ml-agents\n\ndeep-reinforcement-learning\n\nML-Agents-SoccerTwos\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\npoca Agent playing SoccerTwos\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\npoca Agent playing SoccerTwos\n\n\n  This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos\nStep 1: Write your model_id: justinsiow/poca-SoccerTwos\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month13\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ongknsro/dogdog02-Huggy",
        "author": "ongknsro",
        "model_name": "dogdog02-Huggy",
        "url": "https://huggingface.co/ongknsro/dogdog02-Huggy",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nongknsro\n/\ndogdog02-Huggy\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nHuggy\n\ndeep-reinforcement-learning\n\nML-Agents-Huggy\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Huggy\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Huggy\n\n\n  This is a trained model of a ppo agent playing Huggy using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Huggy\nStep 1: Find your model_id: ongknsro/dogdog02-Huggy\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Luksal/q-FrozenLake-v1-4x4-noSlippery",
        "author": "Luksal",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/Luksal/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nLuksal\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Luksal/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Luksal/q-Taxi-v3",
        "author": "Luksal",
        "model_name": "q-Taxi-v3",
        "url": "https://huggingface.co/Luksal/q-Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nLuksal\n/\nq-Taxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Luksal/q-Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "chenoi/deepRL8-2-last",
        "author": "chenoi",
        "model_name": "deepRL8-2-last",
        "url": "https://huggingface.co/chenoi/deepRL8-2-last",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nchenoi\n/\ndeepRL8-2-last\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nSample Factory\n\nTensorBoard\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in sample-factory\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\nA(n) APPO model trained on the doom_health_gathering_supreme environment.\nThis model was trained using Sample-Factory 2.0: https://github.com/alex-petrenko/sample-factory.\nDocumentation for how to use Sample-Factory can be found at https://www.samplefactory.dev/\n\n\n\n\n\n\t\tDownloading the model\n\t\n\nAfter installing Sample-Factory, download the model with:\npython -m sample_factory.huggingface.load_from_hub -r chenoi/deepRL8-2-last\n\n\n\n\n\n\n\t\tUsing the model\n\t\n\nTo run the model after download, use the enjoy script corresponding to this environment:\npython -m .home.chenoi1.miniconda3.envs.last.lib.python3.9.site-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=deepRL8-2-last\n\nYou can also upload models to the Hugging Face Hub using the same script with the --push_to_hub flag.\nSee https://www.samplefactory.dev/10-huggingface/huggingface/ for more details\n\n\n\n\n\n\t\tTraining with this model\n\t\n\nTo continue training with this model, use the train script corresponding to this environment:\npython -m .home.chenoi1.miniconda3.envs.rl.lib.python3.9.site-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=deepRL8-2-last --restart_behavior=resume --train_for_env_steps=10000000000\n\nNote, you may have to adjust --train_for_env_steps to a suitably high number as the experiment will resume at the number of steps it concluded at.\n        \n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton doom_health_gathering_supreme\nself-reported\n\t\t\t\t\t\t\t\n\n19.76 +/- 2.52\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "infatum/RND-Pyramids",
        "author": "infatum",
        "model_name": "RND-Pyramids",
        "url": "https://huggingface.co/infatum/RND-Pyramids",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ninfatum\n/\nRND-Pyramids\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: infatum/RND-Pyramids\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "JamesEJarvis/poca-SoccerTwos",
        "author": "JamesEJarvis",
        "model_name": "poca-SoccerTwos",
        "url": "https://huggingface.co/JamesEJarvis/poca-SoccerTwos",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nJamesEJarvis\n/\npoca-SoccerTwos\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nunity-ml-agents\n\ndeep-reinforcement-learning\n\nML-Agents-SoccerTwos\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\npoca Agent playing SoccerTwos\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\npoca Agent playing SoccerTwos\n\n\n  This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos\nStep 1: Write your model_id: JamesEJarvis/poca-SoccerTwos\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Augcos/a2c-AntBulletEnv-v0",
        "author": "Augcos",
        "model_name": "a2c-AntBulletEnv-v0",
        "url": "https://huggingface.co/Augcos/a2c-AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nAugcos\n/\na2c-AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n1893.63 +/- 99.91\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "jontromanab/q-FrozenLake-v1-4x4-noSlippery",
        "author": "jontromanab",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/jontromanab/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njontromanab\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"jontromanab/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "dylwil3/ppo-LunarLander-v2",
        "author": "dylwil3",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/dylwil3/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ndylwil3\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n245.38 +/- 42.19\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "jontromanab/taxi",
        "author": "jontromanab",
        "model_name": "taxi",
        "url": "https://huggingface.co/jontromanab/taxi",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njontromanab\n/\ntaxi\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"jontromanab/taxi\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.50 +/- 2.76\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "mmg10/q-FrozenLake-v1-4x4-noSlippery",
        "author": "mmg10",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/mmg10/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nmmg10\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"mmg10/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "glitchyordis/Reinforce-pixelcopter-test",
        "author": "glitchyordis",
        "model_name": "Reinforce-pixelcopter-test",
        "url": "https://huggingface.co/glitchyordis/Reinforce-pixelcopter-test",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nglitchyordis\n/\nReinforce-pixelcopter-test\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n42.70 +/- 38.86\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "mmg10/Taxi-v3",
        "author": "mmg10",
        "model_name": "Taxi-v3",
        "url": "https://huggingface.co/mmg10/Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nmmg10\n/\nTaxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"mmg10/Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.54 +/- 2.73\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Flooow/dqn-SpaceInvadersNoFrameskip-v4",
        "author": "Flooow",
        "model_name": "dqn-SpaceInvadersNoFrameskip-v4",
        "url": "https://huggingface.co/Flooow/dqn-SpaceInvadersNoFrameskip-v4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nFlooow\n/\ndqn-SpaceInvadersNoFrameskip-v4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga Flooow -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga Flooow -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga Flooow\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 2000000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n797.00 +/- 313.05\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "vikidance01/ppo-LunarLander-v2",
        "author": "vikidance01",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/vikidance01/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nvikidance01\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n263.71 +/- 48.58\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Nicko789/ppo-SnowballTargetTESTCOLAB",
        "author": "Nicko789",
        "model_name": "ppo-SnowballTargetTESTCOLAB",
        "url": "https://huggingface.co/Nicko789/ppo-SnowballTargetTESTCOLAB",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nNicko789\n/\nppo-SnowballTargetTESTCOLAB\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: Nicko789/ppo-SnowballTargetTESTCOLAB\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ajitgupta/PPO-LunarLander-v2",
        "author": "ajitgupta",
        "model_name": "PPO-LunarLander-v2",
        "url": "https://huggingface.co/ajitgupta/PPO-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\najitgupta\n/\nPPO-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n255.48 +/- 20.60\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "OlgaVityuk/poca-SoccerTwos",
        "author": "OlgaVityuk",
        "model_name": "poca-SoccerTwos",
        "url": "https://huggingface.co/OlgaVityuk/poca-SoccerTwos",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nOlgaVityuk\n/\npoca-SoccerTwos\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nunity-ml-agents\n\ndeep-reinforcement-learning\n\nML-Agents-SoccerTwos\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\npoca Agent playing SoccerTwos\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\npoca Agent playing SoccerTwos\n\n\n  This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos\nStep 1: Write your model_id: OlgaVityuk/poca-SoccerTwos\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "dylwil3/ppo-Huggy",
        "author": "dylwil3",
        "model_name": "ppo-Huggy",
        "url": "https://huggingface.co/dylwil3/ppo-Huggy",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ndylwil3\n/\nppo-Huggy\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nHuggy\n\ndeep-reinforcement-learning\n\nML-Agents-Huggy\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Huggy\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Huggy\n\n\n  This is a trained model of a ppo agent playing Huggy using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Huggy\nStep 1: Find your model_id: dylwil3/ppo-Huggy\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "TahsinZaman/Reinforce-Pixelcopter-PLE-v0",
        "author": "TahsinZaman",
        "model_name": "Reinforce-Pixelcopter-PLE-v0",
        "url": "https://huggingface.co/TahsinZaman/Reinforce-Pixelcopter-PLE-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nTahsinZaman\n/\nReinforce-Pixelcopter-PLE-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n15.50 +/- 9.58\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "rlucasz93/ppo-SnowballTarget",
        "author": "rlucasz93",
        "model_name": "ppo-SnowballTarget",
        "url": "https://huggingface.co/rlucasz93/ppo-SnowballTarget",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nrlucasz93\n/\nppo-SnowballTarget\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: rlucasz93/ppo-SnowballTarget\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "jmurphy97/Pixelcopter-PLE-v0",
        "author": "jmurphy97",
        "model_name": "Pixelcopter-PLE-v0",
        "url": "https://huggingface.co/jmurphy97/Pixelcopter-PLE-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njmurphy97\n/\nPixelcopter-PLE-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n28.80 +/- 25.52\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Dabe/dqn-LunarLander-v2-5",
        "author": "Dabe",
        "model_name": "dqn-LunarLander-v2-5",
        "url": "https://huggingface.co/Dabe/dqn-LunarLander-v2-5",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nDabe\n/\ndqn-LunarLander-v2-5\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing LunarLander-v2\n\n\nThis is a trained model of a DQN agent playing LunarLander-v2\nusing the stable-baselines3 library.\nSome of the hyperparameters used are listed below:\n\n\n\nHyperparameters\nValue\n\n\nLearning rate\n0.0002\n\n\nBatch size\n128\n\n\nBuffer size\n100000\n\n\n\n\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\n# ---------------------- Libraries ------------------------------\nfrom huggingface_sb3 import load_from_hub, package_to_hub, push_to_hub\nfrom huggingface_hub import (\n    notebook_login,\n)  # To log to our Hugging Face account to be able to upload models to the Hub.\n\nfrom stable_baselines3 import DQN\nfrom stable_baselines3.common.evaluation import evaluate_policy\nfrom stable_baselines3.common.env_util import make_vec_env\n\n# ---------------------------- Main --------------------------------------\n\n# PONERLE NOMBRE CADA VEZ QUE ENTRENE UN NUEVO MODELO\nmodel_name = \"dqn-LunarLander-v2-seed42-12\"\n\n# Defino la seed para los envs y los n\u00fameros aleatorios\nSeed=42\nutils.set_seed(Seed)\n\n\n# Se crea el entorno\n\nenv = make_vec_env(\"LunarLander-v2\", n_envs=16)       # Creo un env vectorizado, 16 envs simultaneos\nenv.seed(Seed)                                        # Seed del entorno de entrenamiento\n\n# Se establece el tipo de agente, con sus hiperparametros\n\n# Para toquetear centrarse en: learning rate,buffer size, batch size\nmodel = DQN(policy = 'MlpPolicy',\n            env = env,\n            learning_rate= 0.0002,\n            learning_starts= 0,         # Cuando empieza el proceso de aprendizaje\n            batch_size= 128,            # Cada cuanto se da el paso en el gradiente\n            buffer_size=100000,         #  (size of the replay buffer)\n            gamma = 0.99 ,              # Factor de descuento, 0.99 por defecto\n            train_freq= 4,              # Cada cuanto se actualiza el modelo\n            target_update_interval=15,  # Actualizar la red cada '' pasos en el entorno\n            gradient_steps=4,           # Cuantos pasos dar de gradiente antes de cada actualizacion del modelo\n            exploration_fraction=0.08,  # que fraccion del entrenamiento tiene la exploracion reducida\n            exploration_final_eps=0.05, # Valor final de la probabilidad de realizar una accion aleatoria\n            verbose= 1,                 # Nivel de informacion que da sobre el proceso (0,1 o 2)\n            optimize_memory_usage=False,\n            seed= Seed\n            )\n\n# Entrenamiento\n\nmodel.learn(total_timesteps=5000000)\n\n# Se guarda el modelo\nmodel.save(path = \"Historial/\" + model_name)\n\n# Se crea el entorno de evaluacion\neval_env = gym.make(\"LunarLander-v2\")\neval_env.seed(2*Seed)                                 # Seed del entorno de evaluacion, distinta del de entrenamiento\n\n# Se evalua\nmean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n\n# Guardo los resultados de la evaluacion del modelo\nwith open('Historial/' + model_name + '.txt', 'w') as f:\n    f.write(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n261.75 +/- 24.62\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "OlgaVityuk/Reinforce-CartPole-v1",
        "author": "OlgaVityuk",
        "model_name": "Reinforce-CartPole-v1",
        "url": "https://huggingface.co/OlgaVityuk/Reinforce-CartPole-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nOlgaVityuk\n/\nReinforce-CartPole-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "pinaggle/Reinforce-paramtune",
        "author": "pinaggle",
        "model_name": "Reinforce-paramtune",
        "url": "https://huggingface.co/pinaggle/Reinforce-paramtune",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\npinaggle\n/\nReinforce-paramtune\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "dylwil3/q-FrozenLake-v1-4x4-noSlippery",
        "author": "dylwil3",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/dylwil3/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ndylwil3\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"dylwil3/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "dylwil3/q-Taxi-v3",
        "author": "dylwil3",
        "model_name": "q-Taxi-v3",
        "url": "https://huggingface.co/dylwil3/q-Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ndylwil3\n/\nq-Taxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"dylwil3/q-Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.52 +/- 2.73\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "carolinainmymind/a2c-AntBulletEnv-v0",
        "author": "carolinainmymind",
        "model_name": "a2c-AntBulletEnv-v0",
        "url": "https://huggingface.co/carolinainmymind/a2c-AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ncarolinainmymind\n/\na2c-AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n2454.28 +/- 43.62\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "AMI0x/dqn-SpaceInvadersNoFrameskip-v4",
        "author": "AMI0x",
        "model_name": "dqn-SpaceInvadersNoFrameskip-v4",
        "url": "https://huggingface.co/AMI0x/dqn-SpaceInvadersNoFrameskip-v4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nAMI0x\n/\ndqn-SpaceInvadersNoFrameskip-v4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga AMI0x -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga AMI0x -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga AMI0x\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 1000000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n545.00 +/- 120.79\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "carolinainmymind/a2c-PandaReachDense-v2",
        "author": "carolinainmymind",
        "model_name": "a2c-PandaReachDense-v2",
        "url": "https://huggingface.co/carolinainmymind/a2c-PandaReachDense-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ncarolinainmymind\n/\na2c-PandaReachDense-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nPandaReachDense-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing PandaReachDense-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing PandaReachDense-v2\n\n\nThis is a trained model of a A2C agent playing PandaReachDense-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton PandaReachDense-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-2.63 +/- 0.55\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "yingzhi/q-FrozenLake-v1-4x4-noSlippery",
        "author": "yingzhi",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/yingzhi/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nyingzhi\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"yingzhi/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "yingzhi/Taxi-v3",
        "author": "yingzhi",
        "model_name": "Taxi-v3",
        "url": "https://huggingface.co/yingzhi/Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nyingzhi\n/\nTaxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"yingzhi/Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.46 +/- 2.69\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "vinaysatish/q-FrozenLake-v1-4x4-noSlippery",
        "author": "vinaysatish",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/vinaysatish/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nvinaysatish\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"vinaysatish/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "FernandoD95/ppo-LunarLander-v2",
        "author": "FernandoD95",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/FernandoD95/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nFernandoD95\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n258.14 +/- 25.99\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "dyingc/poca-SoccerTwos",
        "author": "dyingc",
        "model_name": "poca-SoccerTwos",
        "url": "https://huggingface.co/dyingc/poca-SoccerTwos",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ndyingc\n/\npoca-SoccerTwos\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nunity-ml-agents\n\ndeep-reinforcement-learning\n\nML-Agents-SoccerTwos\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\npoca Agent playing SoccerTwos\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\npoca Agent playing SoccerTwos\n\n\n  This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos\nStep 1: Write your model_id: dyingc/poca-SoccerTwos\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "rlucasz93/ppo-Pyramid",
        "author": "rlucasz93",
        "model_name": "ppo-Pyramid",
        "url": "https://huggingface.co/rlucasz93/ppo-Pyramid",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nrlucasz93\n/\nppo-Pyramid\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: rlucasz93/ppo-Pyramid\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Smone55/ppo-Huggy",
        "author": "Smone55",
        "model_name": "ppo-Huggy",
        "url": "https://huggingface.co/Smone55/ppo-Huggy",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nSmone55\n/\nppo-Huggy\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nHuggy\n\ndeep-reinforcement-learning\n\nML-Agents-Huggy\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Huggy\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Huggy\n\n\n  This is a trained model of a ppo agent playing Huggy using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Huggy\nStep 1: Find your model_id: Smone55/ppo-Huggy\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Dabe/dqn-LunarLander-v2-6",
        "author": "Dabe",
        "model_name": "dqn-LunarLander-v2-6",
        "url": "https://huggingface.co/Dabe/dqn-LunarLander-v2-6",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nDabe\n/\ndqn-LunarLander-v2-6\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing LunarLander-v2\n\n\nThis is a trained model of a DQN agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n130.61 +/- 103.28\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "sonny-dev/Reinforce-PixelCopter",
        "author": "sonny-dev",
        "model_name": "Reinforce-PixelCopter",
        "url": "https://huggingface.co/sonny-dev/Reinforce-PixelCopter",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nsonny-dev\n/\nReinforce-PixelCopter\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n19.30 +/- 15.64\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "feng5520/dqn-SpaceInvadersNoFrameskip-v4",
        "author": "feng5520",
        "model_name": "dqn-SpaceInvadersNoFrameskip-v4",
        "url": "https://huggingface.co/feng5520/dqn-SpaceInvadersNoFrameskip-v4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nfeng5520\n/\ndqn-SpaceInvadersNoFrameskip-v4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga feng5520 -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga feng5520 -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga feng5520\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 10000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n15.50 +/- 12.54\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "vinaysatish/taxiexample",
        "author": "vinaysatish",
        "model_name": "taxiexample",
        "url": "https://huggingface.co/vinaysatish/taxiexample",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nvinaysatish\n/\ntaxiexample\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"vinaysatish/taxiexample\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.52 +/- 2.62\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Yanrds/q-FrozenLake-v1-4x4-noSlippery",
        "author": "Yanrds",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/Yanrds/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nYanrds\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Yanrds/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Yanrds/q-Taxi-v3",
        "author": "Yanrds",
        "model_name": "q-Taxi-v3",
        "url": "https://huggingface.co/Yanrds/q-Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nYanrds\n/\nq-Taxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Yanrds/q-Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "pablomaya/dqn-SpaceInvadersNoFrameskip-v4",
        "author": "pablomaya",
        "model_name": "dqn-SpaceInvadersNoFrameskip-v4",
        "url": "https://huggingface.co/pablomaya/dqn-SpaceInvadersNoFrameskip-v4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\npablomaya\n/\ndqn-SpaceInvadersNoFrameskip-v4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga pablomaya -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga pablomaya -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga pablomaya\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 1000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n106.00 +/- 2.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "cpwan/RLOR-TSP",
        "author": "cpwan",
        "model_name": "RLOR-TSP",
        "url": "https://huggingface.co/cpwan/RLOR-TSP",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ncpwan\n/\nRLOR-TSP\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\n\n\n\narxiv:\n2303.13117\n\n\n\n\n\nLicense: \nmit\n\n\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nRLOR: A Flexible Framework of Deep Reinforcement Learning for Operation Research\nNews\n\nDemo\n\nInstallation\nConda\nOptional dependency\n\nFile structures\n\nTraining OR model with PPO\nTSP\nCVRP\nEnable WandB\nWhere is the tsp data?\n\n\nAcknowledgements\n\n\n\n\n\n\n\n\n\n\t\tRLOR: A Flexible Framework of Deep Reinforcement Learning for Operation Research\n\t\n\n1\ufe0f\u20e3 First work to incorporate end-to-end vehicle routing model in a modern RL platform (CleanRL)\n\u26a1 Speed up the training of Attention Model by 8 times (25hours --> 3 hours)\n\ud83d\udd0e A flexible framework for developing model, algorithm, environment, and search for operation research\n\n\n\n\n\n\t\tNews\n\t\n\n\n24/03/2023: We release our paper on arxiv!\n20/03/2023: We release demo and pretrained checkpoints!\n10/03/2023: We release our codebase!\n\n\n\n\n\n\n\t\tDemo\n\t\n\nWe provide inference demo on colab notebook:\n\n\n\nEnvironment\nSearch\nDemo\n\n\nTSP\nGreedy\n \n\n\nCVRP\nMulti-Greedy\n \n\n\n\n\n\n\n\n\n\n\t\tInstallation\n\t\n\n\n\n\n\n\n\t\tConda\n\t\n\nconda env create -n <env name> -f environment.yml\n# The environment.yml was generated from\n# conda env export --no-builds > environment.yml\n\nIt can take a few minutes.\n\n\n\n\n\n\t\tOptional dependency\n\t\n\nwandb\nRefer to their quick start guide for installation.\n\n\n\n\n\n\t\tFile structures\n\t\n\nAll the major implementations were under rlor folder.\n./rlor\n\u251c\u2500\u2500 envs\n\u2502   \u251c\u2500\u2500 tsp_data.py # load pre-generated data for evaluation\n\u2502   \u251c\u2500\u2500 tsp_vector_env.py # define the (vectorized) gym environment\n\u2502   \u251c\u2500\u2500 cvrp_data.py \n\u2502   \u2514\u2500\u2500 cvrp_vector_env.py \n\u251c\u2500\u2500 models\n\u2502   \u251c\u2500\u2500 attention_model_wrapper.py # wrap refactored attention model to cleanRL\n\u2502   \u2514\u2500\u2500 nets # contains refactored attention model\n\u2514\u2500\u2500 ppo_or.py # implementaion of ppo with attention model for operation research problems\n\nThe ppo_or.py was modified from cleanrl/ppo.py. To see what's changed, use diff:\n# apt install diff\ndiff --color ppo.py ppo_or.py\n\n\n\n\n\n\n\t\tTraining OR model with PPO\n\t\n\n\n\n\n\n\n\t\tTSP\n\t\n\npython ppo_or.py --num-steps 51 --env-id tsp-v0 --env-entry-point envs.tsp_vector_env:TSPVectorEnv --problem tsp\n\n\n\n\n\n\n\t\tCVRP\n\t\n\npython ppo_or.py --num-steps 60 --env-id cvrp-v0 --env-entry-point envs.cvrp_vector_env:CVRPVectorEnv --problem cvrp\n\n\n\n\n\n\n\t\tEnable WandB\n\t\n\npython ppo_or.py ... --track\n\nAdd --track argument to enable tracking with WandB.\n\n\n\n\n\n\t\tWhere is the tsp data?\n\t\n\nIt can be generated from the official repo of the attention-learn-to-route paper. You may modify the ./envs/tsp_data.py to update the path to data accordingly.\n\n\n\n\n\n\t\tAcknowledgements\n\t\n\nThe neural network model is refactored and developed from Attention, Learn to Solve Routing Problems!.\nThe idea of multiple trajectory training/ inference is from POMO: Policy Optimization with Multiple Optima for Reinforcement Learning.\nThe RL environments are defined with OpenAI Gym.\nThe PPO algorithm implementation is based on CleanRL.\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\t\t\t\t\tSpace using\n\t\t\t\t\t\tcpwan/RLOR-TSP\n1\n\ud83d\udd0e\ncpwan/RLOR-TSP\n\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "MohammedEltoum/dqn-SpaceInvadersNoFrameskip-v4",
        "author": "MohammedEltoum",
        "model_name": "dqn-SpaceInvadersNoFrameskip-v4",
        "url": "https://huggingface.co/MohammedEltoum/dqn-SpaceInvadersNoFrameskip-v4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nMohammedEltoum\n/\ndqn-SpaceInvadersNoFrameskip-v4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga MohammedEltoum -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga MohammedEltoum -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga MohammedEltoum\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 1000000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n584.00 +/- 104.33\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "xnpeng/q-FrozenLake-v1-4x4-Slippery",
        "author": "xnpeng",
        "model_name": "q-FrozenLake-v1-4x4-Slippery",
        "url": "https://huggingface.co/xnpeng/q-FrozenLake-v1-4x4-Slippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nxnpeng\n/\nq-FrozenLake-v1-4x4-Slippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"xnpeng/q-FrozenLake-v1-4x4-Slippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4\nself-reported\n\t\t\t\t\t\t\t\n\n0.51 +/- 0.50\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "xnpeng/Taxi-v3",
        "author": "xnpeng",
        "model_name": "Taxi-v3",
        "url": "https://huggingface.co/xnpeng/Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nxnpeng\n/\nTaxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"xnpeng/Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.50 +/- 2.78\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ntrant7/LunarLander-v2",
        "author": "ntrant7",
        "model_name": "LunarLander-v2",
        "url": "https://huggingface.co/ntrant7/LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nntrant7\n/\nLunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n239.26 +/- 23.26\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ManishW/SoccerTwos_v0",
        "author": "ManishW",
        "model_name": "SoccerTwos_v0",
        "url": "https://huggingface.co/ManishW/SoccerTwos_v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nManishW\n/\nSoccerTwos_v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nunity-ml-agents\n\ndeep-reinforcement-learning\n\nML-Agents-SoccerTwos\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\npoca Agent playing SoccerTwos\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\npoca Agent playing SoccerTwos\n\n\n  This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos\nStep 1: Write your model_id: ManishW/SoccerTwos_v0\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "jwright94/ppo-LunarLander-v2",
        "author": "jwright94",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/jwright94/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njwright94\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nLunarLander-v2\n\nppo\n\ndeep-reinforcement-learning\n\ncustom-implementation\n\ndeep-rl-course\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent Playing LunarLander-v2\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\t\tPPO Agent Playing LunarLander-v2\n\t\n\n  This is a trained model of a PPO agent playing LunarLander-v2.\n\n\n\n\n\n\t\tHyperparameters\n\t\n\n{'experiment_name': 'final3'\n'env_name': 'LunarLander-v2'\n'learning_rate': 0.0003\n'seed': 1\n'total_timesteps': 125000\n'num_envs': 4\n'num_steps': 128\n'torch_deterministic': True\n'cuda': True\n'anneal_lr': True\n'gae': True\n'gamma': 0.99\n'gae_lambda': 0.95\n'num_minibatches': 4\n'update_epochs': 10\n'norm_adv': True\n'clip_coef': 0.2\n'clip_vloss': True\n'ent_coef': 0.01\n'vf_coef': 0.5\n'max_grad_norm': 0.5\n'save_video': True\n'batch_size': 512\n'mini_batch_size': 128}\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n96.70 +/- 99.97\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "justinsiow/ppo-LunarLander-v2-scratch",
        "author": "justinsiow",
        "model_name": "ppo-LunarLander-v2-scratch",
        "url": "https://huggingface.co/justinsiow/ppo-LunarLander-v2-scratch",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njustinsiow\n/\nppo-LunarLander-v2-scratch\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTensorBoard\n\nLunarLander-v2\n\nppo\n\ndeep-reinforcement-learning\n\ncustom-implementation\n\ndeep-rl-course\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent Playing LunarLander-v2\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\t\tPPO Agent Playing LunarLander-v2\n\t\n\n  This is a trained model of a PPO agent playing LunarLander-v2.\n\n\n\n\n\n\t\tHyperparameters\n\t\n\n{'exp_name': 'ppo'\n'seed': 1\n'torch_deterministic': True\n'cuda': True\n'track': False\n'wandb_project_name': 'cleanRL'\n'wandb_entity': None\n'capture_video': False\n'env_id': 'LunarLander-v2'\n'total_timesteps': 50000\n'learning_rate': 0.00025\n'num_envs': 4\n'num_steps': 128\n'anneal_lr': True\n'gae': True\n'gamma': 0.99\n'gae_lambda': 0.95\n'num_minibatches': 4\n'update_epochs': 4\n'norm_adv': True\n'clip_coef': 0.2\n'clip_vloss': True\n'ent_coef': 0.01\n'vf_coef': 0.5\n'max_grad_norm': 0.5\n'target_kl': None\n'repo_id': 'justinsiow/ppo-LunarLander-v2-scratch'\n'batch_size': 512\n'minibatch_size': 128}\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-153.95 +/- 91.84\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Issacwong/ppo-LunarLander-v2",
        "author": "Issacwong",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/Issacwong/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nIssacwong\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n271.24 +/- 15.82\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "PeterLOVANAS/ppo-Huggy",
        "author": "PeterLOVANAS",
        "model_name": "ppo-Huggy",
        "url": "https://huggingface.co/PeterLOVANAS/ppo-Huggy",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nPeterLOVANAS\n/\nppo-Huggy\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nHuggy\n\ndeep-reinforcement-learning\n\nML-Agents-Huggy\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Huggy\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Huggy\n\n\n  This is a trained model of a ppo agent playing Huggy using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Huggy\nStep 1: Find your model_id: PeterLOVANAS/ppo-Huggy\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "BlaqCosmos/ppo-LunarLander-v2",
        "author": "BlaqCosmos",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/BlaqCosmos/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nBlaqCosmos\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n283.33 +/- 21.89\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "xnpeng/q-Taxi-v3",
        "author": "xnpeng",
        "model_name": "q-Taxi-v3",
        "url": "https://huggingface.co/xnpeng/q-Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nxnpeng\n/\nq-Taxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"xnpeng/q-Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "justinsiow/rl_course_vizdoom_health_gathering_supreme",
        "author": "justinsiow",
        "model_name": "rl_course_vizdoom_health_gathering_supreme",
        "url": "https://huggingface.co/justinsiow/rl_course_vizdoom_health_gathering_supreme",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njustinsiow\n/\nrl_course_vizdoom_health_gathering_supreme\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nSample Factory\n\nTensorBoard\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in sample-factory\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\nA(n) APPO model trained on the doom_health_gathering_supreme environment.\nThis model was trained using Sample-Factory 2.0: https://github.com/alex-petrenko/sample-factory.\nDocumentation for how to use Sample-Factory can be found at https://www.samplefactory.dev/\n\n\n\n\n\n\t\tDownloading the model\n\t\n\nAfter installing Sample-Factory, download the model with:\npython -m sample_factory.huggingface.load_from_hub -r justinsiow/rl_course_vizdoom_health_gathering_supreme\n\n\n\n\n\n\n\t\tUsing the model\n\t\n\nTo run the model after download, use the enjoy script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme\n\nYou can also upload models to the Hugging Face Hub using the same script with the --push_to_hub flag.\nSee https://www.samplefactory.dev/10-huggingface/huggingface/ for more details\n\n\n\n\n\n\t\tTraining with this model\n\t\n\nTo continue training with this model, use the train script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme --restart_behavior=resume --train_for_env_steps=10000000000\n\nNote, you may have to adjust --train_for_env_steps to a suitably high number as the experiment will resume at the number of steps it concluded at.\n        \n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton doom_health_gathering_supreme\nself-reported\n\t\t\t\t\t\t\t\n\n8.22 +/- 3.72\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "justinsiow/rl_course_vizdoom_health_gathering_supreme-v2",
        "author": "justinsiow",
        "model_name": "rl_course_vizdoom_health_gathering_supreme-v2",
        "url": "https://huggingface.co/justinsiow/rl_course_vizdoom_health_gathering_supreme-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njustinsiow\n/\nrl_course_vizdoom_health_gathering_supreme-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nSample Factory\n\nTensorBoard\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in sample-factory\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\nA(n) APPO model trained on the doom_health_gathering_supreme environment.\nThis model was trained using Sample-Factory 2.0: https://github.com/alex-petrenko/sample-factory.\nDocumentation for how to use Sample-Factory can be found at https://www.samplefactory.dev/\n\n\n\n\n\n\t\tDownloading the model\n\t\n\nAfter installing Sample-Factory, download the model with:\npython -m sample_factory.huggingface.load_from_hub -r justinsiow/rl_course_vizdoom_health_gathering_supreme-v2\n\n\n\n\n\n\n\t\tUsing the model\n\t\n\nTo run the model after download, use the enjoy script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme-v2\n\nYou can also upload models to the Hugging Face Hub using the same script with the --push_to_hub flag.\nSee https://www.samplefactory.dev/10-huggingface/huggingface/ for more details\n\n\n\n\n\n\t\tTraining with this model\n\t\n\nTo continue training with this model, use the train script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme-v2 --restart_behavior=resume --train_for_env_steps=10000000000\n\nNote, you may have to adjust --train_for_env_steps to a suitably high number as the experiment will resume at the number of steps it concluded at.\n        \n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton doom_health_gathering_supreme\nself-reported\n\t\t\t\t\t\t\t\n\n11.03 +/- 4.46\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "jmurphy97/ppo-SnowballTarget1",
        "author": "jmurphy97",
        "model_name": "ppo-SnowballTarget1",
        "url": "https://huggingface.co/jmurphy97/ppo-SnowballTarget1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njmurphy97\n/\nppo-SnowballTarget1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://singularite.itch.io/snowballtarget\nStep 1: Find your model_id: jmurphy97/ppo-SnowballTarget1\nStep 2: Select your  SnowballTarget.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "checkRaiseOnCloud/ppo-lunar",
        "author": "checkRaiseOnCloud",
        "model_name": "ppo-lunar",
        "url": "https://huggingface.co/checkRaiseOnCloud/ppo-lunar",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ncheckRaiseOnCloud\n/\nppo-lunar\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n270.78 +/- 21.22\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Mihail-P/qrdqn-SpaceInvadersNoFrameskip-v4",
        "author": "Mihail-P",
        "model_name": "qrdqn-SpaceInvadersNoFrameskip-v4",
        "url": "https://huggingface.co/Mihail-P/qrdqn-SpaceInvadersNoFrameskip-v4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nMihail-P\n/\nqrdqn-SpaceInvadersNoFrameskip-v4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQRDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nQRDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a QRDQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo qrdqn --env SpaceInvadersNoFrameskip-v4 -orga Mihail-P -f logs/\npython -m rl_zoo3.enjoy --algo qrdqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo qrdqn --env SpaceInvadersNoFrameskip-v4 -orga Mihail-P -f logs/\npython -m rl_zoo3.enjoy --algo qrdqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo qrdqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo qrdqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga Mihail-P\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_fraction', 0.025),\n             ('frame_stack', 4),\n             ('n_timesteps', 10000000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n661.50 +/- 201.53\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "jmurphy97/ppo-Pyramids1",
        "author": "jmurphy97",
        "model_name": "ppo-Pyramids1",
        "url": "https://huggingface.co/jmurphy97/ppo-Pyramids1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njmurphy97\n/\nppo-Pyramids1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: jmurphy97/ppo-Pyramids1\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "RandenBanuelos/dqn-SpaceInvadersNoFrameskip-v4",
        "author": "RandenBanuelos",
        "model_name": "dqn-SpaceInvadersNoFrameskip-v4",
        "url": "https://huggingface.co/RandenBanuelos/dqn-SpaceInvadersNoFrameskip-v4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nRandenBanuelos\n/\ndqn-SpaceInvadersNoFrameskip-v4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga RandenBanuelos -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga RandenBanuelos -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga RandenBanuelos\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 1000000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n545.50 +/- 280.90\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "sooh-j/LunarLander",
        "author": "sooh-j",
        "model_name": "LunarLander",
        "url": "https://huggingface.co/sooh-j/LunarLander",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nsooh-j\n/\nLunarLander\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n271.08 +/- 16.67\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "dvesely/a2c-AntBulletEnv-v0",
        "author": "dvesely",
        "model_name": "a2c-AntBulletEnv-v0",
        "url": "https://huggingface.co/dvesely/a2c-AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ndvesely\n/\na2c-AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n2043.59 +/- 93.93\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "MarshallPF/a2c-PandaReachDense-v2",
        "author": "MarshallPF",
        "model_name": "a2c-PandaReachDense-v2",
        "url": "https://huggingface.co/MarshallPF/a2c-PandaReachDense-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nMarshallPF\n/\na2c-PandaReachDense-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nPandaReachDense-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing PandaReachDense-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing PandaReachDense-v2\n\n\nThis is a trained model of a A2C agent playing PandaReachDense-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton PandaReachDense-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-2.46 +/- 0.95\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Behnam/ppo-SnowballTarget",
        "author": "Behnam",
        "model_name": "ppo-SnowballTarget",
        "url": "https://huggingface.co/Behnam/ppo-SnowballTarget",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nBehnam\n/\nppo-SnowballTarget\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: Behnam/ppo-SnowballTarget\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Hristo/Pyramids",
        "author": "Hristo",
        "model_name": "Pyramids",
        "url": "https://huggingface.co/Hristo/Pyramids",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nHristo\n/\nPyramids\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: Hristo/Pyramids\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Behnam/ppo-Pyramid",
        "author": "Behnam",
        "model_name": "ppo-Pyramid",
        "url": "https://huggingface.co/Behnam/ppo-Pyramid",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nBehnam\n/\nppo-Pyramid\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: Behnam/ppo-Pyramid\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ajitgupta/q-FrozenLake-v1-4x4-noSlippery",
        "author": "ajitgupta",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/ajitgupta/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\najitgupta\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"ajitgupta/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ajitgupta/q-Taxi-v3",
        "author": "ajitgupta",
        "model_name": "q-Taxi-v3",
        "url": "https://huggingface.co/ajitgupta/q-Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\najitgupta\n/\nq-Taxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"ajitgupta/q-Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "egarciamartin/ppo-LunarLander-v2",
        "author": "egarciamartin",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/egarciamartin/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\negarciamartin\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTransformers\n\nTensorBoard\n\nLunarLander-v2\n\nppo\n\ndeep-reinforcement-learning\n\ncustom-implementation\n\ndeep-rl-course\n\nEval Results\n\nInference Endpoints\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\t\t\tTrain\n\t\t\n\n\n\n\n\n\t\t\tDeploy\n\t\t\n\n\n\n\t\tUse in Transformers\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent Playing LunarLander-v2\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\t\tPPO Agent Playing LunarLander-v2\n\t\n\n  This is a trained model of a PPO agent playing LunarLander-v2.\n\n\n\n\n\n\t\tHyperparameters\n\t\n\n{'exp_name': 'ppo'\n'seed': 1\n'torch_deterministic': True\n'cuda': True\n'track': False\n'wandb_project_name': 'cleanRL'\n'wandb_entity': None\n'capture_video': False\n'env_id': 'LunarLander-v2'\n'total_timesteps': 220000\n'learning_rate': 0.00025\n'num_envs': 4\n'num_steps': 64\n'anneal_lr': True\n'gae': True\n'gamma': 0.99\n'gae_lambda': 0.95\n'num_minibatches': 4\n'update_epochs': 4\n'norm_adv': True\n'clip_coef': 0.2\n'clip_vloss': True\n'ent_coef': 0.01\n'vf_coef': 0.5\n'max_grad_norm': 0.5\n'target_kl': None\n'repo_id': 'egarciamartin/ppo-LunarLander-v2'\n'batch_size': 256\n'minibatch_size': 64}\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n41.45 +/- 84.63\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Augcos/a2c-PandaReachDense-v2",
        "author": "Augcos",
        "model_name": "a2c-PandaReachDense-v2",
        "url": "https://huggingface.co/Augcos/a2c-PandaReachDense-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nAugcos\n/\na2c-PandaReachDense-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nPandaReachDense-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing PandaReachDense-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing PandaReachDense-v2\n\n\nThis is a trained model of a A2C agent playing PandaReachDense-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton PandaReachDense-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-2.59 +/- 0.51\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Bandika/PGRAD_Pytorch_CartPole-v1",
        "author": "Bandika",
        "model_name": "PGRAD_Pytorch_CartPole-v1",
        "url": "https://huggingface.co/Bandika/PGRAD_Pytorch_CartPole-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nBandika\n/\nPGRAD_Pytorch_CartPole-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "egarciamartin/e",
        "author": "egarciamartin",
        "model_name": "e",
        "url": "https://huggingface.co/egarciamartin/e",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\negarciamartin\n/\ne\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nHuggy\n\ndeep-reinforcement-learning\n\nML-Agents-Huggy\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Huggy\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Huggy\n\n\n  This is a trained model of a ppo agent playing Huggy using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Huggy\nStep 1: Find your model_id: egarciamartin/e\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "egarciamartin/ppo-Huggy",
        "author": "egarciamartin",
        "model_name": "ppo-Huggy",
        "url": "https://huggingface.co/egarciamartin/ppo-Huggy",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\negarciamartin\n/\nppo-Huggy\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nHuggy\n\ndeep-reinforcement-learning\n\nML-Agents-Huggy\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Huggy\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Huggy\n\n\n  This is a trained model of a ppo agent playing Huggy using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Huggy\nStep 1: Find your model_id: egarciamartin/PPO-Huggy\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "infatum/a2c-AntBulletEnv-v0",
        "author": "infatum",
        "model_name": "a2c-AntBulletEnv-v0",
        "url": "https://huggingface.co/infatum/a2c-AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ninfatum\n/\na2c-AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n1675.16 +/- 136.29\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "exiaxu/Reinforce-1",
        "author": "exiaxu",
        "model_name": "Reinforce-1",
        "url": "https://huggingface.co/exiaxu/Reinforce-1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nexiaxu\n/\nReinforce-1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "sarahpuspdew/DeepRLCourse_Unit2-q-FrozenLake-v1-4x4-noSlippery",
        "author": "sarahpuspdew",
        "model_name": "DeepRLCourse_Unit2-q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/sarahpuspdew/DeepRLCourse_Unit2-q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nsarahpuspdew\n/\nDeepRLCourse_Unit2-q-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"sarahpuspdew/DeepRLCourse_Unit2-q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "sarahpuspdew/DeepRLCourse_Unit2-q-Taxi-v3",
        "author": "sarahpuspdew",
        "model_name": "DeepRLCourse_Unit2-q-Taxi-v3",
        "url": "https://huggingface.co/sarahpuspdew/DeepRLCourse_Unit2-q-Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nsarahpuspdew\n/\nDeepRLCourse_Unit2-q-Taxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"sarahpuspdew/DeepRLCourse_Unit2-q-Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.56 +/- 2.71\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "donskerclass/ppo-LunarLander-v2test",
        "author": "donskerclass",
        "model_name": "ppo-LunarLander-v2test",
        "url": "https://huggingface.co/donskerclass/ppo-LunarLander-v2test",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ndonskerclass\n/\nppo-LunarLander-v2test\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n264.01 +/- 20.92\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "asubiabre/ppo-SnowballTarget",
        "author": "asubiabre",
        "model_name": "ppo-SnowballTarget",
        "url": "https://huggingface.co/asubiabre/ppo-SnowballTarget",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nasubiabre\n/\nppo-SnowballTarget\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: asubiabre/ppo-SnowballTarget\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "feabries/LunarLander-v2",
        "author": "feabries",
        "model_name": "LunarLander-v2",
        "url": "https://huggingface.co/feabries/LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nfeabries\n/\nLunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTensorBoard\n\nLunarLander-v2\n\nppo\n\ndeep-reinforcement-learning\n\ncustom-implementation\n\ndeep-rl-course\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent Playing LunarLander-v2\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\t\tPPO Agent Playing LunarLander-v2\n\t\n\n  This is a trained model of a PPO agent playing LunarLander-v2.\n\n\n\n\n\n\t\tHyperparameters\n\t\n\n{'exp_name': 'ppo'\n'seed': 1\n'torch_deterministic': True\n'cuda': True\n'track': False\n'wandb_project_name': 'cleanRL'\n'wandb_entity': None\n'capture_video': False\n'env_id': 'LunarLander-v2'\n'total_timesteps': 50000\n'learning_rate': 0.00025\n'num_envs': 4\n'num_steps': 128\n'anneal_lr': True\n'gae': True\n'gamma': 0.99\n'gae_lambda': 0.95\n'num_minibatches': 4\n'update_epochs': 4\n'norm_adv': True\n'clip_coef': 0.2\n'clip_vloss': True\n'ent_coef': 0.01\n'vf_coef': 0.5\n'max_grad_norm': 0.5\n'target_kl': None\n'repo_id': 'feabries/LunarLander-v2'\n'batch_size': 512\n'minibatch_size': 128}\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-145.76 +/- 60.59\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "infatum/a2c-PandaReachDense-v2",
        "author": "infatum",
        "model_name": "a2c-PandaReachDense-v2",
        "url": "https://huggingface.co/infatum/a2c-PandaReachDense-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ninfatum\n/\na2c-PandaReachDense-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nPandaReachDense-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing PandaReachDense-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing PandaReachDense-v2\n\n\nThis is a trained model of a A2C agent playing PandaReachDense-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton PandaReachDense-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-0.82 +/- 0.06\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "glitchyordis/a2c-AntBulletEnv-v0",
        "author": "glitchyordis",
        "model_name": "a2c-AntBulletEnv-v0",
        "url": "https://huggingface.co/glitchyordis/a2c-AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nglitchyordis\n/\na2c-AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n1452.45 +/- 69.55\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "flowerpot76/q-FrozenLake-v1-4x4-noSlippery",
        "author": "flowerpot76",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/flowerpot76/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nflowerpot76\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"flowerpot76/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "flowerpot76/q-Taxi-v3",
        "author": "flowerpot76",
        "model_name": "q-Taxi-v3",
        "url": "https://huggingface.co/flowerpot76/q-Taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nflowerpot76\n/\nq-Taxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"flowerpot76/q-Taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.48 +/- 2.76\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Hadar-97/ppo-Huggy",
        "author": "Hadar-97",
        "model_name": "ppo-Huggy",
        "url": "https://huggingface.co/Hadar-97/ppo-Huggy",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nHadar-97\n/\nppo-Huggy\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nHuggy\n\ndeep-reinforcement-learning\n\nML-Agents-Huggy\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Huggy\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Huggy\n\n\n  This is a trained model of a ppo agent playing Huggy using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Huggy\nStep 1: Find your model_id: Hadar-97/ppo-Huggy\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "pinaggle/ppo-SnowballTarget",
        "author": "pinaggle",
        "model_name": "ppo-SnowballTarget",
        "url": "https://huggingface.co/pinaggle/ppo-SnowballTarget",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\npinaggle\n/\nppo-SnowballTarget\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: pinaggle/ppo-SnowballTarget\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "TahsinZaman/ppo-SnowballTargetTESTCOLAB",
        "author": "TahsinZaman",
        "model_name": "ppo-SnowballTargetTESTCOLAB",
        "url": "https://huggingface.co/TahsinZaman/ppo-SnowballTargetTESTCOLAB",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nTahsinZaman\n/\nppo-SnowballTargetTESTCOLAB\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: TahsinZaman/ppo-SnowballTargetTESTCOLAB\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "HazelMak/ppo-LunarLander-v2",
        "author": "HazelMak",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/HazelMak/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nHazelMak\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n247.83 +/- 20.09\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Flooow/Reinforce-CartPole-v1",
        "author": "Flooow",
        "model_name": "Reinforce-CartPole-v1",
        "url": "https://huggingface.co/Flooow/Reinforce-CartPole-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nFlooow\n/\nReinforce-CartPole-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n496.75 +/- 27.09\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "glitchyordis/a2c-PandaReachDense-v2",
        "author": "glitchyordis",
        "model_name": "a2c-PandaReachDense-v2",
        "url": "https://huggingface.co/glitchyordis/a2c-PandaReachDense-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nglitchyordis\n/\na2c-PandaReachDense-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nPandaReachDense-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing PandaReachDense-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing PandaReachDense-v2\n\n\nThis is a trained model of a A2C agent playing PandaReachDense-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton PandaReachDense-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-1.25 +/- 0.28\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "pinaggle/ppo-PyramidsRND",
        "author": "pinaggle",
        "model_name": "ppo-PyramidsRND",
        "url": "https://huggingface.co/pinaggle/ppo-PyramidsRND",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\npinaggle\n/\nppo-PyramidsRND\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: pinaggle/ppo-PyramidsRND\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "feabries/rl_course_vizdoom_health_gathering_supreme",
        "author": "feabries",
        "model_name": "rl_course_vizdoom_health_gathering_supreme",
        "url": "https://huggingface.co/feabries/rl_course_vizdoom_health_gathering_supreme",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nfeabries\n/\nrl_course_vizdoom_health_gathering_supreme\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nSample Factory\n\nTensorBoard\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in sample-factory\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\n\nA(n) APPO model trained on the doom_health_gathering_supreme environment.\nThis model was trained using Sample-Factory 2.0: https://github.com/alex-petrenko/sample-factory.\nDocumentation for how to use Sample-Factory can be found at https://www.samplefactory.dev/\n\n\n\n\n\n\t\tDownloading the model\n\t\n\nAfter installing Sample-Factory, download the model with:\npython -m sample_factory.huggingface.load_from_hub -r feabries/rl_course_vizdoom_health_gathering_supreme\n\n\n\n\n\n\n\t\tUsing the model\n\t\n\nTo run the model after download, use the enjoy script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme\n\nYou can also upload models to the Hugging Face Hub using the same script with the --push_to_hub flag.\nSee https://www.samplefactory.dev/10-huggingface/huggingface/ for more details\n\n\n\n\n\n\t\tTraining with this model\n\t\n\nTo continue training with this model, use the train script corresponding to this environment:\npython -m .usr.local.lib.python3.9.dist-packages.ipykernel_launcher --algo=APPO --env=doom_health_gathering_supreme --train_dir=./train_dir --experiment=rl_course_vizdoom_health_gathering_supreme --restart_behavior=resume --train_for_env_steps=10000000000\n\nNote, you may have to adjust --train_for_env_steps to a suitably high number as the experiment will resume at the number of steps it concluded at.\n        \n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton doom_health_gathering_supreme\nself-reported\n\t\t\t\t\t\t\t\n\n10.50 +/- 5.18\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "WasuratS/Reinforce-CartPole-v2",
        "author": "WasuratS",
        "model_name": "Reinforce-CartPole-v2",
        "url": "https://huggingface.co/WasuratS/Reinforce-CartPole-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nWasuratS\n/\nReinforce-CartPole-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "dylwil3/reinforce-cartpole-v1",
        "author": "dylwil3",
        "model_name": "reinforce-cartpole-v1",
        "url": "https://huggingface.co/dylwil3/reinforce-cartpole-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ndylwil3\n/\nreinforce-cartpole-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n450.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "FabienDaniel/Cartpole-v1",
        "author": "FabienDaniel",
        "model_name": "Cartpole-v1",
        "url": "https://huggingface.co/FabienDaniel/Cartpole-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nFabienDaniel\n/\nCartpole-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n483.40 +/- 72.36\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "vikidance01/q-FrozenLake-v1-4x4-noSlippery",
        "author": "vikidance01",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/vikidance01/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nvikidance01\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-8x8\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"vikidance01/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-8x8\nself-reported\n\t\t\t\t\t\t\t\n\n0.12 +/- 0.32\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "vikidance01/taxi-v3",
        "author": "vikidance01",
        "model_name": "taxi-v3",
        "url": "https://huggingface.co/vikidance01/taxi-v3",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nvikidance01\n/\ntaxi-v3\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTaxi-v3\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 Taxi-v3\n\n\n  This is a trained model of a Q-Learning agent playing Taxi-v3 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"vikidance01/taxi-v3\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Taxi-v3\nself-reported\n\t\t\t\t\t\t\t\n\n7.46 +/- 2.78\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Hristo/a2c-AntBulletEnv-v0",
        "author": "Hristo",
        "model_name": "a2c-AntBulletEnv-v0",
        "url": "https://huggingface.co/Hristo/a2c-AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nHristo\n/\na2c-AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n1467.78 +/- 93.57\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "mobiusmatt/a2c-AntBulletEnv-v0",
        "author": "mobiusmatt",
        "model_name": "a2c-AntBulletEnv-v0",
        "url": "https://huggingface.co/mobiusmatt/a2c-AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nmobiusmatt\n/\na2c-AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n1540.62 +/- 456.59\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "OMARS200/SpaceInvadersNoFrameskip-v4",
        "author": "OMARS200",
        "model_name": "SpaceInvadersNoFrameskip-v4",
        "url": "https://huggingface.co/OMARS200/SpaceInvadersNoFrameskip-v4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nOMARS200\n/\nSpaceInvadersNoFrameskip-v4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga OMARS200 -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga OMARS200 -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga OMARS200\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 1000000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n587.50 +/- 217.47\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "email81227/dqn-SpaceInvadersNoFrameskip-v4",
        "author": "email81227",
        "model_name": "dqn-SpaceInvadersNoFrameskip-v4",
        "url": "https://huggingface.co/email81227/dqn-SpaceInvadersNoFrameskip-v4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nemail81227\n/\ndqn-SpaceInvadersNoFrameskip-v4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga email81227 -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga email81227 -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga email81227\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 128),\n             ('buffer_size', 64000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.05),\n             ('exploration_fraction', 0.15),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.005),\n             ('learning_starts', 1000),\n             ('n_timesteps', 1000000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n246.00 +/- 45.65\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "jmurphy97/a2c-AntBulletEnv-v0",
        "author": "jmurphy97",
        "model_name": "a2c-AntBulletEnv-v0",
        "url": "https://huggingface.co/jmurphy97/a2c-AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njmurphy97\n/\na2c-AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n1317.09 +/- 109.12\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "yingzhi/dqn-SpaceInvadersNoFrameskip-v4",
        "author": "yingzhi",
        "model_name": "dqn-SpaceInvadersNoFrameskip-v4",
        "url": "https://huggingface.co/yingzhi/dqn-SpaceInvadersNoFrameskip-v4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nyingzhi\n/\ndqn-SpaceInvadersNoFrameskip-v4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga yingzhi -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga yingzhi -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga yingzhi\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 1000000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n449.00 +/- 151.11\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "asubiabre/ppo-PyramidsTraining",
        "author": "asubiabre",
        "model_name": "ppo-PyramidsTraining",
        "url": "https://huggingface.co/asubiabre/ppo-PyramidsTraining",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nasubiabre\n/\nppo-PyramidsTraining\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: asubiabre/ppo-PyramidsTraining\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "girtss3/LunarLanding",
        "author": "girtss3",
        "model_name": "LunarLanding",
        "url": "https://huggingface.co/girtss3/LunarLanding",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ngirtss3\n/\nLunarLanding\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n246.13 +/- 23.81\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "jmurphy97/a2c-PandaReachDense-v2",
        "author": "jmurphy97",
        "model_name": "a2c-PandaReachDense-v2",
        "url": "https://huggingface.co/jmurphy97/a2c-PandaReachDense-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njmurphy97\n/\na2c-PandaReachDense-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nPandaReachDense-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing PandaReachDense-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing PandaReachDense-v2\n\n\nThis is a trained model of a A2C agent playing PandaReachDense-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton PandaReachDense-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-4.12 +/- 1.05\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Danihu/ppo-LunarLander-v2",
        "author": "Danihu",
        "model_name": "ppo-LunarLander-v2",
        "url": "https://huggingface.co/Danihu/ppo-LunarLander-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nDanihu\n/\nppo-LunarLander-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n250.87 +/- 14.90\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "xerl/Cartpole-v1",
        "author": "xerl",
        "model_name": "Cartpole-v1",
        "url": "https://huggingface.co/xerl/Cartpole-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nxerl\n/\nCartpole-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "sofiapecora/ppo-SnowballTarget",
        "author": "sofiapecora",
        "model_name": "ppo-SnowballTarget",
        "url": "https://huggingface.co/sofiapecora/ppo-SnowballTarget",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nsofiapecora\n/\nppo-SnowballTarget\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: sofiapecora/ppo-SnowballTarget\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "J3/poca-SoccerTwos_ver1",
        "author": "J3",
        "model_name": "poca-SoccerTwos_ver1",
        "url": "https://huggingface.co/J3/poca-SoccerTwos_ver1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nJ3\n/\npoca-SoccerTwos_ver1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nunity-ml-agents\n\ndeep-reinforcement-learning\n\nML-Agents-SoccerTwos\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\npoca Agent playing SoccerTwos\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\npoca Agent playing SoccerTwos\n\n\n  This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos\nStep 1: Write your model_id: J3/poca-SoccerTwos_ver1\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "thackerhelik/ppo-Huggy",
        "author": "thackerhelik",
        "model_name": "ppo-Huggy",
        "url": "https://huggingface.co/thackerhelik/ppo-Huggy",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nthackerhelik\n/\nppo-Huggy\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nHuggy\n\ndeep-reinforcement-learning\n\nML-Agents-Huggy\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Huggy\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Huggy\n\n\n  This is a trained model of a ppo agent playing Huggy using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Huggy\nStep 1: Find your model_id: thackerhelik/ppo-Huggy\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "snicolau/Reinforce-CartPole-v1",
        "author": "snicolau",
        "model_name": "Reinforce-CartPole-v1",
        "url": "https://huggingface.co/snicolau/Reinforce-CartPole-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nsnicolau\n/\nReinforce-CartPole-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Smone55/q-FrozenLake-v1-4x4-noSlippery",
        "author": "Smone55",
        "model_name": "q-FrozenLake-v1-4x4-noSlippery",
        "url": "https://huggingface.co/Smone55/q-FrozenLake-v1-4x4-noSlippery",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nSmone55\n/\nq-FrozenLake-v1-4x4-noSlippery\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nFrozenLake-v1-4x4-no_slippery\n\nq-learning\n\ncustom-implementation\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\nUsage\n\n\n\n\n\n\n\n\n\n\nQ-Learning Agent playing1 FrozenLake-v1\n\n\n  This is a trained model of a Q-Learning agent playing FrozenLake-v1 .\n\n\n\n\n\n\t\tUsage\n\t\n\n\nmodel = load_from_hub(repo_id=\"Smone55/q-FrozenLake-v1-4x4-noSlippery\", filename=\"q-learning.pkl\")\n\n# Don't forget to check if you need to add additional attributes (is_slippery=False etc)\nenv = gym.make(model[\"env_id\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton FrozenLake-v1-4x4-no_slippery\nself-reported\n\t\t\t\t\t\t\t\n\n1.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "TahsinZaman/ppo-Pyramids-TESTCOLAB",
        "author": "TahsinZaman",
        "model_name": "ppo-Pyramids-TESTCOLAB",
        "url": "https://huggingface.co/TahsinZaman/ppo-Pyramids-TESTCOLAB",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nTahsinZaman\n/\nppo-Pyramids-TESTCOLAB\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: TahsinZaman/ppo-Pyramids-TESTCOLAB\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "jmurphy97/poca-SoccerTwos",
        "author": "jmurphy97",
        "model_name": "poca-SoccerTwos",
        "url": "https://huggingface.co/jmurphy97/poca-SoccerTwos",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\njmurphy97\n/\npoca-SoccerTwos\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nTensorBoard\n\nONNX\n\nunity-ml-agents\n\ndeep-reinforcement-learning\n\nML-Agents-SoccerTwos\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\npoca Agent playing SoccerTwos\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\npoca Agent playing SoccerTwos\n\n\n  This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SoccerTwos\nStep 1: Write your model_id: jmurphy97/poca-SoccerTwos\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Flooow/Reinforce-Pixelcopter-PLE-v0",
        "author": "Flooow",
        "model_name": "Reinforce-Pixelcopter-PLE-v0",
        "url": "https://huggingface.co/Flooow/Reinforce-Pixelcopter-PLE-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nFlooow\n/\nReinforce-Pixelcopter-PLE-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n19.00 +/- 13.38\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "TahsinZaman/a2c-AntBulletEnv-v0",
        "author": "TahsinZaman",
        "model_name": "a2c-AntBulletEnv-v0",
        "url": "https://huggingface.co/TahsinZaman/a2c-AntBulletEnv-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nTahsinZaman\n/\na2c-AntBulletEnv-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nAntBulletEnv-v0\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing AntBulletEnv-v0\n\n\nThis is a trained model of a A2C agent playing AntBulletEnv-v0\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton AntBulletEnv-v0\nself-reported\n\t\t\t\t\t\t\t\n\n1600.61 +/- 277.97\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "odeshays/unit_1_recsys",
        "author": "odeshays",
        "model_name": "unit_1_recsys",
        "url": "https://huggingface.co/odeshays/unit_1_recsys",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nodeshays\n/\nunit_1_recsys\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n259.38 +/- 24.41\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "albertcalin/dqn-SpaceInvadersNoFrameskip-v4",
        "author": "albertcalin",
        "model_name": "dqn-SpaceInvadersNoFrameskip-v4",
        "url": "https://huggingface.co/albertcalin/dqn-SpaceInvadersNoFrameskip-v4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nalbertcalin\n/\ndqn-SpaceInvadersNoFrameskip-v4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga albertcalin -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga albertcalin -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga albertcalin\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 64),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 1000000.0),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n569.50 +/- 128.60\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "ajitgupta/Reinforce-CartPole-v1",
        "author": "ajitgupta",
        "model_name": "Reinforce-CartPole-v1",
        "url": "https://huggingface.co/ajitgupta/Reinforce-CartPole-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\najitgupta\n/\nReinforce-CartPole-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "TahsinZaman/a2c-PandaReachDense-v2",
        "author": "TahsinZaman",
        "model_name": "a2c-PandaReachDense-v2",
        "url": "https://huggingface.co/TahsinZaman/a2c-PandaReachDense-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nTahsinZaman\n/\na2c-PandaReachDense-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nPandaReachDense-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing PandaReachDense-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing PandaReachDense-v2\n\n\nThis is a trained model of a A2C agent playing PandaReachDense-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton PandaReachDense-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-2.61 +/- 0.67\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "sonny-dev/ppo-SnowballTargetTESTCOLAB",
        "author": "sonny-dev",
        "model_name": "ppo-SnowballTargetTESTCOLAB",
        "url": "https://huggingface.co/sonny-dev/ppo-SnowballTargetTESTCOLAB",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nsonny-dev\n/\nppo-SnowballTargetTESTCOLAB\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nSnowballTarget\n\ndeep-reinforcement-learning\n\nML-Agents-SnowballTarget\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing SnowballTarget\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing SnowballTarget\n\n\n  This is a trained model of a ppo agent playing SnowballTarget using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-SnowballTarget\nStep 1: Find your model_id: sonny-dev/ppo-SnowballTargetTESTCOLAB\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "dshin/flan-t5-ppo-user-a-allenai-prosocial-dialog-testing-upload",
        "author": "dshin",
        "model_name": "flan-t5-ppo-user-a-allenai-prosocial-dialog-testing-upload",
        "url": "https://huggingface.co/dshin/flan-t5-ppo-user-a-allenai-prosocial-dialog-testing-upload",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ndshin\n/\nflan-t5-ppo-user-a-allenai-prosocial-dialog-testing-upload\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTransformers\n\nPyTorch\n\nt5\n\ntext2text-generation\n\ntrl\n\nInference Endpoints\n\ntext-generation-inference\n\n\n\nLicense: \napache-2.0\n\n\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\t\t\tTrain\n\t\t\n\n\n\n\n\n\t\t\tDeploy\n\t\t\n\n\n\n\t\tUse in Transformers\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nTRL Model\nUsage\n\n\n\n\n\n\n\n\n\n\n\t\tTRL Model\n\t\n\nThis is a TRL language model that has been fine-tuned with reinforcement learning to\n guide the model outputs according to a value, function, or human feedback. The model can be used for text generation.\n\n\n\n\n\n\t\tUsage\n\t\n\nTo use this model for inference, first install the TRL library:\npython -m pip install trl\n\nYou can then generate text as follows:\nfrom transformers import pipeline\n\ngenerator = pipeline(\"text-generation\", model=\"dshin//tmp/tmp8em290cn/dshin/flan-t5-ppo-user-a-allenai-prosocial-dialog-testing-upload\")\noutputs = generator(\"Hello, my llama is cute\")\n\nIf you want to use the model for training or to obtain the outputs from the value head, load the model as follows:\nfrom transformers import AutoTokenizer\nfrom trl import AutoModelForCausalLMWithValueHead\n\ntokenizer = AutoTokenizer.from_pretrained(\"dshin//tmp/tmp8em290cn/dshin/flan-t5-ppo-user-a-allenai-prosocial-dialog-testing-upload\")\nmodel = AutoModelForCausalLMWithValueHead.from_pretrained(\"dshin//tmp/tmp8em290cn/dshin/flan-t5-ppo-user-a-allenai-prosocial-dialog-testing-upload\")\n\ninputs = tokenizer(\"Hello, my llama is cute\", return_tensors=\"pt\")\noutputs = model(**inputs, labels=inputs[\"input_ids\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "snicolau/Reinforce-Pixelcopter-PLE-v0",
        "author": "snicolau",
        "model_name": "Reinforce-Pixelcopter-PLE-v0",
        "url": "https://huggingface.co/snicolau/Reinforce-Pixelcopter-PLE-v0",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nsnicolau\n/\nReinforce-Pixelcopter-PLE-v0\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nPixelcopter-PLE-v0\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n\n\n\n\n\n\n\nReinforce Agent playing Pixelcopter-PLE-v0\n\n\n  This is a trained model of a Reinforce agent playing Pixelcopter-PLE-v0 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton Pixelcopter-PLE-v0\nself-reported\n\t\t\t\t\t\t\t\n\n24.80 +/- 9.90\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "dshin/flan-t5-ppo-user-a-allenai-prosocial-dialog",
        "author": "dshin",
        "model_name": "flan-t5-ppo-user-a-allenai-prosocial-dialog",
        "url": "https://huggingface.co/dshin/flan-t5-ppo-user-a-allenai-prosocial-dialog",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\ndshin\n/\nflan-t5-ppo-user-a-allenai-prosocial-dialog\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTransformers\n\nPyTorch\n\nt5\n\ntext2text-generation\n\ntrl\n\nInference Endpoints\n\ntext-generation-inference\n\n\n\nLicense: \napache-2.0\n\n\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\tTrain\n\t\t\n\n\n\n\n\n\t\t\tDeploy\n\t\t\n\n\n\n\t\tUse in Transformers\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nTRL Model\nUsage\n\n\n\n\n\n\n\n\n\n\n\t\tTRL Model\n\t\n\nThis is a TRL language model that has been fine-tuned with reinforcement learning to\n guide the model outputs according to a value, function, or human feedback. The model can be used for text generation.\n\n\n\n\n\n\t\tUsage\n\t\n\nTo use this model for inference, first install the TRL library:\npython -m pip install trl\n\nYou can then generate text as follows:\nfrom transformers import pipeline\n\ngenerator = pipeline(\"text-generation\", model=\"dshin//tmp/tmpw0kwbx78/dshin/flan-t5-ppo-user-a-allenai-prosocial-dialog\")\noutputs = generator(\"Hello, my llama is cute\")\n\nIf you want to use the model for training or to obtain the outputs from the value head, load the model as follows:\nfrom transformers import AutoTokenizer\nfrom trl import AutoModelForCausalLMWithValueHead\n\ntokenizer = AutoTokenizer.from_pretrained(\"dshin//tmp/tmpw0kwbx78/dshin/flan-t5-ppo-user-a-allenai-prosocial-dialog\")\nmodel = AutoModelForCausalLMWithValueHead.from_pretrained(\"dshin//tmp/tmpw0kwbx78/dshin/flan-t5-ppo-user-a-allenai-prosocial-dialog\")\n\ninputs = tokenizer(\"Hello, my llama is cute\", return_tensors=\"pt\")\noutputs = model(**inputs, labels=inputs[\"input_ids\"])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "priteshkeleven/LunarLander-V2",
        "author": "priteshkeleven",
        "model_name": "LunarLander-V2",
        "url": "https://huggingface.co/priteshkeleven/LunarLander-V2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\npriteshkeleven\n/\nLunarLander-V2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nLunarLander-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent playing LunarLander-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nPPO Agent playing LunarLander-v2\n\n\nThis is a trained model of a PPO agent playing LunarLander-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n267.61 +/- 19.50\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "Yanrds/dqn-SpaceInvadersNoFrameskip-v4",
        "author": "Yanrds",
        "model_name": "dqn-SpaceInvadersNoFrameskip-v4",
        "url": "https://huggingface.co/Yanrds/dqn-SpaceInvadersNoFrameskip-v4",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nYanrds\n/\ndqn-SpaceInvadersNoFrameskip-v4\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nSpaceInvadersNoFrameskip-v4\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\nUsage (with SB3 RL Zoo)\n\nTraining (with the RL Zoo)\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\nDQN Agent playing SpaceInvadersNoFrameskip-v4\n\n\nThis is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4\nusing the stable-baselines3 library\nand the RL Zoo.\nThe RL Zoo is a training framework for Stable Baselines3\nreinforcement learning agents,\nwith hyperparameter optimization and pre-trained agents included.\n\n\n\n\n\n\t\tUsage (with SB3 RL Zoo)\n\t\n\nRL Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nSB3: https://github.com/DLR-RM/stable-baselines3\nSB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nInstall the RL Zoo (with SB3 and SB3-Contrib):\npip install rl_zoo3\n\n# Download model and save it into the logs/ folder\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga Yanrds -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\nIf you installed the RL Zoo3 via pip (pip install rl_zoo3), from anywhere you can do:\npython -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -orga Yanrds -f logs/\npython -m rl_zoo3.enjoy --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/\n\n\n\n\n\n\n\t\tTraining (with the RL Zoo)\n\t\n\npython -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/\n# Upload the model and generate video (when possible)\npython -m rl_zoo3.push_to_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga Yanrds\n\n\n\n\n\n\n\t\tHyperparameters\n\t\n\nOrderedDict([('batch_size', 32),\n             ('buffer_size', 100000),\n             ('env_wrapper',\n              ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n             ('exploration_final_eps', 0.01),\n             ('exploration_fraction', 0.1),\n             ('frame_stack', 4),\n             ('gradient_steps', 1),\n             ('learning_rate', 0.0001),\n             ('learning_starts', 100000),\n             ('n_timesteps', 1000000),\n             ('optimize_memory_usage', False),\n             ('policy', 'CnnPolicy'),\n             ('target_update_interval', 1000),\n             ('train_freq', 4),\n             ('normalize', False)])\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton SpaceInvadersNoFrameskip-v4\nself-reported\n\t\t\t\t\t\t\t\n\n650.00 +/- 165.74\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "sonny-dev/ppo-Pyramids",
        "author": "sonny-dev",
        "model_name": "ppo-Pyramids",
        "url": "https://huggingface.co/sonny-dev/ppo-Pyramids",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nsonny-dev\n/\nppo-Pyramids\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nUnity ML-Agents\n\nPyramids\n\ndeep-reinforcement-learning\n\nML-Agents-Pyramids\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\t\tUse in ml-agents\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nppo Agent playing Pyramids\nUsage (with ML-Agents)\nResume the training\nWatch your Agent play\n\n\n\n\n\n\n\n\n\n\nppo Agent playing Pyramids\n\n\n  This is a trained model of a ppo agent playing Pyramids using the Unity ML-Agents Library.\n\n\n\n\n\n\t\tUsage (with ML-Agents)\n\t\n\n  The Documentation: https://github.com/huggingface/ml-agents#get-started\n  We wrote a complete tutorial to learn to train your first agent using ML-Agents and publish it to the Hub:\n\n\n\n\n\n\t\tResume the training\n\t\n\nmlagents-learn <your_configuration_file_path.yaml> --run-id=<run_id> --resume\n\n\n\n\n\n\n\t\tWatch your Agent play\n\t\n\n  You can watch your agent playing directly in your browser:.\n\nGo to https://huggingface.co/spaces/unity/ML-Agents-Pyramids\nStep 1: Find your model_id: sonny-dev/ppo-Pyramids\nStep 2: Select your .nn /.onnx file\nClick on Watch the agent play \ud83d\udc40\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "mobiusmatt/a2c-PandaReachDense-v2",
        "author": "mobiusmatt",
        "model_name": "a2c-PandaReachDense-v2",
        "url": "https://huggingface.co/mobiusmatt/a2c-PandaReachDense-v2",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nmobiusmatt\n/\na2c-PandaReachDense-v2\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nStable-Baselines3\n\nPandaReachDense-v2\n\ndeep-reinforcement-learning\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t1\n\t\t\t\t\n\n\n\n\n\n\n\n\n\t\tUse in stable-baselines3\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nA2C Agent playing PandaReachDense-v2\nUsage (with Stable-baselines3)\n\n\n\n\n\n\n\n\n\n\nA2C Agent playing PandaReachDense-v2\n\n\nThis is a trained model of a A2C agent playing PandaReachDense-v2\nusing the stable-baselines3 library.\n\n\n\n\n\n\t\tUsage (with Stable-baselines3)\n\t\n\nTODO: Add your code\nfrom stable_baselines3 import ...\nfrom huggingface_sb3 import load_from_hub\n\n...\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton PandaReachDense-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-0.92 +/- 0.34\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "TahsinZaman/ppo-CartPole-v1",
        "author": "TahsinZaman",
        "model_name": "ppo-CartPole-v1",
        "url": "https://huggingface.co/TahsinZaman/ppo-CartPole-v1",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nTahsinZaman\n/\nppo-CartPole-v1\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTensorBoard\n\nLunarLander-v2\n\nppo\n\ndeep-reinforcement-learning\n\ncustom-implementation\n\ndeep-rl-course\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent Playing LunarLander-v2\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\t\tPPO Agent Playing LunarLander-v2\n\t\n\n  This is a trained model of a PPO agent playing LunarLander-v2.\n\n\n\n\n\n\t\tHyperparameters\n\t\n\n{'exp_name': 'ipykernel_launcher'\n'seed': 1\n'torch_deterministic': True\n'cuda': True\n'track': False\n'wandb_project_name': 'cleanRL'\n'wandb_entity': None\n'capture_video': False\n'env_id': 'LunarLander-v2'\n'total_timesteps': 50000\n'learning_rate': 0.00025\n'num_envs': 4\n'num_steps': 128\n'anneal_lr': True\n'gae': True\n'gamma': 0.99\n'gae_lambda': 0.95\n'num_minibatches': 4\n'update_epochs': 4\n'norm_adv': True\n'clip_coef': 0.2\n'clip_vloss': True\n'ent_coef': 0.01\n'vf_coef': 0.5\n'max_grad_norm': 0.5\n'target_kl': None\n'repo_id': 'TahsinZaman/ppo-CartPole-v1'\n'batch_size': 512\n'minibatch_size': 128}\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-191.95 +/- 122.68\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "bsenst/Reinforce-Cartpole",
        "author": "bsenst",
        "model_name": "Reinforce-Cartpole",
        "url": "https://huggingface.co/bsenst/Reinforce-Cartpole",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nbsenst\n/\nReinforce-Cartpole\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nCartPole-v1\n\nreinforce\n\ncustom-implementation\n\ndeep-rl-class\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n\n\n\n\n\n\n\nReinforce Agent playing CartPole-v1\n\n\n  This is a trained model of a Reinforce agent playing CartPole-v1 .\n  To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton CartPole-v1\nself-reported\n\t\t\t\t\t\t\t\n\n500.00 +/- 0.00\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    },
    {
        "title": "msthil/LunarLander-v2-Unit8",
        "author": "msthil",
        "model_name": "LunarLander-v2-Unit8",
        "url": "https://huggingface.co/msthil/LunarLander-v2-Unit8",
        "describe": "\n\n\nHugging Face\n\n\n\n\n\n\n\n\t\t\t\t\tModels\n\n\t\t\t\t\tDatasets\n\n\t\t\t\t\tSpaces\n\n\t\t\t\t\tPosts\n\n\t\t\t\t\tDocs\n\n\n\n\n\t\t\tSolutions\n\t\t\n\nPricing\n\t\t\t\n\n\n\n\n\n\nLog In\n\t\t\t\t\nSign Up\n\t\t\t\t\t\n\n\n\n\n\nmsthil\n/\nLunarLander-v2-Unit8\n\n\n\nlike\n0\n\n\nReinforcement Learning\n\nTensorBoard\n\nLunarLander-v2\n\nppo\n\ndeep-reinforcement-learning\n\ncustom-implementation\n\ndeep-rl-course\n\nEval Results\n\n\n\t\t\tModel card\n\t\t\t\n\t\t\t\n\t\t\nFiles\nFiles and versions\n\nMetrics\nTraining metrics\n\n\t\t\tCommunity\n\t\t\t\n\t\t\t\n\t\t\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tEdit model card\n\t\t\t\t\t\n\n\n\n\nPPO Agent Playing LunarLander-v2\n\nHyperparameters\n\n\n\n\n\n\n\n\n\n\t\tPPO Agent Playing LunarLander-v2\n\t\n\n  This is a trained model of a PPO agent playing LunarLander-v2.\n\n\n\n\n\n\t\tHyperparameters\n\t\n\n{'exp_name': 'ppo'\n'seed': 1\n'torch_deterministic': True\n'cuda': True\n'track': False\n'wandb_project_name': 'cleanRL'\n'wandb_entity': None\n'capture_video': False\n'env_id': 'LunarLander-v2'\n'total_timesteps': 50000\n'learning_rate': 0.00025\n'num_envs': 4\n'num_steps': 128\n'anneal_lr': True\n'gae': True\n'gamma': 0.99\n'gae_lambda': 0.95\n'num_minibatches': 4\n'update_epochs': 4\n'norm_adv': True\n'clip_coef': 0.2\n'clip_vloss': True\n'ent_coef': 0.01\n'vf_coef': 0.5\n'max_grad_norm': 0.5\n'target_kl': None\n'repo_id': 'msthil/LunarLander-v2-Unit8'\n'batch_size': 512\n'minibatch_size': 128}\n\n\n\n\nDownloads last month0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Preview\n\nReinforcement Learning\n\n\nloading\n\n\n\t\tEvaluation results\n\t\t\n\n\nmean_reward\n\t\t\t\t\t\t\ton LunarLander-v2\nself-reported\n\t\t\t\t\t\t\t\n\n-199.51 +/- 149.99\n\n\n\t\t\t\tView on Papers With Code\n\nCompany\n\u00a9 Hugging Face\nTOS\nPrivacy\nAbout\nJobs\n\nWebsite\nModels\nDatasets\nSpaces\nPricing\nDocs\n\n\n\n\n\n"
    }
]